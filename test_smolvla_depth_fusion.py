#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šç›¸æœºæ·±åº¦èåˆæµ‹è¯•è„šæœ¬

æµ‹è¯•SmolVLAå¤šç›¸æœºæ·±åº¦èåˆåŠŸèƒ½çš„å®ç°æ•ˆæœ
"""

from kuavo_deploy.utils.multi_camera_fusion import (
    create_multi_camera_fusion,
    benchmark_multi_camera_fusion
)
from kuavo_deploy.utils.depth_conversion import (
    depth_to_rgb_for_smolvla,
    benchmark_depth_conversion
)
import matplotlib.pyplot as plt
import time
import torch
import numpy as np
import sys
import os
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))


def test_depth_conversion():
    """æµ‹è¯•æ·±åº¦è½¬æ¢åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•æ·±åº¦è½¬æ¢åŠŸèƒ½")
    print("=" * 50)

    # åˆ›å»ºæµ‹è¯•æ·±åº¦å›¾åƒ
    depth_image = np.random.randint(0, 1000, (480, 640), dtype=np.uint16)

    # æµ‹è¯•è½¬æ¢
    rgb_tensor = depth_to_rgb_for_smolvla(
        depth_image,
        target_size=(512, 512),
        depth_range=(0, 1000),
        device='cpu'
    )

    print(f"âœ… æ·±åº¦è½¬æ¢æˆåŠŸ")
    print(f"   è¾“å…¥å½¢çŠ¶: {depth_image.shape}")
    print(f"   è¾“å‡ºå½¢çŠ¶: {rgb_tensor.shape}")
    print(f"   æ•°æ®ç±»å‹: {rgb_tensor.dtype}")
    print(f"   æ•°å€¼èŒƒå›´: [{rgb_tensor.min():.3f}, {rgb_tensor.max():.3f}]")

    return rgb_tensor


def test_multi_camera_fusion():
    """æµ‹è¯•å¤šç›¸æœºèåˆåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•å¤šç›¸æœºèåˆåŠŸèƒ½")
    print("=" * 50)

    # åˆ›å»ºæµ‹è¯•è§‚æµ‹æ•°æ®
    obs = {}

    # RGBç›¸æœºæ•°æ®
    for camera in ['head_cam_h', 'wrist_cam_l', 'wrist_cam_r']:
        obs[camera] = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

    # æ·±åº¦ç›¸æœºæ•°æ®
    for camera in ['depth_h', 'depth_l', 'depth_r']:
        obs[camera] = np.random.randint(0, 1000, (480, 640), dtype=np.uint16)

    # çŠ¶æ€æ•°æ®
    obs['state'] = np.random.randn(16)

    # åˆ›å»ºèåˆå¤„ç†å™¨
    fusion_processor = create_multi_camera_fusion(
        target_size=(512, 512),
        depth_range=(0, 1000),
        device='cpu',
        enable_depth=True
    )

    # å¤„ç†è§‚æµ‹æ•°æ®
    processed_obs = fusion_processor.process_observations_simple(obs)

    print(f"âœ… å¤šç›¸æœºèåˆæˆåŠŸ")
    print(
        f"   è¾“å…¥ç›¸æœºæ•°: {len([k for k in obs.keys() if 'cam' in k or 'depth' in k])}")
    print(
        f"   è¾“å‡ºå¼ é‡æ•°: {len([k for k in processed_obs.keys() if 'observation' in k])}")

    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    print(f"\nğŸ“Š å¤„ç†ç»“æœ:")
    for key, value in processed_obs.items():
        if isinstance(value, torch.Tensor):
            print(f"   {key}: {value.shape} ({value.dtype})")
        else:
            print(f"   {key}: {type(value)}")

    return processed_obs


def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("\nğŸ” æ€§èƒ½æµ‹è¯•")
    print("=" * 50)

    # æ·±åº¦è½¬æ¢æ€§èƒ½æµ‹è¯•
    benchmark_depth_conversion()

    # å¤šç›¸æœºèåˆæ€§èƒ½æµ‹è¯•
    benchmark_multi_camera_fusion()


def test_visualization():
    """æµ‹è¯•å¯è§†åŒ–æ•ˆæœ"""
    print("\nğŸ” å¯è§†åŒ–æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºæ¨¡æ‹Ÿæ·±åº¦å›¾åƒï¼ˆæ¨¡æ‹Ÿä¼ é€å¸¦åœºæ™¯ï¼‰
    depth_image = np.zeros((480, 640), dtype=np.uint16)

    # æ·»åŠ ä¸€äº›æ·±åº¦å±‚æ¬¡
    depth_image[100:200, 200:400] = 300  # è¿‘è·ç¦»ç‰©ä½“
    depth_image[250:350, 150:500] = 600  # ä¸­è·ç¦»ç‰©ä½“
    depth_image[400:450, 100:600] = 900  # è¿œè·ç¦»èƒŒæ™¯

    # è½¬æ¢ä¸ºRGBä¼ªå½©è‰²
    rgb_tensor = depth_to_rgb_for_smolvla(
        depth_image,
        target_size=(512, 512),
        depth_range=(0, 1000),
        device='cpu'
    )

    # è½¬æ¢ä¸ºnumpyç”¨äºæ˜¾ç¤º
    rgb_image = rgb_tensor.squeeze(0).permute(1, 2, 0).numpy()

    print(f"âœ… å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
    print(f"   æ·±åº¦å›¾åƒèŒƒå›´: [{depth_image.min()}, {depth_image.max()}]")
    print(f"   RGBå›¾åƒèŒƒå›´: [{rgb_image.min():.3f}, {rgb_image.max():.3f}]")

    # ä¿å­˜å›¾åƒç”¨äºæ£€æŸ¥
    try:
        import cv2
        cv2.imwrite('/tmp/depth_original.png', depth_image)
        cv2.imwrite('/tmp/depth_rgb.png', (rgb_image * 255).astype(np.uint8))
        print(f"   å›¾åƒå·²ä¿å­˜åˆ° /tmp/ ç›®å½•")
    except ImportError:
        print(f"   éœ€è¦å®‰è£… opencv-python æ¥ä¿å­˜å›¾åƒ")

    return rgb_image


def test_smolvla_compatibility():
    """æµ‹è¯•SmolVLAå…¼å®¹æ€§"""
    print("\nğŸ” SmolVLAå…¼å®¹æ€§æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºæ¨¡æ‹Ÿè§‚æµ‹æ•°æ®
    obs = {}

    # RGBç›¸æœºæ•°æ®
    for camera in ['head_cam_h', 'wrist_cam_l', 'wrist_cam_r']:
        obs[camera] = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)

    # æ·±åº¦ç›¸æœºæ•°æ®
    for camera in ['depth_h', 'depth_l', 'depth_r']:
        obs[camera] = np.random.randint(0, 1000, (480, 640), dtype=np.uint16)

    # çŠ¶æ€æ•°æ®
    obs['state'] = np.random.randn(16)

    # åˆ›å»ºèåˆå¤„ç†å™¨
    fusion_processor = create_multi_camera_fusion(
        target_size=(512, 512),
        depth_range=(0, 1000),
        device='cpu',
        enable_depth=True
    )

    # å¤„ç†è§‚æµ‹æ•°æ®
    processed_obs = fusion_processor.process_observations_simple(obs)

    # æ·»åŠ è¯­è¨€æŒ‡ä»¤ï¼ˆSmolVLAéœ€è¦ï¼‰
    processed_obs['task'] = [
        'Pick up the moving object from the conveyor belt']

    print(f"âœ… SmolVLAå…¼å®¹æ€§æµ‹è¯•å®Œæˆ")
    print(f"   è§‚æµ‹é”®: {list(processed_obs.keys())}")

    # éªŒè¯å¼ é‡å½¢çŠ¶
    for key, value in processed_obs.items():
        if isinstance(value, torch.Tensor):
            if len(value.shape) == 4:  # å›¾åƒå¼ é‡
                print(f"   {key}: {value.shape} âœ… (å›¾åƒå¼ é‡)")
            elif len(value.shape) == 2:  # çŠ¶æ€å¼ é‡
                print(f"   {key}: {value.shape} âœ… (çŠ¶æ€å¼ é‡)")
        elif isinstance(value, list):  # è¯­è¨€æŒ‡ä»¤
            print(f"   {key}: {len(value)} æ¡æŒ‡ä»¤ âœ… (è¯­è¨€æŒ‡ä»¤)")

    return processed_obs


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ SmolVLAå¤šç›¸æœºæ·±åº¦èåˆæµ‹è¯•")
    print("=" * 60)

    try:
        # 1. æµ‹è¯•æ·±åº¦è½¬æ¢
        test_depth_conversion()

        # 2. æµ‹è¯•å¤šç›¸æœºèåˆ
        test_multi_camera_fusion()

        # 3. æµ‹è¯•æ€§èƒ½
        test_performance()

        # 4. æµ‹è¯•å¯è§†åŒ–
        test_visualization()

        # 5. æµ‹è¯•SmolVLAå…¼å®¹æ€§
        test_smolvla_compatibility()

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("âœ… SmolVLAå¤šç›¸æœºæ·±åº¦èåˆåŠŸèƒ½å·²æˆåŠŸå®ç°")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
