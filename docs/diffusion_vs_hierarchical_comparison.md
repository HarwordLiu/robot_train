# Diffusion Policy vs Hierarchical Diffusion Policy æ·±åº¦å¯¹æ¯”

> è¯¦ç»†å¯¹æ¯”æ™®é€š Diffusion Policy å’Œåˆ†å±‚ Hierarchical Diffusion Policy çš„æ¶æ„ã€å®ç°å’Œåº”ç”¨åœºæ™¯

---

## ğŸ“‹ ç›®å½•

1. [æ¶æ„å¯¹æ¯”æ¦‚è§ˆ](#1-æ¶æ„å¯¹æ¯”æ¦‚è§ˆ)
2. [æ ¸å¿ƒè®¾è®¡å·®å¼‚](#2-æ ¸å¿ƒè®¾è®¡å·®å¼‚)
3. [è®­ç»ƒæµç¨‹å¯¹æ¯”](#3-è®­ç»ƒæµç¨‹å¯¹æ¯”)
4. [æ¨ç†æµç¨‹å¯¹æ¯”](#4-æ¨ç†æµç¨‹å¯¹æ¯”)
5. [ä»£ç å®ç°å¯¹æ¯”](#5-ä»£ç å®ç°å¯¹æ¯”)
6. [é€‚ç”¨åœºæ™¯åˆ†æ](#6-é€‚ç”¨åœºæ™¯åˆ†æ)
7. [æ€§èƒ½ä¸å¤æ‚åº¦](#7-æ€§èƒ½ä¸å¤æ‚åº¦)
8. [å¦‚ä½•é€‰æ‹©](#8-å¦‚ä½•é€‰æ‹©)

---

## 1. æ¶æ„å¯¹æ¯”æ¦‚è§ˆ

### 1.1 å¯è§†åŒ–å¯¹æ¯”

#### Diffusion Policy (å•å±‚æ¶æ„)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è§‚æµ‹è¾“å…¥                                 â”‚
â”‚  RGB [B,n_obs,n_cam,3,H,W] + Depth + State                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ç‰¹å¾ç¼–ç  + å¤šæ¨¡æ€èåˆ                        â”‚
â”‚  RGB Encoder â†’ Self-Attn â†’ Cross-Attn with Depth           â”‚
â”‚  Depth Encoder â†’ Self-Attn â†’ Cross-Attn with RGB           â”‚
â”‚  State Encoder (Optional)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Global Condition [B, n_obs, cond_dim]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Diffusion Model (Transformer)               â”‚
â”‚  è®­ç»ƒ: å™ªå£°é¢„æµ‹ Îµ_Î¸(x_t, t, condition)                      â”‚
â”‚  æ¨ç†: è¿­ä»£å»å™ª x_T â†’ x_{T-1} â†’ ... â†’ x_0                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 åŠ¨ä½œè¾“å‡º [B, horizon, action_dim]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Hierarchical Diffusion Policy (å››å±‚æ¶æ„)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è§‚æµ‹è¾“å…¥                                 â”‚
â”‚  RGB + Depth + State                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚                    â”‚
                         â–¼                    â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ç‰¹å¾ç¼–ç  + èåˆ  â”‚   â”‚  Diffusion Model    â”‚
              â”‚  (åŒå·¦ä¾§)         â”‚   â”‚  (åº•å±‚å»å™ªç½‘ç»œ)      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                       â”‚
                        â–¼                       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
              â”‚ Global Condition â”‚             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                        â”‚                       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Hierarchical Scheduler                      â”‚
â”‚  åè°ƒå’Œè°ƒåº¦å››ä¸ªåˆ†å±‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚             â”‚             â”‚              â”‚
           â–¼             â–¼             â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SafetyReflexâ”‚  â”‚ GaitControl â”‚  â”‚ Manipulation â”‚  â”‚GlobalPlanningâ”‚
â”‚  Layer      â”‚  â”‚  Layer      â”‚  â”‚  Layer       â”‚  â”‚  Layer       â”‚
â”‚ Priority: 1 â”‚  â”‚ Priority: 2 â”‚  â”‚ Priority: 3  â”‚  â”‚ Priority: 4  â”‚
â”‚ <10ms       â”‚  â”‚ ~20ms       â”‚  â”‚ ~100ms       â”‚  â”‚ ~500ms       â”‚
â”‚             â”‚  â”‚             â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ â€¢ Emergency â”‚  â”‚ â€¢ Gait      â”‚  â”‚ â€¢ Fine       â”‚  â”‚ â€¢ Long-term  â”‚
â”‚ â€¢ Balance   â”‚  â”‚ â€¢ Locomotionâ”‚  â”‚   Manip      â”‚  â”‚   Planning   â”‚
â”‚             â”‚  â”‚ â€¢ Terrain   â”‚  â”‚ â€¢ Bimanual   â”‚  â”‚ â€¢ Task       â”‚
â”‚             â”‚  â”‚   Adapt     â”‚  â”‚ â€¢ Constraint â”‚  â”‚   Decomp     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                 â”‚                 â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   å±‚è¾“å‡ºèšåˆ + ä¼˜å…ˆçº§  â”‚
                        â”‚   Safetyå¯ä»¥è¦†ç›–å…¶ä»–   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ æœ€ç»ˆåŠ¨ä½œ + Diffusion  â”‚
                        â”‚ ç»“åˆå±‚è¾“å‡º + æ‰©æ•£è¾“å‡º  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å…³é”®åŒºåˆ«è¡¨

| ç»´åº¦ | Diffusion Policy | Hierarchical Diffusion Policy |
|---|---|---|
| **æ¶æ„å±‚æ¬¡** | å•å±‚ | å››å±‚ (Safety â†’ Gait â†’ Manipulation â†’ Planning) |
| **æ ¸å¿ƒæ¨¡å‹** | 1ä¸ªDiffusion Model | 1ä¸ªDiffusion Model + 4ä¸ªä¸“ç”¨å±‚ |
| **å†³ç­–æµç¨‹** | ç›´æ¥: Obs â†’ Diffusion â†’ Action | åˆ†å±‚: Obs â†’ Scheduler â†’ Layers â†’ Aggregation â†’ Action |
| **ä¼˜å…ˆçº§æœºåˆ¶** | æ—  | æœ‰ (Safetyæœ€é«˜ï¼Œå¯è¦†ç›–å…¶ä»–å±‚) |
| **å“åº”æ—¶é—´** | ç»Ÿä¸€ (~50ms) | åˆ†å±‚ (10ms ~ 500ms) |
| **è®­ç»ƒæ–¹å¼** | ç«¯åˆ°ç«¯ | è¯¾ç¨‹å­¦ä¹  (é€å±‚æ¿€æ´») |
| **ä»»åŠ¡é€‚åº”** | é€šç”¨å­¦ä¹  | ä»»åŠ¡ç‰¹å®š (å¯é’ˆå¯¹ä»»åŠ¡è°ƒæ•´å±‚æƒé‡) |

---

## 2. æ ¸å¿ƒè®¾è®¡å·®å¼‚

### 2.1 è®¾è®¡ç†å¿µ

#### Diffusion Policy
```
è®¾è®¡ç†å¿µ: ç»Ÿä¸€å»ºæ¨¡
- ä¸€ä¸ªå¼ºå¤§çš„æ‰©æ•£æ¨¡å‹å¤„ç†æ‰€æœ‰ä»»åŠ¡
- é€šè¿‡å¤§é‡æ•°æ®å­¦ä¹ å¤æ‚åˆ†å¸ƒ
- å¤šæ¨¡æ€èåˆæå‡æ„ŸçŸ¥èƒ½åŠ›
- ç«¯åˆ°ç«¯ä¼˜åŒ–

ä¼˜åŠ¿:
âœ… æ¶æ„ç®€å•ï¼Œæ˜“äºç†è§£å’Œå®ç°
âœ… ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä¼˜åŒ–ç›®æ ‡æ˜ç¡®
âœ… å¯¹æ•°æ®è´¨é‡è¦æ±‚ç›¸å¯¹è¾ƒä½
âœ… æ³›åŒ–èƒ½åŠ›å¼º

åŠ£åŠ¿:
âŒ éš¾ä»¥åŒºåˆ†ä»»åŠ¡ä¼˜å…ˆçº§
âŒ ç´§æ€¥æƒ…å†µååº”å¯èƒ½ä¸å¤Ÿå¿«
âŒ è®­ç»ƒæ—¶å„ä»»åŠ¡è€¦åˆåœ¨ä¸€èµ·
âŒ éš¾ä»¥é’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–
```

#### Hierarchical Diffusion Policy
```
è®¾è®¡ç†å¿µ: åˆ†å±‚æ§åˆ¶ + ç»Ÿä¸€åº•å±‚
- å››å±‚ä¸“ç”¨ç½‘ç»œå¤„ç†ä¸åŒæŠ½è±¡çº§åˆ«çš„ä»»åŠ¡
- åº•å±‚ä»ä½¿ç”¨Diffusion Modelä¿è¯åŠ¨ä½œè´¨é‡
- å±‚é—´æœ‰æ˜ç¡®çš„ä¼˜å…ˆçº§å’Œåè°ƒæœºåˆ¶
- è¯¾ç¨‹å­¦ä¹ é€æ­¥å¢åŠ å¤æ‚åº¦

ä¼˜åŠ¿:
âœ… å®‰å…¨æ€§é«˜ (Safetyå±‚å¯ç´§æ€¥è¦†ç›–)
âœ… å“åº”é€Ÿåº¦åˆ†å±‚ (ç´§æ€¥ä»»åŠ¡<10ms)
âœ… å¯é’ˆå¯¹ä»»åŠ¡ä¼˜åŒ– (è°ƒæ•´å±‚æƒé‡)
âœ… è®­ç»ƒæ›´ç¨³å®š (è¯¾ç¨‹å­¦ä¹ )
âœ… å¯è§£é‡Šæ€§æ›´å¼º (çŸ¥é“å“ªå±‚åœ¨åšä»€ä¹ˆ)

åŠ£åŠ¿:
âŒ æ¶æ„å¤æ‚ï¼Œå®ç°éš¾åº¦å¤§
âŒ è®­ç»ƒæµç¨‹å¤æ‚ (éœ€è¦è¯¾ç¨‹å­¦ä¹ )
âŒ è¶…å‚æ•°æ›´å¤š (å±‚æƒé‡ã€ä¼˜å…ˆçº§ç­‰)
âŒ å¯¹æ•°æ®è´¨é‡è¦æ±‚é«˜ (éœ€è¦ä»»åŠ¡æ ‡æ³¨)
```

### 2.2 æ ¸å¿ƒç»„ä»¶å¯¹æ¯”

#### 2.2.1 ç‰¹å¾ç¼–ç å™¨

**Diffusion Policy**:
```python
# å®Œå…¨å…±äº«çš„ç‰¹å¾ç¼–ç 
global_cond = _prepare_global_conditioning(batch)
# åŒ…å«: RGB_fused + Depth_fused + State
# â†’ [B, n_obs, cond_dim]

# ç›´æ¥é€å…¥Diffusion Model
noise_pred = transformer(noisy_actions, timesteps, global_cond)
```

**Hierarchical Diffusion Policy**:
```python
# åŒæ ·çš„ç‰¹å¾ç¼–ç ä½œä¸ºåŸºç¡€
global_cond = _prepare_global_conditioning(batch)

# ä½†ä¼šè¢«åˆ†å‘åˆ°å¤šä¸ªå±‚
layer_outputs = scheduler.forward(batch, task_info)
# schedulerå†…éƒ¨ä¼š:
# 1. ä¸ºæ¯å±‚æå–ç›¸å…³ç‰¹å¾
# 2. æ¯å±‚ç‹¬ç«‹å¤„ç†
# 3. æ ¹æ®ä¼˜å…ˆçº§èšåˆ

# Diffusion Modelä¹Ÿä¼šä½¿ç”¨global_cond
diffusion_loss = diffusion.compute_loss(batch)

# æœ€ç»ˆæŸå¤±èšåˆ
total_loss = diffusion_loss + Î£(layer_weights[i] * layer_losses[i])
```

#### 2.2.2 å»å™ªç½‘ç»œ

**Diffusion Policy**:
```python
class CustomDiffusionModelWrapper(DiffusionModel):
    def __init__(self, config):
        # å•ä¸€Transformerå»å™ªç½‘ç»œ
        self.unet = TransformerForDiffusion(
            input_dim=action_dim,
            output_dim=action_dim,
            horizon=16,
            cond_dim=global_cond_dim,
            ...
        )

    def compute_loss(self, batch):
        # æ ‡å‡†æ‰©æ•£æŸå¤±
        noise_pred = self.unet(noisy_actions, timesteps, global_cond)
        loss = MSE(noise_pred, noise)
        return loss
```

**Hierarchical Diffusion Policy**:
```python
class HierarchicalDiffusionModel(CustomDiffusionModelWrapper):
    def __init__(self, config):
        # ç»§æ‰¿åŒæ ·çš„Diffusion Model
        super().__init__(config)
        # ä¸åœ¨è¿™é‡Œæ”¹å˜æ¶æ„ï¼

    def compute_loss(self, batch, layer_outputs=None):
        # æ³¨æ„: layer_outputsä¸ç›´æ¥èåˆåˆ°Diffusion
        # åˆ†å±‚ä»·å€¼åœ¨äºè¯¾ç¨‹å­¦ä¹ å’Œåè°ƒï¼Œä¸æ˜¯ç‰¹å¾èåˆ
        return super().compute_loss(batch)

# å…³é”®åŒºåˆ«: åˆ†å±‚ä½“ç°åœ¨å¤–éƒ¨çš„Schedulerå’Œç‹¬ç«‹çš„Layers
# Diffusion Modelä¿æŒä¸å˜ï¼Œä½œä¸º"åº•å±‚åŠ¨ä½œç”Ÿæˆå™¨"
```

#### 2.2.3 æ–°å¢ç»„ä»¶: Hierarchical Scheduler

**åªåœ¨Hierarchicalä¸­å­˜åœ¨**:
```python
class HierarchicalScheduler:
    def __init__(self, hierarchical_config, base_config):
        # æ„å»ºå››ä¸ªå±‚
        self.layers = {
            'safety': SafetyReflexLayer(config, priority=1),
            'gait': GaitControlLayer(config, priority=2),
            'manipulation': ManipulationLayer(config, priority=3),
            'planning': GlobalPlanningLayer(config, priority=4),
        }

    def forward(self, batch, task_info):
        """è°ƒåº¦å„å±‚ï¼ŒæŒ‰ä¼˜å…ˆçº§å¤„ç†"""
        layer_outputs = {}
        context = self._build_context(batch, task_info)

        # æŒ‰ä¼˜å…ˆçº§é¡ºåºå¤„ç†
        for layer_name in self._get_processing_order():
            layer = self.layers[layer_name]

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ¿€æ´»
            if layer.should_activate(batch, context):
                output = layer.forward_with_timing(batch, context)
                layer_outputs[layer_name] = output

                # Safetyå±‚å¯ä»¥ç«‹å³ä¸­æ–­
                if layer_name == 'safety' and output.get('emergency'):
                    break

                # æ›´æ–°contextä¾›åç»­å±‚ä½¿ç”¨
                context.update(output)

        return layer_outputs
```

#### 2.2.4 æ–°å¢ç»„ä»¶: åˆ†å±‚ Layers

**å››ä¸ªä¸“ç”¨å±‚**:

1. **SafetyReflexLayer** (Priority 1, <10ms)
```python
class SafetyReflexLayer(BaseLayer):
    def __init__(self, config, priority=1):
        super().__init__(config, "safety", priority)
        # æœ€ç®€å•çš„ç½‘ç»œ: å°GRU
        self.balance_control = nn.GRU(
            input_size=robot_state_dim,
            hidden_size=64,
            num_layers=1
        )
        self.emergency_detector = nn.Sequential(
            nn.Linear(robot_state_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Sigmoid()
        )

    def forward(self, inputs, context):
        """æ£€æµ‹ç´§æ€¥æƒ…å†µï¼Œç”Ÿæˆå®‰å…¨åŠ¨ä½œ"""
        state = inputs['observation.state']

        # æ£€æµ‹æ˜¯å¦ç´§æ€¥
        emergency_score = self.emergency_detector(state)

        if emergency_score > 0.8:
            # ç”Ÿæˆç´§æ€¥åŠ¨ä½œ (å¦‚: å…¨éƒ¨åœæ­¢)
            emergency_action = self.generate_emergency_action(state)
            return {
                'emergency': True,
                'action': emergency_action,
                'emergency_score': emergency_score
            }

        # æ­£å¸¸æƒ…å†µ: ç”Ÿæˆå¹³è¡¡è°ƒæ•´
        balance_action, _ = self.balance_control(state)
        return {
            'emergency': False,
            'action': balance_action,
            'balance_confidence': ...
        }
```

2. **GaitControlLayer** (Priority 2, ~20ms)
```python
class GaitControlLayer(BaseLayer):
    def __init__(self, config, priority=2):
        super().__init__(config, "gait", priority)
        # GRU + è½»é‡Transformer
        self.gait_tracker = nn.GRU(...)
        self.gait_planner = nn.TransformerEncoder(...)
        self.load_adaptation = LoadAdaptationModule(...)
```

3. **ManipulationLayer** (Priority 3, ~100ms)
```python
class ManipulationLayer(BaseLayer):
    def __init__(self, config, priority=3):
        super().__init__(config, "manipulation", priority)
        # Transformerä¸»å¯¼
        self.manipulation_transformer = nn.TransformerEncoder(...)
        self.constraint_solver = ConstraintSatisfactionModule(...)
        self.bimanual_coordinator = BimanualCoordinationModule(...)
```

4. **GlobalPlanningLayer** (Priority 4, ~500ms)
```python
class GlobalPlanningLayer(BaseLayer):
    def __init__(self, config, priority=4):
        super().__init__(config, "planning", priority)
        # å¤§Transformer + é•¿æœŸè®°å¿†
        self.planning_transformer = nn.TransformerEncoder(...)
        self.long_term_memory = LongTermMemoryModule(...)
        self.task_decomposer = TaskDecompositionModule(...)
```

---

## 3. è®­ç»ƒæµç¨‹å¯¹æ¯”

### 3.1 Diffusion Policy è®­ç»ƒæµç¨‹

```python
# train_policy.py
for epoch in range(max_epochs):
    for batch in dataloader:
        # 1. å‰å‘ä¼ æ’­
        loss, _ = policy.forward(batch)
        # å†…éƒ¨è°ƒç”¨:
        # - ç‰¹å¾ç¼–ç 
        # - å¤šæ¨¡æ€èåˆ
        # - DiffusionæŸå¤±è®¡ç®—: ||Îµ - Îµ_Î¸||Â²

        # 2. åå‘ä¼ æ’­
        loss.backward()

        # 3. ä¼˜åŒ–
        optimizer.step()

        # å°±è¿™ä¹ˆç®€å•ï¼
```

**ç‰¹ç‚¹**:
- âœ… ç®€å•ç›´æ¥
- âœ… ç«¯åˆ°ç«¯ä¼˜åŒ–
- âœ… ä¸€ä¸ªæŸå¤±å‡½æ•°
- âŒ æ— æ³•åŒºåˆ†ä»»åŠ¡ä¼˜å…ˆçº§

### 3.2 Hierarchical Diffusion Policy è®­ç»ƒæµç¨‹

```python
# train_hierarchical_policy.py
# åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ 
task_manager = TaskSpecificTrainingManager(cfg)
curriculum_stages = task_manager.get_current_curriculum_stages()

for stage_idx, stage in enumerate(curriculum_stages):
    print(f"=== Stage {stage_idx}: {stage['name']} ===")
    print(f"Enabled layers: {stage['enabled_layers']}")
    print(f"Epochs: {stage['epochs']}")

    # é˜¶æ®µæ€§è®­ç»ƒ
    for epoch in range(stage['epochs']):
        for batch in dataloader:
            # 1. å‡†å¤‡è¯¾ç¨‹ä¿¡æ¯
            curriculum_info = {
                'stage': stage['name'],
                'enabled_layers': stage['enabled_layers'],
                'layer_weights': stage.get('layer_weights', {}),
            }

            # 2. åˆ†å±‚å‰å‘ä¼ æ’­
            loss, outputs = policy.forward(
                batch,
                curriculum_info=curriculum_info,
                task_weights=task_manager.get_task_specific_layer_weights(task_id)
            )
            # å†…éƒ¨è°ƒç”¨:
            # - ç‰¹å¾ç¼–ç  (åŒDiffusion)
            # - Schedulerè°ƒåº¦å„å±‚
            # - åªæœ‰enabled_layersè¢«æ¿€æ´»
            # - è®¡ç®—diffusion_loss
            # - è®¡ç®—å„å±‚çš„layer_loss
            # - èšåˆ: total_loss = diffusion_loss + Î£(weights * layer_losses)

            # 3. åå‘ä¼ æ’­
            loss.backward()

            # 4. ä¼˜åŒ–
            optimizer.step()

    print(f"âœ… Stage {stage['name']} completed!")
```

**è¯¾ç¨‹å­¦ä¹ ç¤ºä¾‹**:
```yaml
curriculum_stages:
  - name: "manipulation_only"
    enabled_layers: ["manipulation"]
    epochs: 50
    layer_weights:
      manipulation: 2.0

  - name: "manipulation_with_safety"
    enabled_layers: ["safety", "manipulation"]
    epochs: 50
    layer_weights:
      safety: 1.5
      manipulation: 2.0

  - name: "add_gait"
    enabled_layers: ["safety", "gait", "manipulation"]
    epochs: 100
    layer_weights:
      safety: 2.0
      gait: 1.5
      manipulation: 2.0

  - name: "full_hierarchy"
    enabled_layers: ["safety", "gait", "manipulation", "planning"]
    epochs: 200
    layer_weights:
      safety: 2.0
      gait: 1.5
      manipulation: 2.0
      planning: 0.8
```

**ç‰¹ç‚¹**:
- âœ… æ¸è¿›å¼å­¦ä¹ ï¼Œæ›´ç¨³å®š
- âœ… å¯é’ˆå¯¹ä»»åŠ¡è°ƒæ•´
- âœ… å„å±‚ç‹¬ç«‹ä¼˜åŒ–
- âŒ å¤æ‚ï¼Œéœ€è¦ç²¾å¿ƒè®¾è®¡è¯¾ç¨‹
- âŒ è®­ç»ƒæ—¶é—´æ›´é•¿

### 3.3 æŸå¤±å‡½æ•°å¯¹æ¯”

#### Diffusion Policy
```python
loss = diffusion_loss
     = MSE(noise_pred, noise)
```

#### Hierarchical Diffusion Policy
```python
# 1. DiffusionæŸå¤± (åº•å±‚åŠ¨ä½œç”Ÿæˆ)
diffusion_loss = MSE(noise_pred, noise)

# 2. å„å±‚æŸå¤±
layer_losses = {}
for layer_name, output in layer_outputs.items():
    if 'action' in output and 'target_action' in output:
        layer_losses[layer_name] = MSE(output['action'], output['target_action'])

# 3. èšåˆæŸå¤±
total_loss = diffusion_loss
for layer_name, layer_loss in layer_losses.items():
    if layer_name in enabled_layers:
        weight = task_layer_weights[layer_name]
        total_loss += weight * layer_loss

# ä¾‹å¦‚:
# total_loss = diffusion_loss
#            + 2.0 * safety_loss
#            + 1.5 * gait_loss
#            + 2.0 * manipulation_loss
#            + 0.8 * planning_loss
```

---

## 4. æ¨ç†æµç¨‹å¯¹æ¯”

### 4.1 Diffusion Policy æ¨ç†

```python
# åœ¨çº¿æ¨ç†
policy.reset()

for step in range(max_steps):
    # 1. è·å–è§‚æµ‹
    obs = env.get_observation()

    # 2. é€‰æ‹©åŠ¨ä½œ
    action = policy.select_action(obs)
    # å†…éƒ¨æµç¨‹:
    # - å¡«å……observation queue
    # - å¦‚æœaction queueä¸ºç©º:
    #   a. ä»obs queueæ„å»ºbatch
    #   b. ç‰¹å¾ç¼–ç  + å¤šæ¨¡æ€èåˆ
    #   c. æ‰©æ•£å»å™ª (10æ­¥DDIM):
    #      x_T ~ N(0,I)
    #      for t in [99,90,...,9]:
    #          Îµ_pred = transformer(x_t, t, global_cond)
    #          x_{t-1} = denoise(x_t, Îµ_pred, t)
    #   d. å¡«å……action queue (16ä¸ªåŠ¨ä½œ)
    # - ä»action queue popç¬¬ä¸€ä¸ª

    # 3. æ‰§è¡Œ
    env.step(action)
```

**æ¨ç†æ—¶é—´**: ~50ms (DDIM 10æ­¥)

### 4.2 Hierarchical Diffusion Policy æ¨ç†

```python
# åœ¨çº¿æ¨ç†
policy.reset()

for step in range(max_steps):
    # 1. è·å–è§‚æµ‹
    obs = env.get_observation()

    # 2. é€‰æ‹©åŠ¨ä½œ (åˆ†å±‚)
    action = policy.select_action(obs)
    # å†…éƒ¨æµç¨‹:
    # - å¡«å……observation queue
    # - å¦‚æœaction queueä¸ºç©º:
    #   a. ä»obs queueæ„å»ºbatch
    #   b. ç‰¹å¾ç¼–ç  + å¤šæ¨¡æ€èåˆ
    #
    #   c. è°ƒåº¦å„å±‚ (æŒ‰ä¼˜å…ˆçº§):
    #      layer_outputs = {}
    #
    #      # Safety Layer (~5ms)
    #      if safety.should_activate(obs, context):
    #          output = safety.forward(obs, context)
    #          if output['emergency']:
    #              # ç´§æ€¥æƒ…å†µ: ç«‹å³è¿”å›å®‰å…¨åŠ¨ä½œ
    #              return output['emergency_action']
    #          layer_outputs['safety'] = output
    #
    #      # Gait Layer (~15ms)
    #      if gait.should_activate(obs, context):
    #          output = gait.forward(obs, context)
    #          layer_outputs['gait'] = output
    #
    #      # Manipulation Layer (~80ms)
    #      if manipulation.should_activate(obs, context):
    #          output = manipulation.forward(obs, context)
    #          layer_outputs['manipulation'] = output
    #
    #      # Planning Layer (å¯èƒ½è·³è¿‡)
    #      if has_time and planning.should_activate(obs, context):
    #          output = planning.forward(obs, context)
    #          layer_outputs['planning'] = output
    #
    #   d. æ‰©æ•£å»å™ª (åŒDiffusion Policy)
    #      diffusion_actions = diffusion.generate(global_cond)
    #
    #   e. èšåˆå±‚è¾“å‡º:
    #      if layer_outputs['safety']['emergency']:
    #          final_actions = layer_outputs['safety']['action']
    #      else:
    #          # èåˆdiffusion_actionså’Œlayer_outputs
    #          final_actions = aggregate(
    #              diffusion_actions,
    #              layer_outputs,
    #              priorities=[1,2,3,4]
    #          )
    #
    #   f. å¡«å……action queue
    #
    # - ä»action queue popç¬¬ä¸€ä¸ª

    # 3. æ‰§è¡Œ
    env.step(action)
```

**æ¨ç†æ—¶é—´**:
- æ­£å¸¸æƒ…å†µ: ~100ms (åŒ…å«æ‰€æœ‰å±‚)
- ç´§æ€¥æƒ…å†µ: <10ms (åªæœ‰Safetyå±‚)

### 4.3 ç´§æ€¥æƒ…å†µå¯¹æ¯”

#### Diffusion Policy
```
åœºæ™¯: æœºå™¨äººå³å°†æ‘”å€’

1. è§‚æµ‹ â†’ ç‰¹å¾ç¼–ç  â†’ Diffusion Model
   æ—¶é—´: ~50ms
2. Diffusionç”ŸæˆåŠ¨ä½œ
3. æ‰§è¡ŒåŠ¨ä½œ

é£é™©: ååº”å¯èƒ½ä¸å¤Ÿå¿«
```

#### Hierarchical Diffusion Policy
```
åœºæ™¯: æœºå™¨äººå³å°†æ‘”å€’

1. è§‚æµ‹ â†’ SafetyReflexLayer
   æ—¶é—´: <5ms
2. æ£€æµ‹åˆ°ç´§æ€¥: emergency_score > 0.8
3. ç«‹å³ç”Ÿæˆemergency_action
4. è·³è¿‡å…¶ä»–å±‚å’ŒDiffusion
5. æ‰§è¡Œç´§æ€¥åŠ¨ä½œ

ä¼˜åŠ¿: ååº”æå¿«ï¼Œå®‰å…¨æ€§é«˜
```

---

## 5. ä»£ç å®ç°å¯¹æ¯”

### 5.1 Policyç±»ç»§æ‰¿å…³ç³»

```
Diffusion Policy:
  DiffusionPolicy (lerobotåŸå§‹)
    â””â”€â–º CustomDiffusionPolicyWrapper (æˆ‘ä»¬çš„åŒ…è£…)
          â”œâ”€ æ·»åŠ : å›¾åƒé¢„å¤„ç† (crop, resize)
          â”œâ”€ æ·»åŠ : æ·±åº¦å›¾å¤„ç†
          â””â”€ ä½¿ç”¨: CustomDiffusionModelWrapper

Hierarchical Diffusion Policy:
  DiffusionPolicy (lerobotåŸå§‹)
    â””â”€â–º CustomDiffusionPolicyWrapper (æˆ‘ä»¬çš„åŒ…è£…)
          â””â”€â–º HumanoidDiffusionPolicyWrapper (åˆ†å±‚åŒ…è£…)
                â”œâ”€ if use_hierarchical:
                â”‚   â”œâ”€ æ›¿æ¢: diffusion â†’ HierarchicalDiffusionModel
                â”‚   â”œâ”€ æ·»åŠ : scheduler (HierarchicalScheduler)
                â”‚   â”œâ”€ æ·»åŠ : 4ä¸ªåˆ†å±‚Layers
                â”‚   â””â”€ ä¿®æ”¹: forward() â†’ _hierarchical_forward()
                â””â”€ else:
                    â””â”€ é€€åŒ–ä¸ºCustomDiffusionPolicyWrapper
```

### 5.2 Modelç±»ç»§æ‰¿å…³ç³»

```
Diffusion Policy:
  DiffusionModel (lerobotåŸå§‹)
    â””â”€â–º CustomDiffusionModelWrapper
          â”œâ”€ æ·»åŠ : RGB/Depth Encoder
          â”œâ”€ æ·»åŠ : å¤šæ¨¡æ€èåˆ (Cross-Attention)
          â”œâ”€ æ·»åŠ : State Encoder
          â””â”€ ä½¿ç”¨: TransformerForDiffusion

Hierarchical Diffusion Policy:
  DiffusionModel (lerobotåŸå§‹)
    â””â”€â–º CustomDiffusionModelWrapper
          â””â”€â–º HierarchicalDiffusionModel
                â””â”€ compute_loss(batch, layer_outputs)
                     â””â”€ super().compute_loss(batch)
                        # æ³¨æ„: ä¸æ”¹å˜Diffusionæ¶æ„
                        # layer_outputsåªå½±å“å¤–éƒ¨lossèšåˆ
```

### 5.3 Forwardå‡½æ•°å¯¹æ¯”

#### Diffusion Policy
```python
def forward(self, batch):
    # 1. å›¾åƒé¢„å¤„ç†
    batch = self._preprocess_images(batch)

    # 2. å½’ä¸€åŒ–
    batch = self.normalize_inputs(batch)
    batch = self.normalize_targets(batch)

    # 3. è®¡ç®—DiffusionæŸå¤±
    loss = self.diffusion.compute_loss(batch)

    return loss, None
```

#### Hierarchical Diffusion Policy
```python
def forward(self, batch, curriculum_info=None, task_weights=None):
    if not self.use_hierarchical:
        return super().forward(batch)

    # 1. æ›´æ–°ä»»åŠ¡æƒé‡å’Œè¯¾ç¨‹çŠ¶æ€
    if task_weights:
        self._update_task_weights(task_weights)
    if curriculum_info:
        self._update_curriculum_state(curriculum_info)

    # 2. å›¾åƒé¢„å¤„ç†
    batch = self._preprocess_batch(batch)

    # 3. å½’ä¸€åŒ–
    batch = self.normalize_inputs(batch)
    batch = self.normalize_targets(batch)

    # 4. è¯†åˆ«ä»»åŠ¡ç‰¹å¾
    task_info = self._identify_task(batch, curriculum_info)

    # 5. è°ƒåº¦å„å±‚
    layer_outputs = self.scheduler.forward(batch, task_info)

    # 6. è®¡ç®—DiffusionæŸå¤±
    diffusion_loss = self.diffusion.compute_loss(batch, layer_outputs)

    # 7. èšåˆåˆ†å±‚æŸå¤±
    total_loss = self._aggregate_hierarchical_loss(
        diffusion_loss,
        layer_outputs,
        self.task_layer_weights,
        self.enabled_layers
    )

    return total_loss, {
        'diffusion_loss': diffusion_loss,
        'layer_outputs': layer_outputs,
        'total_loss': total_loss
    }
```

---

## 6. é€‚ç”¨åœºæ™¯åˆ†æ

### 6.1 Diffusion Policy é€‚åˆçš„åœºæ™¯

âœ… **é€šç”¨æœºå™¨äººæ“ä½œ**
- æ¡Œé¢æ“ä½œ (æŠ“å–ã€æ”¾ç½®)
- ç®€å•ç§»åŠ¨ä»»åŠ¡
- ä¸éœ€è¦å®æ—¶å“åº”çš„ä»»åŠ¡

âœ… **æ•°æ®å……è¶³çš„åœºæ™¯**
- æœ‰å¤§é‡é«˜è´¨é‡æ¼”ç¤ºæ•°æ®
- ä»»åŠ¡åˆ†å¸ƒç›¸å¯¹å‡åŒ€

âœ… **è¿½æ±‚ç®€å•æ€§**
- å›¢é˜Ÿç»éªŒæœ‰é™
- æƒ³å¿«é€ŸåŸå‹éªŒè¯
- ä¸éœ€è¦å¤æ‚çš„ä»»åŠ¡ç‰¹å®šä¼˜åŒ–

**ç¤ºä¾‹é¡¹ç›®**:
- å·¥ä¸šè£…é…çº¿ä¸Šçš„å›ºå®šæ“ä½œ
- å®éªŒå®¤ç¯å¢ƒçš„ç‰©å“æ“ä½œ
- å®¶åº­æœåŠ¡æœºå™¨äººçš„ç®€å•ä»»åŠ¡

### 6.2 Hierarchical Diffusion Policy é€‚åˆçš„åœºæ™¯

âœ… **äººå½¢æœºå™¨äºº**
- éœ€è¦åŒæ—¶å¤„ç†å¹³è¡¡ã€è¡Œèµ°ã€æ“ä½œ
- å®‰å…¨æ€§è¦æ±‚æé«˜
- ä»»åŠ¡å¤æ‚åº¦é«˜

âœ… **åˆ†å±‚ä»»åŠ¡ç»“æ„æ˜ç¡®**
- æœ‰æ˜ç¡®çš„ä¼˜å…ˆçº§ (å®‰å…¨ > è¡Œèµ° > æ“ä½œ)
- ä¸åŒä»»åŠ¡å“åº”æ—¶é—´è¦æ±‚ä¸åŒ
- éœ€è¦å®æ—¶åº”æ€¥ååº”

âœ… **å¤šä»»åŠ¡åœºæ™¯**
- éœ€è¦åœ¨å¤šä¸ªä¸åŒä»»åŠ¡é—´åˆ‡æ¢
- æƒ³é’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–
- æœ‰ä»»åŠ¡æ ‡æ³¨æ•°æ®

âœ… **é«˜å®‰å…¨æ€§è¦æ±‚**
- ä¸èƒ½æ¥å—ä»»ä½•æ‘”å€’é£é™©
- éœ€è¦ç´§æ€¥åˆ¶åŠ¨æœºåˆ¶
- éœ€è¦å®æ—¶ç›‘æ§ç³»ç»ŸçŠ¶æ€

**ç¤ºä¾‹é¡¹ç›®**:
- äººå½¢æœºå™¨äººå®¶æ”¿æœåŠ¡
- åŒè¶³æœºå™¨äººå¤æ‚åœ°å½¢è¡Œèµ°
- å·¥ä¸šåŒè‡‚æœºå™¨äººç²¾å¯†æ“ä½œ
- ç¾éš¾æ•‘æ´æœºå™¨äºº

---

## 7. æ€§èƒ½ä¸å¤æ‚åº¦

### 7.1 è®­ç»ƒå¤æ‚åº¦å¯¹æ¯”

| æŒ‡æ ‡ | Diffusion | Hierarchical |
|---|---|---|
| **å‚æ•°é‡** | ~15M | ~25M (+4å±‚ç½‘ç»œ) |
| **è®­ç»ƒæ—¶é—´/epoch** | 10åˆ†é’Ÿ | 15åˆ†é’Ÿ (+50%) |
| **æ”¶æ•›epochs** | 300-500 | 400-600 |
| **GPUå†…å­˜** | 12GB | 18GB |
| **éœ€è¦æ•°æ®** | é€šç”¨æ¼”ç¤º | é€šç”¨ + ä»»åŠ¡æ ‡æ³¨ |
| **å®ç°éš¾åº¦** | â­â­ | â­â­â­â­ |
| **è°ƒå‚éš¾åº¦** | â­â­ | â­â­â­â­â­ |

### 7.2 æ¨ç†æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | Diffusion | Hierarchical |
|---|---|---|
| **æ­£å¸¸æ¨ç†å»¶è¿Ÿ** | ~50ms | ~100ms |
| **ç´§æ€¥æ¨ç†å»¶è¿Ÿ** | ~50ms | <10ms âœ… |
| **CPUå ç”¨** | 40% | 60% |
| **æ¨ç†å‚æ•°é‡** | 15M | 25M (å¯é€‰æ‹©æ€§æ¿€æ´») |
| **å¯è§£é‡Šæ€§** | â­ | â­â­â­â­ |

### 7.3 å®é™…è¡¨ç°å¯¹æ¯” (å‡è®¾æ•°æ®)

**æµ‹è¯•ä»»åŠ¡**: äººå½¢æœºå™¨äººæŠ“å– + è¡Œèµ°

| æŒ‡æ ‡ | Diffusion | Hierarchical |
|---|---|---|
| **æˆåŠŸç‡** | 75% | 85% |
| **æ‘”å€’æ¬¡æ•°/100æ¬¡** | 5æ¬¡ | 0æ¬¡ âœ… |
| **ç´§æ€¥ååº”æ—¶é—´** | 50ms | <10ms âœ… |
| **åŠ¨ä½œå¹³æ»‘åº¦** | â­â­â­â­ | â­â­â­â­â­ |
| **ä»»åŠ¡é€‚åº”æ€§** | â­â­â­ | â­â­â­â­â­ |

---

## 8. å¦‚ä½•é€‰æ‹©

### 8.1 å†³ç­–æ ‘

```
å¼€å§‹
  â”‚
  â”œâ”€ æ˜¯å¦æ˜¯äººå½¢æœºå™¨äºº? â”€â”€â”€Noâ”€â”€â–º Diffusion Policy
  â”‚  Yes
  â”‚  â”‚
  â”‚  â”œâ”€ æ˜¯å¦éœ€è¦é«˜å®‰å…¨æ€§? â”€â”€â”€Noâ”€â”€â–º Diffusion Policy
  â”‚  â”‚  Yes
  â”‚  â”‚  â”‚
  â”‚  â”‚  â”œâ”€ æ˜¯å¦æœ‰å……è¶³çš„æ ‡æ³¨æ•°æ®? â”€â”€â”€Noâ”€â”€â–º Diffusion Policy (å…ˆ)
  â”‚  â”‚  â”‚  Yes
  â”‚  â”‚  â”‚  â”‚
  â”‚  â”‚  â”‚  â”œâ”€ å›¢é˜Ÿæ˜¯å¦æœ‰å¤æ‚ç³»ç»Ÿç»éªŒ? â”€â”€â”€Noâ”€â”€â–º Diffusion Policy (å»ºè®®)
  â”‚  â”‚  â”‚  â”‚  Yes
  â”‚  â”‚  â”‚  â”‚  â”‚
  â”‚  â”‚  â”‚  â”‚  â””â”€â–º Hierarchical Diffusion Policy âœ…
```

### 8.2 æ¸è¿›å¼ç­–ç•¥

**æ¨èè·¯å¾„**:
```
é˜¶æ®µ1: ç”¨Diffusion PolicyéªŒè¯åŸºç¡€å¯è¡Œæ€§
  â”œâ”€ æ”¶é›†æ•°æ®
  â”œâ”€ è®­ç»ƒåŸºç¡€æ¨¡å‹
  â”œâ”€ éªŒè¯ä»»åŠ¡å¯è¡Œæ€§
  â””â”€ è¯†åˆ«ç—›ç‚¹ (å¦‚: å®‰å…¨æ€§ã€ä»»åŠ¡åˆ‡æ¢)

é˜¶æ®µ2: è¯„ä¼°æ˜¯å¦éœ€è¦å‡çº§
  å¦‚æœé‡åˆ°ä»¥ä¸‹é—®é¢˜:
  â”œâ”€ å®‰å…¨æ€§ä¸è¶³
  â”œâ”€ å¤šä»»åŠ¡åˆ‡æ¢å›°éš¾
  â”œâ”€ ååº”é€Ÿåº¦ä¸å¤Ÿ
  â””â”€ éœ€è¦æ›´å¥½çš„å¯æ§æ€§

  â†’ è€ƒè™‘å‡çº§åˆ°Hierarchical

é˜¶æ®µ3: è¿ç§»åˆ°Hierarchical
  â”œâ”€ ä¿ç•™Diffusion Modelä½œä¸ºåº•å±‚
  â”œâ”€ é€æ­¥æ·»åŠ åˆ†å±‚
  â”œâ”€ è®¾è®¡è¯¾ç¨‹å­¦ä¹ 
  â””â”€ ç²¾ç»†è°ƒä¼˜
```

### 8.3 æ··åˆæ–¹æ¡ˆ

**å¯ä»¥åœ¨ä¸€ä¸ªé¡¹ç›®ä¸­åŒæ—¶ä½¿ç”¨**:
```yaml
# é…ç½®æ–‡ä»¶
policy:
  use_hierarchical: True  # æˆ– False

# ä»£ç è‡ªåŠ¨å…¼å®¹
if config.use_hierarchical:
    policy = HumanoidDiffusionPolicyWrapper(...)
    # ä½¿ç”¨åˆ†å±‚æ¶æ„
else:
    policy = CustomDiffusionPolicyWrapper(...)
    # ä½¿ç”¨æ™®é€šæ¶æ„

# ç”šè‡³å¯ä»¥åœ¨æ¨ç†æ—¶åŠ¨æ€åˆ‡æ¢
policy.set_hierarchical_mode(enable=True/False)
```

---

## 9. æ€»ç»“

### 9.1 æ ¸å¿ƒå·®å¼‚æ€»ç»“

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Diffusion Policy                           â”‚
â”‚  ä¸€ä¸ªå¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ + å¤šæ¨¡æ€èåˆ                              â”‚
â”‚  ç®€å•ã€ç›´æ¥ã€æ˜“ç”¨                                             â”‚
â”‚  é€‚åˆ: é€šç”¨æœºå™¨äººä»»åŠ¡                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hierarchical Diffusion Policy                   â”‚
â”‚  æ‰©æ•£æ¨¡å‹ + å››å±‚åˆ†å±‚æ¶æ„ + è¯¾ç¨‹å­¦ä¹                            â”‚
â”‚  å¤æ‚ã€å¼ºå¤§ã€å¯æ§                                             â”‚
â”‚  é€‚åˆ: äººå½¢æœºå™¨äººã€é«˜å®‰å…¨æ€§ã€å¤šä»»åŠ¡åœºæ™¯                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 å…³é”®takeaway

1. **ä¸æ˜¯æ›¿ä»£å…³ç³»**: Hierarchicalæ˜¯åœ¨DiffusionåŸºç¡€ä¸Šçš„æ‰©å±•
2. **Diffusionæ˜¯åº•å±‚**: ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„æ‰©æ•£æ¨¡å‹è¿›è¡ŒåŠ¨ä½œç”Ÿæˆ
3. **åˆ†å±‚æä¾›æ§åˆ¶**: é¢å¤–çš„å±‚æä¾›ä¼˜å…ˆçº§ã€å®‰å…¨æ€§ã€ä»»åŠ¡ç‰¹å®šä¼˜åŒ–
4. **å¯ä»¥å…±å­˜**: ä»£ç æ”¯æŒåœ¨ä¸¤ç§æ¨¡å¼é—´åˆ‡æ¢
5. **æ¸è¿›å¼é‡‡ç”¨**: å»ºè®®å…ˆç”¨DiffusionéªŒè¯ï¼Œå†å‡çº§åˆ°Hierarchical

---

**ç›¸å…³æ–‡æ¡£**:
- [Diffusion Policyæ¶æ„](diffusion_policy_architecture.md)
- [Hierarchical Policyæ¶æ„](hierarchical_policy_architecture.md)
- [Diffusionæ–‡æ¡£ç´¢å¼•](README_DIFFUSION.md)
- [Hierarchicalæ–‡æ¡£ç´¢å¼•](README.md)

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2025-10-10
**ä½œè€…**: AI Assistant

