hydra: # Hydra 配置文件保存目录，仅供参数检查使用
  run:
    dir: ./outputs/train_hydra_save/singlerun/${now:%Y%m%d_%H%M%S} # 单次运行目录
  sweep:
    dir: ./outputs/train_hydra_save/multirun/${now:%Y%m%d_%H%M%S} # sweep并行时的根目录
    subdir: ${hydra:job.override_dirname}

task: 'task_1_200_episodes' # 自定义任务名称，如果不使用本地数据想使用huggingface官方数据，请指定，例如pusht，aloha_sim_insertion_human等
method: 'act_bs64_usedepth_nofuse' # 自定义方法名称
timestamp: ${now:%Y%m%d_%H%M%S} # 自动获取的运行时时间戳
# 训练时模型参数的保存目录在outputs/train/<task>/<method>/<timestamp>中
repoid: 'lerobot/${task}' # lerobot新版本需指定这个，仅供参考，设置了即可
root: '/root/robot/data/task-1/1-200/lerobot' # 你的本地转换好的lerobot数据的目录
# root: null  # 如果不使用本地数据想使用huggingface官方数据，请在task中指定，例如pusht，aloha_sim_insertion_human，此处就设置为null空
# 将去云端调用下载数据集

# 训练相关配置
training:
  output_directory: 'outputs/train/${task}/${method}' # 模型参数保存路径，默认这个结构，不要改动
  seed: 2025 # 数据增广、训练模型的随机种子，便于复现
  max_epoch: 1000 # 最大训练轮次，用于控制学习率调整器，与下述max_training_step相关

  save_freq_epoch: 10 # 模型参数保存频率，每10个epoch保存一次
  log_freq: 1 # 进度条刷新频率，每1个迭代step
  device: 'cuda' # 训练设备，目前只支持单卡，多卡请使用CUDA_VISIBLE_DEVICES=6指定环境变量后使用，cuda:6这种类似的可能会出错
  accumulation_steps: 1 # 梯度累积步数，自定义
  ema_power: 0.75 # 如果使用ema移动指数平均方法可使用这个参数，目前测试使用ema会掉性能，所以代码中不再支持

  batch_size: 64 # 批次大小
  num_workers: 8 # dataloader的num_workers
  drop_last: False # 是否丢弃最后一个不完整的batch

  # 最大训练步数，用于控制学习率调整器，如果指定了 `max_training_step`，则它将优先生效，否则，该值将根据上述的 `max_epoch` 自动确定。
  # `max_epoch` 和 `max_training_step` 不会同时生效。
  max_training_step: null

  # resume training，断点续训
  resume: False
  resume_timestamp: 'run_20250826_181254' # 若开启，将从outputs/train/<task>/<method>/<resume_timestamp>中加载最后一个epoch参数续训

  scheduler_name: cosine # 学习率调整器名称，仅在policy config中不包含该调度器时生效，否则会使用policy自带的调整器，相关参数也会在下方policy里
  scheduler_warmup_steps: 500 # 学习率预热warm up步数

  # 数据增广相关的配置
  RGB_Augmenter:
    enable: True
    max_num_transforms: 1
    random_order: True
    tfs:
      notransform:
        weight: 2.0 # 占比权重
        type: 'Identity'
        kwargs: {}
      brightness:
        weight: 1.0
        type: 'ColorJitter'
        kwargs: { 'brightness': [0.5, 1.5] }
      contrast:
        weight: 1.0
        type: 'ColorJitter'
        kwargs: { 'contrast': [0.5, 1.5] }
      saturation:
        weight: 1.0
        type: 'ColorJitter'
        kwargs: { 'saturation': [0.5, 1.5] }
      hue:
        weight: 1.0
        type: 'ColorJitter'
        kwargs: { 'hue': [-0.05, 0.05] }
      sharpness:
        weight: 1.0
        type: 'SharpnessJitter'
        kwargs: { 'sharpness': [0.5, 1.5] }
      random_mask:
        weight: 1.0
        type: RandomMask
        kwargs:
          mask_size: [0.1, 0.1] # h_ratio, w_ratio
      random_border_cutout:
        weight: 1.0
        type: RandomBorderCutout
        kwargs:
          cut_ratio: 0.15
      gaussian_noise:
        weight: 1.0
        type: GaussianNoise
        kwargs:
          mean: 0.0
          std: 0.05
      gamma_correction:
        weight: 1.0
        type: GammaCorrection
        kwargs:
          gamma: [0.5, 2.0]

policy_name: act # 策略类型，支持diffusion和act

# 策略相关
policy:
  _target_: lerobot.policies.act.configuration_act.ACTConfig # 用于实例化
  n_obs_steps: 1 # 观测步数
  chunk_size: 100 # 动作块大小
  n_action_steps: 1 # 动作步数

  use_amp: False # 是否使用混合精度训练

  # 模型超参数相关调整
  vision_backbone: resnet18
  pretrained_backbone_weights: ResNet18_Weights.IMAGENET1K_V1
  replace_final_stride_with_dilation: False
  # Transformer layers.
  pre_norm: False
  dim_model: 512
  n_heads: 8
  dim_feedforward: 3200
  feedforward_activation: relu
  n_encoder_layers: 4
  # Note: Although the original ACT implementation has 7 for `n_decoder_layers`, there is a bug in the code
  # that means only the first layer is used. Here we match the original implementation by setting this to 1.
  # See this issue https://github.com/tonyzhaozh/act/issues/25#issue-2258740521.
  n_decoder_layers: 1
  # VAE.
  use_vae: True
  latent_dim: 32
  n_vae_encoder_layers: 4

  # Inference.
  # Note: the value used in ACT when temporal ensembling is enabled is 0.01.
  temporal_ensemble_coeff: -0.1

  # Training and loss computation.
  dropout: 0.1
  kl_weight: 10.0

  # Training preset
  optimizer_lr: 1e-5
  optimizer_weight_decay: 1e-4
  optimizer_lr_backbone: 1e-5
