hydra: # Hydra configuration directory
  run:
    dir: ./outputs/kuavo_smolvla_sim_deploy_hydra_save/singlerun/${now:%Y%m%d_%H%M%S}
  sweep:
    dir: ./outputs/kuavo_smolvla_sim_deploy_hydra_save/multirun/${now:%Y%m%d_%H%M%S}
    subdir: ${hydra:job.override_dirname}

# ==================== SmolVLA Simulation Environment Configuration ====================
# This config is for deploying SmolVLA sequential multi-task models in simulation

# ==================== HuggingFace Configuration ====================
# Set HuggingFace download mirror (optional)
# If not set, uses default HuggingFace Hub (https://huggingface.co)
# Common mirrors:
#   - China mirror: https://hf-mirror.com
#   - Leave commented out to use default
hf_endpoint: 'https://hf-mirror.com' # Uncomment and modify if needed

# Environment config
real: false # Simulation environment
only_arm: true # Only use arm data
eef_type: rq2f85 # End-effector type: rq2f85 for simulation
control_mode: joint # Joint control mode
which_arm: both # Which arm: left, right, both
head_init: [0, 0.209] # Robot head initial position

# Input images: must match training configuration
# SmolVLA uses pure RGB approach (depth not natively supported)
input_images: ['head_cam_h', 'wrist_cam_l', 'wrist_cam_r']
# depth_range: [0, 1000] # Depth image clipping range (mm) - Not used in RGB-only mode
image_size: [480, 640] # Original ROS topic image size
target_image_size: [512, 512] # SmolVLA requires 512x512 (NOT 224x224!)
ros_rate: 10 # Inference frequency (Hz)

# End-effector DOF configuration
qiangnao_dof_needed: 1
leju_claw_dof_needed: 1
rq2f85_dof_needed: 1

# Arm initialization and limits
arm_init: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] # Arm initial position
arm_min:
  [
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
    -180,
  ]
arm_max: [180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180]

eef_min: [0]
eef_max: [1]

is_binary: false

# ==================== SmolVLA Inference Configuration ====================
go_bag_path: /your_bag_path # Provide full bag path for inference

policy_type: 'smolvla' # SmolVLA sequential policy
use_delta: false # Delta action (not supported yet)
eval_episodes: 100 # Number of evaluation episodes
seed: 42 # Random seed
start_seed: 42 # Episode start seed
device: 'cuda' # or "cpu"

# ==================== Model Path Configuration ====================
# Points to SmolVLA sequential training outputs

# Task selection: Change this to evaluate different tasks
# Options:
#   - task1_moving_grasp: Moving target grasping from conveyor belt
#   - task2_weighing: Package weighing
#   - task3_placement: Daily chemical product placement
#   - task4_sorting: Full process sorting
task: 'task1_moving_grasp'
method: 'smolvla_sequential'
timestamp: 'run_20251104_082205' # Your actual training timestamp
epoch: 18 # Test epoch 10 model (loss ~0.02)

# ==================== Language Instruction Configuration ====================
# SmolVLA uses language instructions to condition the policy
# Change this based on which task you're evaluating

# Task 1: Moving target grasping
# language_instruction: 'Grasp the object from the moving conveyor belt using visual guidance. Place it precisely at the center of the first colored target block on the table, ensuring the object center aligns with the target center. Then grasp it again and place it precisely at the center of the second colored target block on the table, maintaining visual alignment throughout the placement.'

# Task 2: Package weighing (uncomment to use)
language_instruction:  'Grasp the package from the moving conveyor belt and place it precisely at the center of the electronic scale with correct orientation for weighing. Then grasp it again and place it precisely at the center of the designated storage container with correct final orientation.'

# Task 3: Product placement (uncomment to use)
# language_instruction: "Pick up the daily chemical product bottle, transfer it to the other hand, and place it in the designated location with the label facing up"

# Task 4: Full process sorting (uncomment to use)
# language_instruction: "Move from the starting position, pick up the workpiece, move to the designated location and place it precisely"

# ==================== Multi-Task Evaluation Configuration ====================
# For evaluating all 4 tasks sequentially, use this configuration

# Enable multi-task evaluation (optional)
multi_task_eval: false # Set to true to evaluate all tasks

# If multi_task_eval is true, define tasks to evaluate
tasks_to_evaluate:
  - task_id: 1
    task_name: 'task1_moving_grasp'
    language_instruction: 'Pick up the moving object from the conveyor belt, place it on the table, and push it to the designated area'
    episodes: 10
  - task_id: 2
    task_name: 'task2_weighing'
    language_instruction: 'Pick up the package from the conveyor belt, weigh it on the electronic scale, then pick it up again and place it in the designated storage container'
    episodes: 10
  - task_id: 3
    task_name: 'task3_placement'
    language_instruction: 'Pick up the daily chemical product bottle, transfer it to the other hand, and place it in the designated location with the label facing up'
    episodes: 10
  - task_id: 4
    task_name: 'task4_sorting'
    language_instruction: 'Move from the starting position, pick up the workpiece, move to the designated location and place it precisely'
    episodes: 10

# ==================== Environment Configuration ====================
max_episode_steps: 300 # Maximum episode steps
env_name: Kuavo-Sim # Kuavo SmolVLA simulation environment name

# ==================== Inference Optimization ====================
# Reduce sampling steps for faster inference
num_inference_steps: 40 # Default is 60, recommended: 20-30 for 3x speedup

# ==================== SmolVLA Specific Notes ====================
# 1. Image size MUST be 512x512 (SmolVLA requirement)
# 2. RGB-only configuration (3 cameras): head_cam_h, wrist_cam_l, wrist_cam_r
# 3. Policy outputs 50-frame action chunks, but only first step is executed
# 4. Action dimension is 32D, but only first 16D are used for Kuavo control
# 5. Language instruction is REQUIRED for SmolVLA inference
# 6. To evaluate different tasks, change both 'task' and 'language_instruction'
# 7. Model path format: outputs/train/smolvla_sequential/task{N}_{name}/best
# 8. Depth images are not used as SmolVLA's SigLIP encoder only supports RGB
# 9. num_inference_steps controls Flow Matching sampling steps (lower = faster, but may reduce quality)
