"""
HumanoidDiffusionPolicy: åˆ†å±‚äººå½¢æœºå™¨äººDiffusion Policyä¸»å…¥å£
"""
import torch
import torch.nn as nn
from typing import Dict, Any, Optional, Tuple
from pathlib import Path

# å¯¼å…¥åŸæœ‰çš„ç»„ä»¶
from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy
from kuavo_train.wrapper.policy.diffusion.DiffusionPolicyWrapper import CustomDiffusionPolicyWrapper
from kuavo_train.wrapper.policy.diffusion.DiffusionConfigWrapper import CustomDiffusionConfigWrapper

# å¯¼å…¥åˆ†å±‚æ¶æ„ç»„ä»¶
from .HierarchicalScheduler import HierarchicalScheduler
from .HierarchicalDiffusionModel import HierarchicalDiffusionModel


class HumanoidDiffusionPolicyWrapper(CustomDiffusionPolicyWrapper):
    """
    åˆ†å±‚äººå½¢æœºå™¨äººDiffusion Policy

    ç»§æ‰¿è‡ªCustomDiffusionPolicyWrapperä»¥ä¿æŒå‘åå…¼å®¹æ€§
    æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©ä½¿ç”¨åˆ†å±‚æ¶æ„æˆ–ä¼ ç»Ÿæ¶æ„
    """

    def __init__(self,
                 config: CustomDiffusionConfigWrapper,
                 dataset_stats: Optional[Dict[str, Dict[str, torch.Tensor]]] = None):
        """
        åˆå§‹åŒ–åˆ†å±‚Diffusion Policy

        Args:
            config: é…ç½®å¯¹è±¡
            dataset_stats: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†å±‚æ¶æ„
        self.use_hierarchical = getattr(config, 'use_hierarchical', False)

        if self.use_hierarchical:
            # ä½¿ç”¨åˆ†å±‚æ¶æ„
            super().__init__(config, dataset_stats)
            self._init_hierarchical_components(config)
        else:
            # å‘åå…¼å®¹ï¼šä½¿ç”¨åŸæœ‰æ¶æ„
            super().__init__(config, dataset_stats)
            self.scheduler = None

    def _init_hierarchical_components(self, config):
        """åˆå§‹åŒ–åˆ†å±‚æ¶æ„ç»„ä»¶"""
        try:
            # æ›¿æ¢åŸæœ‰çš„diffusionæ¨¡å‹ä¸ºåˆ†å±‚ç‰ˆæœ¬
            self.diffusion = HierarchicalDiffusionModel(config)

            # åˆ›å»ºåˆ†å±‚è°ƒåº¦å™¨
            hierarchical_config = getattr(config, 'hierarchical', {})
            self.scheduler = HierarchicalScheduler(hierarchical_config, config)

            print(f"âœ… Hierarchical architecture initialized with {len(self.scheduler.layers)} layers")

        except Exception as e:
            print(f"âŒ Failed to initialize hierarchical components: {e}")
            print("ğŸ”„ Falling back to traditional architecture")
            self.use_hierarchical = False
            self.scheduler = None

    def forward(self, batch: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, Optional[Dict[str, Any]]]:
        """
        å‰å‘ä¼ æ’­ï¼Œæ ¹æ®æ¶æ„ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼

        Args:
            batch: è¾“å…¥æ‰¹æ¬¡æ•°æ®

        Returns:
            Tuple[loss, outputs]: æŸå¤±å’Œè¾“å‡ºç»“æœ
        """
        if self.use_hierarchical and self.scheduler is not None:
            return self._hierarchical_forward(batch)
        else:
            return super().forward(batch)

    def _hierarchical_forward(self, batch: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """åˆ†å±‚æ¶æ„çš„å‰å‘ä¼ æ’­"""
        # å›¾åƒé¢„å¤„ç†ï¼ˆä¿æŒä¸åŸæœ‰é€»è¾‘ä¸€è‡´ï¼‰
        batch = self._preprocess_batch(batch)

        # å½’ä¸€åŒ–è¾“å…¥å’Œç›®æ ‡
        batch = self.normalize_inputs(batch)
        batch = self.normalize_targets(batch)

        # ä»»åŠ¡è¯†åˆ«
        task_info = self._identify_task(batch)

        # åˆ†å±‚å¤„ç†
        layer_outputs = self.scheduler(batch, task_info)

        # DiffusionæŸå¤±è®¡ç®—
        diffusion_loss = self.diffusion.compute_loss(batch, layer_outputs)

        # åˆ†å±‚æŸå¤±èšåˆ
        total_loss = self._aggregate_hierarchical_loss(diffusion_loss, layer_outputs)

        return total_loss, layer_outputs

    def _preprocess_batch(self, batch: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆå›¾åƒè£å‰ªã€ç¼©æ”¾ç­‰ï¼‰"""
        # å¤ç”¨åŸæœ‰çš„å›¾åƒé¢„å¤„ç†é€»è¾‘
        random_crop = self.config.crop_is_random and self.training
        crop_position = None

        # RGBå›¾åƒé¢„å¤„ç†
        if self.config.image_features:
            batch = dict(batch)  # shallow copy
            for key in self.config.image_features:
                from kuavo_train.utils.augmenter import crop_image, resize_image
                batch[key], crop_position = crop_image(
                    batch[key],
                    target_range=self.config.crop_shape,
                    random_crop=random_crop
                )
                batch[key] = resize_image(
                    batch[key],
                    target_size=self.config.resize_shape,
                    image_type="rgb"
                )

            # å †å RGBç‰¹å¾
            from lerobot.constants import OBS_IMAGES
            batch[OBS_IMAGES] = torch.stack([batch[key] for key in self.config.image_features], dim=-4)

        # æ·±åº¦å›¾åƒé¢„å¤„ç†
        if self.config.use_depth and self.config.depth_features:
            batch = dict(batch)
            for key in self.config.depth_features:
                import torchvision.transforms.functional as TF
                if len(crop_position) == 4:
                    batch[key] = TF.crop(batch[key], *crop_position)
                else:
                    batch[key] = TF.center_crop(batch[key], crop_position)

                from kuavo_train.utils.augmenter import resize_image
                batch[key] = resize_image(
                    batch[key],
                    target_size=self.config.resize_shape,
                    image_type="depth"
                )

            # å †å æ·±åº¦ç‰¹å¾
            OBS_DEPTH = "observation.depth"
            batch[OBS_DEPTH] = torch.stack([batch[key] for key in self.config.depth_features], dim=-4)

        return batch

    def _identify_task(self, batch: Dict[str, torch.Tensor]) -> Dict[str, Any]:
        """ä»»åŠ¡è¯†åˆ«ï¼ˆç›®å‰ç®€åŒ–ä¸ºåŸºäºé…ç½®çš„é™æ€è¯†åˆ«ï¼‰"""
        # TODO: å®ç°åŸºäºè¾“å…¥æ•°æ®çš„åŠ¨æ€ä»»åŠ¡è¯†åˆ«
        return {
            'task_type': 'general',
            'task_complexity': 'medium',
            'requires_locomotion': True,
            'requires_manipulation': True,
            'requires_planning': False  # é»˜è®¤ä¸å¯ç”¨æœ€å¤æ‚çš„è§„åˆ’å±‚
        }

    def _aggregate_hierarchical_loss(self,
                                   diffusion_loss: torch.Tensor,
                                   layer_outputs: Dict[str, Any]) -> torch.Tensor:
        """èšåˆåˆ†å±‚æŸå¤±"""
        total_loss = diffusion_loss

        # è·å–å±‚æƒé‡é…ç½®
        layer_weights = getattr(self.scheduler.config, 'layer_weights', {})

        # èšåˆå„å±‚çš„æŸå¤±
        for layer_name, layer_output in layer_outputs.items():
            if isinstance(layer_output, dict) and 'loss' in layer_output:
                layer_weight = layer_weights.get(layer_name, 1.0)
                total_loss = total_loss + layer_weight * layer_output['loss']

        return total_loss

    def select_action(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        é€‰æ‹©åŠ¨ä½œï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰

        Args:
            batch: è§‚æµ‹æ•°æ®

        Returns:
            torch.Tensor: é€‰æ‹©çš„åŠ¨ä½œ
        """
        if self.use_hierarchical and self.scheduler is not None:
            return self._hierarchical_select_action(batch)
        else:
            return super().select_action(batch)

    def _hierarchical_select_action(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:
        """åˆ†å±‚æ¶æ„çš„åŠ¨ä½œé€‰æ‹©"""
        # é¢„å¤„ç†
        batch = self._preprocess_batch(batch)
        batch = self.normalize_inputs(batch)

        # ä»»åŠ¡è¯†åˆ«
        task_info = self._identify_task(batch)

        # åˆ†å±‚æ¨ç†ï¼ˆå¯èƒ½åªæ¿€æ´»éƒ¨åˆ†å±‚ä»¥æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼‰
        with torch.no_grad():
            layer_outputs = self.scheduler.inference_mode(batch, task_info)

        # ä»åˆ†å±‚è¾“å‡ºä¸­æå–æœ€ç»ˆåŠ¨ä½œ
        return self._extract_action_from_layers(layer_outputs, batch)

    def _extract_action_from_layers(self,
                                  layer_outputs: Dict[str, Any],
                                  batch: Dict[str, torch.Tensor]) -> torch.Tensor:
        """ä»åˆ†å±‚è¾“å‡ºä¸­æå–æœ€ç»ˆåŠ¨ä½œ"""
        # ä¼˜å…ˆçº§å¤„ç†ï¼šå®‰å…¨å±‚å¯ä»¥è¦†ç›–å…¶ä»–å±‚çš„è¾“å‡º
        if 'safety' in layer_outputs and layer_outputs['safety'].get('emergency', False):
            return layer_outputs['safety'].get('emergency_action', torch.zeros_like(batch.get('action', torch.zeros(1, 32))))

        # æ­£å¸¸æƒ…å†µä¸‹ï¼Œä½¿ç”¨æœ€é«˜çº§åˆ«å¯ç”¨å±‚çš„è¾“å‡º
        for layer_name in ['planning', 'manipulation', 'gait', 'safety']:
            if layer_name in layer_outputs and 'action' in layer_outputs[layer_name]:
                return layer_outputs[layer_name]['action']

        # å›é€€ï¼šä½¿ç”¨ä¼ ç»Ÿdiffusionè¾“å‡º
        return super().select_action(batch)

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if self.use_hierarchical and self.scheduler is not None:
            return self.scheduler.get_performance_stats()
        else:
            return {'architecture': 'traditional', 'hierarchical_enabled': False}

    def set_layer_enabled(self, layer_name: str, enabled: bool):
        """åŠ¨æ€å¯ç”¨/ç¦ç”¨ç‰¹å®šå±‚"""
        if self.use_hierarchical and self.scheduler is not None:
            self.scheduler.set_layer_enabled(layer_name, enabled)

    def get_active_layers(self) -> List[str]:
        """è·å–å½“å‰æ¿€æ´»çš„å±‚åˆ—è¡¨"""
        if self.use_hierarchical and self.scheduler is not None:
            return self.scheduler.get_active_layers()
        else:
            return ['traditional']

    @classmethod
    def from_pretrained(cls, *args, **kwargs):
        """ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ï¼ˆä¿æŒä¸çˆ¶ç±»æ¥å£å…¼å®¹ï¼‰"""
        # TODO: å®ç°åˆ†å±‚æ¶æ„çš„æ¨¡å‹åŠ è½½é€»è¾‘
        return super().from_pretrained(*args, **kwargs)