"""
ActionTokenizer: å®ç°åŠ¨ä½œç©ºé—´å’Œtokenç©ºé—´çš„åŒå‘è½¬æ¢
"""
import torch
import torch.nn as nn
from typing import Optional


class ActionTokenizer(nn.Module):
    """
    åŠ¨ä½œTokenåŒ–å™¨ï¼šå®ç°åŠ¨ä½œâ†”tokensçš„åŒå‘è½¬æ¢

    æ ¸å¿ƒä½œç”¨ï¼š
    1. tokenize(): è®­ç»ƒæ—¶å°†çœŸå®åŠ¨ä½œè½¬ä¸ºtokensï¼ˆç”¨äºåŠ å™ªå£°å­¦ä¹ ï¼‰
    2. detokenize(): æ¨ç†æ—¶å°†å»å™ªåçš„tokensè½¬å›åŠ¨ä½œ

    è®¾è®¡æ€è·¯ï¼š
    - æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹ç¼–ç ï¼ˆå› ä¸ºdiffusionåœ¨æ—¶é—´ç»´åº¦å¤„ç†ï¼‰
    - ä½¿ç”¨æ—¶é—´æ­¥embeddingåŒºåˆ†ä¸åŒæ—¶åˆ»
    - ç¼–ç å™¨å’Œè§£ç å™¨åˆ†ç¦»ï¼Œæ”¯æŒåœ¨tokenç©ºé—´åšdiffusion
    """

    def __init__(self, action_dim: int, horizon: int, embed_dim: int = 512):
        """
        Args:
            action_dim: åŠ¨ä½œç»´åº¦ï¼ˆä»é…ç½®è¯»å–ï¼Œæ”¯æŒ16/36ç­‰ï¼‰
            horizon: åŠ¨ä½œåºåˆ—é•¿åº¦
            embed_dim: Token embeddingç»´åº¦
        """
        super().__init__()

        self.action_dim = action_dim
        self.horizon = horizon
        self.embed_dim = embed_dim

        # ç¼–ç å™¨ï¼šåŠ¨ä½œ â†’ tokensï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
        # æ‰€æœ‰æ—¶é—´æ­¥å…±äº«åŒä¸€ä¸ªç¼–ç å™¨
        self.action_encoder = nn.Sequential(
            nn.Linear(action_dim, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.ReLU(),
            nn.Linear(embed_dim, embed_dim),
            nn.LayerNorm(embed_dim)
        )

        # è§£ç å™¨ï¼štokens â†’ åŠ¨ä½œï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
        # æ‰€æœ‰æ—¶é—´æ­¥å…±äº«è§£ç å™¨
        self.action_decoder = nn.Sequential(
            nn.Linear(embed_dim, embed_dim),
            nn.ReLU(),
            nn.Linear(embed_dim, action_dim)
        )

        # æ—¶é—´æ­¥embedding
        self.time_embedding = nn.Embedding(horizon, embed_dim)

        print(
            f"âœ… ActionTokenizer initialized: {action_dim}D actions, {horizon} timesteps, {embed_dim}D tokens")

    def tokenize(self, actions: torch.Tensor) -> torch.Tensor:
        """
        è®­ç»ƒæ—¶ï¼šåŠ¨ä½œåºåˆ— â†’ tokenåºåˆ—

        Args:
            actions: [B, horizon, action_dim] ç›®æ ‡åŠ¨ä½œåºåˆ—

        Returns:
            tokens: [B, horizon, embed_dim] action tokens
        """
        batch_size, horizon, action_dim = actions.shape
        device = actions.device

        assert horizon == self.horizon, f"Expected horizon {self.horizon}, got {horizon}"
        assert action_dim == self.action_dim, f"Expected action_dim {self.action_dim}, got {action_dim}"

        # ä½¿ç”¨å…±äº«ç¼–ç å™¨ç¼–ç æ‰€æœ‰æ—¶é—´æ­¥
        tokens = self.action_encoder(actions)  # [B, horizon, embed_dim]

        # æ·»åŠ æ—¶é—´æ­¥embeddingï¼ˆå¹¿æ’­æ–¹å¼ï¼‰
        time_ids = torch.arange(horizon, device=device)  # [horizon]
        time_embeds = self.time_embedding(time_ids)  # [horizon, embed_dim]
        tokens = tokens + time_embeds.unsqueeze(0)  # [B, horizon, embed_dim] + [1, horizon, embed_dim]

        return tokens

    def detokenize(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        æ¨ç†æ—¶ï¼štokenåºåˆ— â†’ åŠ¨ä½œåºåˆ—

        Args:
            tokens: [B, horizon, embed_dim] å»å™ªåçš„action tokens

        Returns:
            actions: [B, horizon, action_dim] é¢„æµ‹çš„åŠ¨ä½œåºåˆ—
        """
        batch_size, horizon, embed_dim = tokens.shape

        assert horizon == self.horizon, f"Expected horizon {self.horizon}, got {horizon}"
        assert embed_dim == self.embed_dim, f"Expected embed_dim {self.embed_dim}, got {embed_dim}"

        # è§£ç æ‰€æœ‰tokensï¼ˆå…±äº«è§£ç å™¨ï¼‰
        actions = self.action_decoder(tokens)  # [B, horizon, action_dim]

        return actions

    def expand_action_dim(self, new_action_dim: int, freeze_old_weights: bool = True):
        """
        æ‰©å±•åŠ¨ä½œç»´åº¦ï¼ˆä¾‹å¦‚ä»16ç»´åˆ°36ç»´ï¼‰

        ç­–ç•¥ï¼š
        - ç¼–ç å™¨ï¼šé‡æ–°åˆå§‹åŒ–ï¼ˆå› ä¸ºè¾“å…¥ç»´åº¦å˜äº†ï¼‰
        - è§£ç å™¨ï¼šå‰Nç»´å¤ç”¨æƒé‡ï¼Œæ–°ç»´åº¦éšæœºåˆå§‹åŒ–

        Args:
            new_action_dim: æ–°çš„åŠ¨ä½œç»´åº¦
            freeze_old_weights: æ˜¯å¦å†»ç»“æ—§æƒé‡
        """
        if new_action_dim == self.action_dim:
            print(
                f"âš ï¸  Action dimension already {new_action_dim}, no expansion needed")
            return

        print(
            f"ğŸ”§ Expanding ActionTokenizer: {self.action_dim}D â†’ {new_action_dim}D")

        old_action_dim = self.action_dim

        # 1. æ‰©å±•è§£ç å™¨
        # Linear(embed_dim, old_action_dim)
        old_decoder_final_layer = self.action_decoder[-1]
        # [old_action_dim, embed_dim]
        old_weight = old_decoder_final_layer.weight.data
        old_bias = old_decoder_final_layer.bias.data      # [old_action_dim]

        # åˆ›å»ºæ–°çš„è§£ç å™¨æœ€åä¸€å±‚
        new_final_layer = nn.Linear(self.embed_dim, new_action_dim)

        # å¤ç”¨å‰old_action_dimç»´çš„æƒé‡
        new_final_layer.weight.data[:old_action_dim] = old_weight
        new_final_layer.bias.data[:old_action_dim] = old_bias

        # æ–°ç»´åº¦éšæœºåˆå§‹åŒ–ï¼ˆå·²ç»ç”±PyTorché»˜è®¤å®Œæˆï¼‰

        # æ›¿æ¢è§£ç å™¨æœ€åä¸€å±‚
        self.action_decoder[-1] = new_final_layer

        # 2. é‡æ–°åˆå§‹åŒ–ç¼–ç å™¨ï¼ˆå› ä¸ºè¾“å…¥ç»´åº¦å˜äº†ï¼‰
        self.action_encoder = nn.Sequential(
            nn.Linear(new_action_dim, self.embed_dim),
            nn.LayerNorm(self.embed_dim),
            nn.ReLU(),
            nn.Linear(self.embed_dim, self.embed_dim),
            nn.LayerNorm(self.embed_dim)
        )

        # 3. å¯é€‰ï¼šå†»ç»“è§£ç å™¨çš„æ—§æƒé‡
        if freeze_old_weights:
            # éƒ¨åˆ†å†»ç»“è§£ç å™¨ï¼ˆåªå†»ç»“å‰old_action_dimç»´çš„è¾“å‡ºæƒé‡ï¼‰
            # æ³¨æ„ï¼šPyTorchä¸æ”¯æŒéƒ¨åˆ†æƒé‡å†»ç»“ï¼Œè¿™é‡Œåªæ˜¯æ ‡è®°
            print(f"ğŸ’¡ Consider fine-tuning with small learning rate for old dimensions")

        self.action_dim = new_action_dim

        print(f"âœ… ActionTokenizer expanded to {new_action_dim}D")
