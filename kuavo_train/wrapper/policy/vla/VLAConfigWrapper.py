"""
VLAConfigWrapper: VLAç­–ç•¥çš„é…ç½®ç±»
"""
from typing import Any, Dict, Union, Tuple
from dataclasses import dataclass, field
from kuavo_train.wrapper.policy.diffusion.DiffusionConfigWrapper import CustomDiffusionConfigWrapper
from lerobot.configs.policies import PreTrainedConfig


@PreTrainedConfig.register_subclass("vla_transformer")
@dataclass
class VLAConfigWrapper(CustomDiffusionConfigWrapper):
    """
    VLA Transformerç­–ç•¥é…ç½®

    ç»§æ‰¿è‡ªCustomDiffusionConfigWrapperä»¥å¤ç”¨diffusionç›¸å…³é…ç½®
    """

    # TokenåŒ–é…ç½®ï¼ˆä¼˜åŒ–åçš„é»˜è®¤å€¼ï¼‰
    patch_size: int = 32  # Vision patchå¤§å°ï¼ˆä»16å¢å¤§åˆ°32ï¼‰
    token_embed_dim: int = 256  # ç»Ÿä¸€tokenç»´åº¦ï¼ˆä»512é™åˆ°256ï¼‰
    image_size: Union[int, Tuple[int, int]] = (192, 256)  # è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆä¿æŒ3:4å®½é«˜æ¯”ï¼‰
    use_pretrained_patches: bool = True  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒpatch embeddings

    # Transformer Encoderé…ç½®
    transformer_depth: int = 6  # Encoderå±‚æ•°ï¼ˆä»8é™åˆ°6ï¼‰
    transformer_heads: int = 8  # æ³¨æ„åŠ›å¤´æ•°
    transformer_dim_feedforward: int = 1024  # FFNç»´åº¦ï¼ˆä»2048é™åˆ°1024ï¼‰
    transformer_dropout: float = 0.25  # Dropoutç‡ï¼ˆä»0.1å¢åŠ åˆ°0.25ï¼‰

    # Diffusion Decoderé…ç½®
    num_denoiser_layers: int = 3  # Decoderå±‚æ•°ï¼ˆä»4é™åˆ°3ï¼‰
    denoiser_heads: int = 8  # Decoderæ³¨æ„åŠ›å¤´æ•°
    denoiser_dim_feedforward: int = 1024  # Decoder FFNç»´åº¦ï¼ˆä»2048é™åˆ°1024ï¼‰

    # Stateé…ç½®ï¼ˆæ ¸å¿ƒï¼‰
    state_config: Dict[str, Any] = field(default_factory=dict)

    # å›¾åƒå’Œè®­ç»ƒé…ç½®
    use_depth: bool = True  # æ˜¯å¦ä½¿ç”¨æ·±åº¦å›¾åƒ
    use_amp: bool = True  # æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆè®­ç»ƒè„šæœ¬ä½¿ç”¨ï¼‰

    # æ¶æ„é…ç½®ï¼ˆç”¨äºä¼˜åŒ–å™¨é€‰æ‹©ï¼‰
    use_unet: bool = False  # VLAä½¿ç”¨Transformerï¼Œä¸ä½¿ç”¨UNet
    use_transformer: bool = True  # VLAä½¿ç”¨Transformeræ¶æ„

    def __post_init__(self):
        """ååˆå§‹åŒ–å¤„ç†"""
        super().__post_init__()

        # éªŒè¯state_config
        if 'joints' not in self.state_config:
            print(
                "âš ï¸  Warning: state_config missing 'joints' key. Using empty joint list.")
            self.state_config['joints'] = []

        # æ‰“å°é…ç½®æ‘˜è¦
        num_joints = len(self.state_config.get('joints', []))
        print(f"ğŸ“‹ VLA Config Summary:")
        print(f"   - Token dimension: {self.token_embed_dim}")
        print(f"   - Transformer depth: {self.transformer_depth}")
        print(f"   - Number of joints: {num_joints}")
        print(f"   - Action horizon: {self.horizon}")
        print(f"   - Diffusion steps: {self.num_train_timesteps}")
