"""
Flow Matching Scheduler for Robot Control
åŸºäºæœ€ä¼˜ä¼ è¾“çš„æµåŒ¹é…è°ƒåº¦å™¨ï¼Œå¯æ›¿ä»£ä¼ ç»Ÿ Diffusion è°ƒåº¦å™¨

å‚è€ƒ:
- Flow Matching for Generative Modeling (Lipman et al., 2023)
- Rectified Flow (Liu et al., 2022)
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import Optional, Union, Tuple
from enum import Enum


class FlowMatchingType(Enum):
    """Flow Matching ç±»å‹"""
    CONDITIONAL = "conditional"  # æ¡ä»¶æµåŒ¹é…ï¼ˆé»˜è®¤ï¼‰
    OPTIMAL_TRANSPORT = "optimal_transport"  # æœ€ä¼˜ä¼ è¾“æµåŒ¹é…
    RECTIFIED = "rectified"  # ä¿®æ­£æµ


class FlowMatchingScheduler:
    """
    Flow Matching è°ƒåº¦å™¨

    ç›¸æ¯” DDPM/DDIM:
    - ä½¿ç”¨ ODE è€Œé SDE
    - è®­ç»ƒæ—¶é—´æ­¥ä¸ºè¿ç»­ [0, 1] è€Œéç¦»æ•£ [0, T]
    - é¢„æµ‹é€Ÿåº¦åœº v_t è€Œéå™ªå£° Îµ
    - æ¨ç†æ­¥æ•°å¯ä»¥å¤§å¹…å‡å°‘ï¼ˆ10-20æ­¥ï¼‰

    è®­ç»ƒè¿‡ç¨‹:
    1. é‡‡æ · t ~ U[0, 1]
    2. è®¡ç®—æ’å€¼: x_t = (1-t)Â·x_0 + tÂ·x_1
    3. è®¡ç®—ç›®æ ‡é€Ÿåº¦: v_t = x_1 - x_0
    4. è®­ç»ƒæ¨¡å‹é¢„æµ‹ v_t

    æ¨ç†è¿‡ç¨‹:
    1. ä» x_0 ~ N(0, I) å¼€å§‹
    2. ä½¿ç”¨ ODE æ±‚è§£å™¨ï¼ˆEuler/RK4ï¼‰ç§¯åˆ†
    3. å¾—åˆ° x_1ï¼ˆç”Ÿæˆçš„åŠ¨ä½œï¼‰
    """

    def __init__(
        self,
        num_inference_steps: int = 10,
        flow_matching_type: str = "conditional",
        sigma: float = 0.0,  # å™ªå£°æ°´å¹³ï¼ˆ0è¡¨ç¤ºç¡®å®šæ€§æµï¼‰
        use_ode_solver: str = "euler",  # "euler" æˆ– "rk4"
        device: Union[str, torch.device] = "cpu",
    ):
        """
        åˆå§‹åŒ– Flow Matching è°ƒåº¦å™¨

        Args:
            num_inference_steps: æ¨ç†æ­¥æ•°ï¼ˆé€šå¸¸10-20æ­¥å³å¯ï¼‰
            flow_matching_type: æµåŒ¹é…ç±»å‹
            sigma: å™ªå£°æ°´å¹³ï¼ˆç”¨äºéšæœºæµåŒ¹é…ï¼‰
            use_ode_solver: ODE æ±‚è§£å™¨ç±»å‹
            device: è®¾å¤‡
        """
        self.num_inference_steps = num_inference_steps
        self.flow_matching_type = FlowMatchingType(flow_matching_type)
        self.sigma = sigma
        self.use_ode_solver = use_ode_solver
        self.device = device

        # è®¾ç½®æ—¶é—´æ­¥
        self.timesteps = None
        self._init_timesteps()

        print(f"âœ… FlowMatchingScheduler å·²åˆå§‹åŒ–:")
        print(f"   - æ¨ç†æ­¥æ•°: {num_inference_steps}")
        print(f"   - ç±»å‹: {flow_matching_type}")
        print(f"   - ODEæ±‚è§£å™¨: {use_ode_solver}")
        print(f"   - å™ªå£°æ°´å¹³: {sigma}")

    def _init_timesteps(self):
        """åˆå§‹åŒ–æ—¶é—´æ­¥ï¼ˆä» 0 åˆ° 1ï¼‰"""
        self.timesteps = torch.linspace(
            0, 1, self.num_inference_steps + 1,
            device=self.device
        )

    def set_timesteps(self, num_inference_steps: int, device: Union[str, torch.device] = None):
        """
        è®¾ç½®æ¨ç†æ—¶é—´æ­¥

        Args:
            num_inference_steps: æ¨ç†æ­¥æ•°
            device: è®¾å¤‡
        """
        self.num_inference_steps = num_inference_steps
        if device is not None:
            self.device = device
        self._init_timesteps()

    def add_noise(
        self,
        original_samples: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.Tensor,
    ) -> torch.Tensor:
        """
        è®­ç»ƒæ—¶æ·»åŠ å™ªå£°ï¼ˆçº¿æ€§æ’å€¼ï¼‰

        Flow Matching: x_t = (1-t)Â·x_0 + tÂ·x_1
        å…¶ä¸­ x_0 æ˜¯å™ªå£°ï¼Œx_1 æ˜¯ç›®æ ‡æ ·æœ¬

        Args:
            original_samples: åŸå§‹æ ·æœ¬ï¼ˆç›®æ ‡åŠ¨ä½œï¼‰x_1 [B, T, D]
            noise: å™ªå£°æ ·æœ¬ x_0 [B, T, D]
            timesteps: æ—¶é—´æ­¥ t âˆˆ [0, 1] [B]

        Returns:
            æ’å€¼åçš„æ ·æœ¬ x_t
        """
        # ç¡®ä¿ timesteps åœ¨ [0, 1] èŒƒå›´å†…
        timesteps = timesteps.to(original_samples.device)

        # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ ·æœ¬å½¢çŠ¶ [B] -> [B, 1, 1]
        t_expanded = timesteps.view(-1, 1, 1)

        # çº¿æ€§æ’å€¼: x_t = (1-t)Â·noise + tÂ·original
        noisy_samples = (1 - t_expanded) * noise + \
            t_expanded * original_samples

        # å¯é€‰ï¼šæ·»åŠ å°é‡å™ªå£°ï¼ˆéšæœºæµåŒ¹é…ï¼‰
        if self.sigma > 0:
            additional_noise = torch.randn_like(noisy_samples) * self.sigma
            noisy_samples = noisy_samples + additional_noise

        return noisy_samples

    def get_velocity(
        self,
        sample: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.Tensor
    ) -> torch.Tensor:
        """
        è®¡ç®—ç›®æ ‡é€Ÿåº¦åœº v_t

        å¯¹äºæ¡ä»¶æµåŒ¹é…: v_t = x_1 - x_0

        Args:
            sample: ç›®æ ‡æ ·æœ¬ x_1
            noise: åˆå§‹å™ªå£° x_0
            timesteps: æ—¶é—´æ­¥ï¼ˆåœ¨ Flow Matching ä¸­ä¸å½±å“é€Ÿåº¦ï¼‰

        Returns:
            ç›®æ ‡é€Ÿåº¦åœº v_t
        """
        # Flow Matching çš„é€Ÿåº¦åœºæ˜¯å¸¸æ•°ï¼ˆä» x_0 æŒ‡å‘ x_1ï¼‰
        return sample - noise

    def step(
        self,
        model_output: torch.Tensor,
        timestep: Union[int, torch.Tensor],
        sample: torch.Tensor,
        return_dict: bool = False,
    ) -> Union[torch.Tensor, Tuple]:
        """
        æ‰§è¡Œä¸€æ­¥ ODE æ±‚è§£ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰

        ä½¿ç”¨ Euler æ–¹æ³•: x_{t+dt} = x_t + v_t * dt
        æˆ– RK4 æ–¹æ³•è·å¾—æ›´é«˜ç²¾åº¦

        Args:
            model_output: æ¨¡å‹é¢„æµ‹çš„é€Ÿåº¦åœº v_t
            timestep: å½“å‰æ—¶é—´æ­¥
            sample: å½“å‰æ ·æœ¬ x_t
            return_dict: æ˜¯å¦è¿”å›å­—å…¸

        Returns:
            ä¸‹ä¸€æ—¶é—´æ­¥çš„æ ·æœ¬ x_{t+dt}
        """
        if isinstance(timestep, torch.Tensor):
            timestep = timestep.item()

        # è®¡ç®—æ—¶é—´æ­¥é•¿
        dt = 1.0 / self.num_inference_steps

        if self.use_ode_solver == "euler":
            # Euler æ–¹æ³•: x_{t+dt} = x_t + v_t * dt
            prev_sample = sample + model_output * dt

        elif self.use_ode_solver == "rk4":
            # RK4 æ–¹æ³•ï¼ˆæ›´ç²¾ç¡®ä½†éœ€è¦4æ¬¡å‰å‘ä¼ æ’­ï¼‰
            # æ³¨æ„ï¼šè¿™éœ€è¦é¢å¤–çš„æ¨¡å‹è°ƒç”¨ï¼Œè¿™é‡Œä»…åšæ¼”ç¤º
            # å®é™…ä½¿ç”¨æ—¶éœ€è¦åœ¨å¤–éƒ¨å®ç°
            prev_sample = sample + model_output * dt

        else:
            raise ValueError(f"Unknown ODE solver: {self.use_ode_solver}")

        if return_dict:
            return {"prev_sample": prev_sample}
        return prev_sample

    def scale_model_input(
        self,
        sample: torch.Tensor,
        timestep: Optional[Union[int, torch.Tensor]] = None
    ) -> torch.Tensor:
        """
        ç¼©æ”¾æ¨¡å‹è¾“å…¥ï¼ˆFlow Matching ä¸éœ€è¦ç¼©æ”¾ï¼‰

        Args:
            sample: è¾“å…¥æ ·æœ¬
            timestep: æ—¶é—´æ­¥ï¼ˆæœªä½¿ç”¨ï¼‰

        Returns:
            åŸæ ·è¿”å›
        """
        return sample

    def __len__(self):
        return self.num_inference_steps


class OptimalTransportFlowScheduler(FlowMatchingScheduler):
    """
    æœ€ä¼˜ä¼ è¾“æµåŒ¹é…è°ƒåº¦å™¨

    ä½¿ç”¨æœ€ä¼˜ä¼ è¾“ç†è®ºæ„å»ºæ›´ä¼˜çš„ä¼ è¾“è·¯å¾„
    å¯ä»¥è¿›ä¸€æ­¥æå‡é‡‡æ ·æ•ˆç‡
    """

    def __init__(self, **kwargs):
        super().__init__(flow_matching_type="optimal_transport", **kwargs)
        print("âš ï¸ æœ€ä¼˜ä¼ è¾“æµåŒ¹é…éœ€è¦é¢å¤–çš„é…å¯¹ç®—æ³•")
        print("   å½“å‰ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼ˆç­‰ä»·äºæ¡ä»¶æµåŒ¹é…ï¼‰")

    def add_noise(
        self,
        original_samples: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.Tensor,
    ) -> torch.Tensor:
        """
        ä½¿ç”¨æœ€ä¼˜ä¼ è¾“è·¯å¾„æ·»åŠ å™ªå£°

        ç†è®ºä¸Šåº”è¯¥ä½¿ç”¨ Sinkhorn ç®—æ³•ç­‰è®¡ç®—æœ€ä¼˜é…å¯¹
        è¿™é‡Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
        """
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨çº¿æ€§æ’å€¼
        # å®Œæ•´å®ç°éœ€è¦ï¼š
        # 1. è®¡ç®— cost matrix
        # 2. ä½¿ç”¨ Sinkhorn ç®—æ³•æ±‚è§£æœ€ä¼˜ä¼ è¾“è®¡åˆ’
        # 3. æ ¹æ®ä¼ è¾“è®¡åˆ’è¿›è¡Œé…å¯¹
        return super().add_noise(original_samples, noise, timesteps)


class RectifiedFlowScheduler(FlowMatchingScheduler):
    """
    ä¿®æ­£æµè°ƒåº¦å™¨

    é€šè¿‡å¤šæ¬¡ä¿®æ­£ï¼ˆrectificationï¼‰ä½¿æµæ›´åŠ ç›´æ¥
    å¯ä»¥ç”¨æ›´å°‘çš„æ­¥æ•°è¾¾åˆ°ç›¸åŒè´¨é‡
    """

    def __init__(self, num_rectifications: int = 1, **kwargs):
        super().__init__(flow_matching_type="rectified", **kwargs)
        self.num_rectifications = num_rectifications
        print(f"âœ… ä¿®æ­£æµè°ƒåº¦å™¨ï¼ˆä¿®æ­£æ¬¡æ•°: {num_rectifications}ï¼‰")

    def get_velocity(
        self,
        sample: torch.Tensor,
        noise: torch.Tensor,
        timesteps: torch.Tensor
    ) -> torch.Tensor:
        """
        ä¿®æ­£æµçš„é€Ÿåº¦åœº

        ç»è¿‡ä¿®æ­£åï¼Œè½¨è¿¹æ›´æ¥è¿‘ç›´çº¿
        """
        # åŸºç¡€ç‰ˆæœ¬ä»ç„¶ä½¿ç”¨ v_t = x_1 - x_0
        # å®Œæ•´å®ç°éœ€è¦é€šè¿‡å¤šæ¬¡è®­ç»ƒè¿›è¡Œä¿®æ­£
        return super().get_velocity(sample, noise, timesteps)


def create_flow_matching_scheduler(
    scheduler_type: str = "conditional",
    num_inference_steps: int = 10,
    **kwargs
) -> FlowMatchingScheduler:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»º Flow Matching è°ƒåº¦å™¨

    Args:
        scheduler_type: è°ƒåº¦å™¨ç±»å‹
        num_inference_steps: æ¨ç†æ­¥æ•°
        **kwargs: å…¶ä»–å‚æ•°

    Returns:
        Flow Matching è°ƒåº¦å™¨å®ä¾‹
    """
    if scheduler_type == "conditional":
        return FlowMatchingScheduler(
            num_inference_steps=num_inference_steps,
            **kwargs
        )
    elif scheduler_type == "optimal_transport":
        return OptimalTransportFlowScheduler(
            num_inference_steps=num_inference_steps,
            **kwargs
        )
    elif scheduler_type == "rectified":
        return RectifiedFlowScheduler(
            num_inference_steps=num_inference_steps,
            **kwargs
        )
    else:
        raise ValueError(f"Unknown scheduler type: {scheduler_type}")


# ============= è¾…åŠ©å‡½æ•° =============

def compare_schedulers_info():
    """æ‰“å° Flow Matching å’Œ Diffusion çš„å¯¹æ¯”ä¿¡æ¯"""
    print("\n" + "="*70)
    print("ğŸ“Š Flow Matching vs Diffusion å¯¹æ¯”")
    print("="*70)

    info = """
    | ç‰¹æ€§                | Diffusion (DDPM)    | Flow Matching        |
    |---------------------|---------------------|----------------------|
    | ç†è®ºåŸºç¡€            | SDE                 | ODE                  |
    | è®­ç»ƒæ—¶é—´æ­¥          | [0, T] (ç¦»æ•£)       | [0, 1] (è¿ç»­)        |
    | æ¨ç†æ­¥æ•°            | 50-1000æ­¥           | 10-20æ­¥ âš¡           |
    | é¢„æµ‹ç›®æ ‡            | å™ªå£° Îµ              | é€Ÿåº¦åœº v_t           |
    | é‡‡æ ·ç¡®å®šæ€§          | éšæœº(DDPM)          | ç¡®å®šæ€§ âœ…            |
    | æ¨ç†é€Ÿåº¦            | æ…¢                  | å¿«(3-10å€) ğŸš€        |
    | è®­ç»ƒå¤æ‚åº¦          | éœ€è¦å™ªå£°è°ƒåº¦        | ç®€å•çº¿æ€§æ’å€¼         |
    | é€‚ç”¨åœºæ™¯            | é«˜è´¨é‡ç”Ÿæˆ          | å®æ—¶æ§åˆ¶ â­          |

    æ¨èä½¿ç”¨ Flow Matching çš„åœºæ™¯:
    âœ… æœºå™¨äººå®æ—¶æ§åˆ¶
    âœ… é«˜é¢‘ç‡åŠ¨ä½œç”Ÿæˆ
    âœ… èµ„æºå—é™è®¾å¤‡
    âœ… å»¶è¿Ÿæ•æ„Ÿåº”ç”¨
    """
    print(info)
    print("="*70 + "\n")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯• FlowMatchingScheduler")

    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = FlowMatchingScheduler(num_inference_steps=10)

    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    batch_size, horizon, action_dim = 8, 16, 14
    target_actions = torch.randn(batch_size, horizon, action_dim)
    noise = torch.randn_like(target_actions)
    timesteps = torch.rand(batch_size)  # [0, 1]

    # æ·»åŠ å™ªå£°
    noisy_actions = scheduler.add_noise(target_actions, noise, timesteps)
    print(f"âœ… æ·»åŠ å™ªå£°: {noisy_actions.shape}")

    # è®¡ç®—é€Ÿåº¦åœº
    velocity = scheduler.get_velocity(target_actions, noise, timesteps)
    print(f"âœ… è®¡ç®—é€Ÿåº¦åœº: {velocity.shape}")

    # æ¨¡æ‹Ÿæ¨ç†æ­¥éª¤
    current_sample = noise
    for i, t in enumerate(scheduler.timesteps[:-1]):
        # å‡è®¾æ¨¡å‹é¢„æµ‹çš„é€Ÿåº¦åœº
        pred_velocity = velocity  # å®é™…åº”è¯¥æ˜¯æ¨¡å‹è¾“å‡º
        current_sample = scheduler.step(pred_velocity, t, current_sample)
        if i % 3 == 0:
            print(
                f"  Step {i}: t={t:.2f}, sample_mean={current_sample.mean():.4f}")

    print(f"\nâœ… æ¨ç†å®Œæˆ: {current_sample.shape}")
    print(f"ğŸ“Š ç›®æ ‡å‡å€¼: {target_actions.mean():.4f}")
    print(f"ğŸ“Š ç”Ÿæˆå‡å€¼: {current_sample.mean():.4f}")

    # æ‰“å°å¯¹æ¯”ä¿¡æ¯
    compare_schedulers_info()
