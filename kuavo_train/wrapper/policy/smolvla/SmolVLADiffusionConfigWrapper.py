"""
SmolVLA Diffusion Configuration Wrapper for Kuavo Project

åŸºäº SmolVLA ä½†ä½¿ç”¨ Diffusion è€Œé Flow Matching è¿›è¡ŒåŠ¨ä½œç”Ÿæˆ
"""

from dataclasses import dataclass, fields
from pathlib import Path
from copy import deepcopy
from typing import TypeVar, List, Tuple, Optional
import torch

from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig
from lerobot.configs.policies import PreTrainedConfig, PolicyFeature

T = TypeVar("T", bound="SmolVLADiffusionConfigWrapper")


@PreTrainedConfig.register_subclass("smolvla_diffusion_kuavo")
@dataclass
class SmolVLADiffusionConfigWrapper(SmolVLAConfig):
    """
    Kuavoé¡¹ç›®çš„ SmolVLA Diffusion é…ç½®æ‰©å±•ç±»

    ä¸»è¦å˜åŒ–ï¼š
    1. ä½¿ç”¨ Diffusion æ›¿ä»£ Flow Matching
    2. å®Œå…¨å†»ç»“è§†è§‰å±‚
    3. æ·»åŠ  Diffusion ç‰¹å®šé…ç½®
    4. ä¿æŒä¸åŸå§‹ SmolVLA çš„å…¼å®¹æ€§
    """

    # ==================== Diffusion ç‰¹å®šé…ç½® ====================
    use_diffusion: bool = True  # å¯ç”¨ Diffusion
    num_inference_steps: int = 50  # æ¨ç†æ­¥æ•°
    num_train_timesteps: int = 1000  # è®­ç»ƒæ—¶é—´æ­¥æ•°
    noise_schedule: str = "linear"  # å™ªå£°è°ƒåº¦ç±»å‹
    prediction_type: str = "epsilon"  # é¢„æµ‹ç±»å‹

    # å™ªå£°è°ƒåº¦å‚æ•°
    beta_start: float = 0.0001
    beta_end: float = 0.02

    # DDIM é‡‡æ ·é…ç½®
    use_ddim_sampling: bool = True
    ddim_eta: float = 0.0

    # å…¶ä»– Diffusion å‚æ•°
    clip_sample: bool = False
    clip_sample_range: float = 1.0
    variance_type: str = "fixed_small"  # fixed_small, fixed_large, learned, etc.

    # ==================== è§†è§‰å±‚é…ç½®ï¼ˆå®Œå…¨å†»ç»“ï¼‰====================
    # é‡å†™çˆ¶ç±»é…ç½®ï¼Œç¡®ä¿è§†è§‰å±‚å®Œå…¨å†»ç»“
    unfreeze_vision_layers: Optional[List[int]] = None
    freeze_vision_layers: Optional[List[int]] = None
    freeze_vision_ratio: Optional[float] = None

    # ==================== å­¦ä¹ ç‡é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼‰====================
    use_layerwise_lr: bool = False  # ç®€åŒ–ç­–ç•¥ï¼Œä¸ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡
    vision_encoder_lr: Optional[float] = None  # è§†è§‰å±‚å†»ç»“ï¼Œä¸éœ€è¦
    expert_lr: Optional[float] = None  # ä½¿ç”¨ç»Ÿä¸€å­¦ä¹ ç‡

    # ==================== å…¶ä»–ä¼˜åŒ–é…ç½® ====================
    # Diffusion é€šå¸¸éœ€è¦ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
    optimizer_lr: float = 2.0e-5  # é»˜è®¤å­¦ä¹ ç‡ï¼ˆæ¯” Flow Matching ç¨ä½ï¼‰

    def __post_init__(self):
        """
        ååˆå§‹åŒ–å¤„ç†
        """
        # è®¾ç½®é»˜è®¤å€¼
        if self.unfreeze_vision_layers is None:
            self.unfreeze_vision_layers = None

        if self.freeze_vision_layers is None:
            self.freeze_vision_layers = None

        if self.freeze_vision_ratio is None:
            self.freeze_vision_ratio = None

        # ç¡®ä¿ Diffusion é…ç½®æ­£ç¡®
        assert self.use_diffusion, "SmolVLADiffusionConfig å¿…é¡»è®¾ç½® use_diffusion=True"

        # éªŒè¯é…ç½®
        if self.noise_schedule not in ["linear", "cosine", "sqrt_linear"]:
            raise ValueError(f"ä¸æ”¯æŒçš„ noise_schedule: {self.noise_schedule}")

        if self.prediction_type not in ["epsilon", "v_prediction", "sample"]:
            raise ValueError(f"ä¸æ”¯æŒçš„ prediction_type: {self.prediction_type}")

        # è½¬æ¢ OmegaConf å¯¹è±¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._convert_omegaconf_to_native()

        # é‡æ–°è½¬æ¢ features ä¸º PolicyFeature å¯¹è±¡
        if hasattr(self, 'input_features') and self.input_features is not None:
            self.input_features = self._normalize_feature_dict(self.input_features)
        if hasattr(self, 'output_features') and self.output_features is not None:
            self.output_features = self._normalize_feature_dict(self.output_features)

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__post_init__()

        # Diffusion ç‰¹å®šéªŒè¯
        if self.use_diffusion and self.num_inference_steps > self.num_train_timesteps:
            print(f"âš ï¸ è­¦å‘Š: num_inference_steps ({self.num_inference_steps}) > num_train_timesteps ({self.num_train_timesteps})")

        # æ‰“å°é…ç½®æ‘˜è¦
        self._print_config_summary()

    def _convert_omegaconf_to_native(self):
        """
        å°†é…ç½®ä¸­æ‰€æœ‰ OmegaConf å¯¹è±¡è½¬æ¢ä¸ºåŸç”Ÿ Python å¯¹è±¡
        """
        try:
            from omegaconf import DictConfig, ListConfig, OmegaConf
        except ImportError:
            return

        for field in fields(self):
            value = getattr(self, field.name)
            if isinstance(value, (DictConfig, ListConfig)):
                native_value = OmegaConf.to_container(value, resolve=True)
                setattr(self, field.name, native_value)

    def _normalize_feature_dict(self, d):
        """å°†å­—å…¸æ ¼å¼çš„ features è½¬æ¢ä¸º PolicyFeature å¯¹è±¡"""
        if not isinstance(d, dict):
            return d

        return {
            k: PolicyFeature(**v) if isinstance(v, dict) and not isinstance(v, PolicyFeature) else v
            for k, v in d.items()
        }

    def _print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸš€ SmolVLA Diffusion Config Initialized for Kuavo Project")
        print("="*70)
        print(f"ğŸ“‹ Configuration Summary:")
        print(f"   - VLM Model: {self.vlm_model_name}")
        print(f"   - Action Generation: Diffusion (not Flow Matching)")
        print(f"   - Vision Encoder: FROZEN (all layers)")
        print(f"   - Train Expert Only: {self.train_expert_only}")
        print(f"   - Max Action Dim: {self.max_action_dim}")
        print(f"   - Max State Dim: {self.max_state_dim}")
        print(f"   - Chunk Size: {self.chunk_size}")
        print(f"   - Action Steps: {self.n_action_steps}")

        print(f"\nğŸ­ Diffusion Parameters:")
        print(f"   - Train Timesteps: {self.num_train_timesteps}")
        print(f"   - Inference Steps: {self.num_inference_steps}")
        print(f"   - Noise Schedule: {self.noise_schedule}")
        print(f"   - Prediction Type: {self.prediction_type}")
        print(f"   - Beta Range: [{self.beta_start}, {self.beta_end}]")
        print(f"   - Use DDIM: {self.use_ddim_sampling}")
        if self.use_ddim_sampling:
            print(f"   - DDIM Eta: {self.ddim_eta}")

        print(f"\nğŸ§  Learning Rate:")
        print(f"   - Optimizer LR: {self.optimizer_lr:.2e}")
        print(f"   - Use Layerwise LR: {self.use_layerwise_lr}")

        print(f"\nğŸ‘ï¸  Vision Config:")
        print(f"   - Use Depth: {self.use_depth}")
        if self.use_depth and self.depth_features:
            print(f"   - Depth Features: {self.depth_features}")
        print(f"   - Image Size: {self.resize_imgs_with_padding}")

        print("="*70 + "\n")

    def _save_pretrained(self, save_directory: Path) -> None:
        """
        ä¿å­˜é…ç½®åˆ°æŒ‡å®šç›®å½•
        """
        import draccus
        from lerobot.configs.policies import CONFIG_NAME

        # åˆ›å»ºæ·±æ‹·è´
        cfg_copy = deepcopy(self)

        # è½¬æ¢ torch.device ä¸ºå­—ç¬¦ä¸²
        if hasattr(cfg_copy, 'device') and isinstance(cfg_copy.device, torch.device):
            cfg_copy.device = str(cfg_copy.device)

        # ä¿å­˜é…ç½®
        save_directory = Path(save_directory)
        save_directory.mkdir(parents=True, exist_ok=True)

        with open(save_directory / CONFIG_NAME, "w") as f, draccus.config_type("json"):
            draccus.dump(cfg_copy, f, indent=4)

    @classmethod
    def from_pretrained(
        cls: type[T],
        pretrained_name_or_path: str | Path,
        *,
        force_download: bool = False,
        resume_download: bool = None,
        proxies: dict | None = None,
        token: str | bool | None = None,
        cache_dir: str | Path | None = None,
        local_files_only: bool = False,
        revision: str | None = None,
        **policy_kwargs,
    ) -> T:
        """
        ä»é¢„è®­ç»ƒè·¯å¾„åŠ è½½é…ç½®

        æ”¯æŒä» SmolVLA é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ï¼Œå¹¶è‡ªåŠ¨è½¬æ¢ä¸º Diffusion é…ç½®
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“‚ Loading SmolVLA Diffusion Config from: {pretrained_name_or_path}")
        print(f"{'='*70}")

        # å¦‚æœæä¾›äº† Diffusion ç‰¹å®šå‚æ•°ï¼Œæ›´æ–° policy_kwargs
        diffusion_defaults = {
            'use_diffusion': True,
            'num_inference_steps': 50,
            'num_train_timesteps': 1000,
            'noise_schedule': 'linear',
            'prediction_type': 'epsilon',
            'use_ddim_sampling': True,
            'ddim_eta': 0.0,
            'freeze_vision_encoder': True,  # ç¡®ä¿è§†è§‰å±‚å†»ç»“
        }

        # åˆå¹¶å‚æ•°ï¼ˆç”¨æˆ·å‚æ•°ä¼˜å…ˆï¼‰
        for key, value in diffusion_defaults.items():
            if key not in policy_kwargs:
                policy_kwargs[key] = value

        # å°è¯•ä»é¢„è®­ç»ƒè·¯å¾„åŠ è½½
        pretrained_path = Path(pretrained_name_or_path)
        if pretrained_path.exists():
            # æœ¬åœ°é…ç½®æ–‡ä»¶
            config_file = pretrained_path / "config.json"
            if config_file.exists():
                import json
                with open(config_file, 'r') as f:
                    config_dict = json.load(f)

                # å¦‚æœæ˜¯åŸå§‹ SmolVLA é…ç½®ï¼Œè½¬æ¢ç±»å‹
                if config_dict.get("_type_name") == "smolvla_kuavo":
                    config_dict["_type_name"] = "smolvla_diffusion_kuavo"
                    print("âœ… è½¬æ¢ SmolVLA é…ç½®ä¸º SmolVLA Diffusion é…ç½®")

                # åº”ç”¨ Diffusion é»˜è®¤å€¼
                config_dict.update(policy_kwargs)

                # åˆ›å»ºé…ç½®å®ä¾‹
                from draccus import decode
                config = decode(SmolVLADiffusionConfigWrapper, config_dict)
                print("âœ… ä»æœ¬åœ°é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
                return config

        # å¦‚æœä¸æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œè°ƒç”¨çˆ¶ç±»æ–¹æ³•
        parent_cls = PreTrainedConfig
        return parent_cls.from_pretrained(
            pretrained_name_or_path,
            force_download=force_download,
            resume_download=resume_download,
            proxies=proxies,
            token=token,
            cache_dir=cache_dir,
            local_files_only=local_files_only,
            revision=revision,
            **policy_kwargs,
        )

    def create_scheduler(self, device: Optional[str] = None):
        """
        åˆ›å»ºå™ªå£°è°ƒåº¦å™¨

        Args:
            device: è®¾å¤‡

        Returns:
            å™ªå£°è°ƒåº¦å™¨å®ä¾‹
        """
        from .diffusion_scheduler import DDIMScheduler, DDPMScheduler

        if self.use_ddim_sampling:
            scheduler = DDIMScheduler(
                num_train_timesteps=self.num_train_timesteps,
                num_inference_steps=self.num_inference_steps,
                beta_start=self.beta_start,
                beta_end=self.beta_end,
                beta_schedule=self.noise_schedule,
                prediction_type=self.prediction_type,
                clip_sample=self.clip_sample,
                clip_sample_range=self.clip_sample_range,
            )
        else:
            scheduler = DDPMScheduler(
                num_train_timesteps=self.num_train_timesteps,
                beta_start=self.beta_start,
                beta_end=self.beta_end,
                beta_schedule=self.noise_schedule,
                prediction_type=self.prediction_type,
                clip_sample=self.clip_sample,
                clip_sample_range=self.clip_sample_range,
            )

        if device is not None:
            scheduler = scheduler.to(device)

        return scheduler