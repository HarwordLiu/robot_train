"""
SmolVLA Policy Wrapper for Kuavo Project

SmolVLAçš„Kuavoé¡¹ç›®åŒ…è£…å™¨ï¼Œç»§æ‰¿lerobotçš„SmolVLAPolicyï¼Œ
æ·»åŠ Kuavoç‰¹å®šçš„åŠŸèƒ½å’Œå…¼å®¹æ€§å¤„ç†ã€‚
"""

import torch
from typing import Dict, Any, Optional
from pathlib import Path

from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig


class SmolVLAPolicyWrapper(SmolVLAPolicy):
    """
    Kuavoé¡¹ç›®çš„SmolVLAç­–ç•¥åŒ…è£…å™¨

    ç›´æ¥ç»§æ‰¿lerobotçš„SmolVLAPolicyï¼Œæ·»åŠ ï¼š
    1. Kuavoé¡¹ç›®çš„åˆå§‹åŒ–æ—¥å¿—
    2. å…¼å®¹Kuavoæ•°æ®æ ¼å¼
    3. æ”¯æŒå¤šä»»åŠ¡é¡ºåºè®­ç»ƒ

    Usage:
        # è®­ç»ƒæ¨¡å¼
        policy = SmolVLAPolicyWrapper(config, dataset_stats)
        loss, info = policy.forward(batch)

        # æ¨ç†æ¨¡å¼
        action = policy.select_action(batch)
    """

    def __init__(
        self,
        config: SmolVLAConfig,
        dataset_stats: Optional[Dict[str, Dict[str, torch.Tensor]]] = None,
    ):
        """
        åˆå§‹åŒ–SmolVLAç­–ç•¥

        Args:
            config: SmolVLAConfigé…ç½®å¯¹è±¡
            dataset_stats: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
        """
        # è°ƒç”¨çˆ¶ç±»SmolVLAPolicyçš„åˆå§‹åŒ–
        super().__init__(config, dataset_stats)

        # Kuavoé¡¹ç›®ç‰¹å®šæ—¥å¿—
        print("\n" + "="*70)
        print("ğŸ¤– SmolVLA Policy Initialized for Kuavo Project")
        print("="*70)
        print(f"VLM Backbone: {config.vlm_model_name}")
        print(f"Action Dimension: {config.max_action_dim} (Kuavo Dual-Arm)")
        print(f"Chunk Size: {config.chunk_size}")
        print(f"Action Steps per Inference: {config.n_action_steps}")
        print(f"Freeze Vision Encoder: {config.freeze_vision_encoder}")
        print(f"Train Expert Only: {config.train_expert_only}")

        # æ‰“å°æ¨¡å‹å‚æ•°é‡
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        print(f"\nModel Parameters:")
        print(f"  Total: {total_params:,}")
        print(f"  Trainable: {trainable_params:,}")
        print(f"  Frozen: {total_params - trainable_params:,}")
        print("="*70 + "\n")

    def prepare_batch_with_language(
        self,
        batch: Dict[str, torch.Tensor],
        language_instruction: str
    ) -> Dict[str, torch.Tensor]:
        """
        ä¸ºbatchæ·»åŠ language instruction

        SmolVLAéœ€è¦language instructionä½œä¸ºä»»åŠ¡æ¡ä»¶ï¼Œ
        è¿™ä¸ªæ–¹æ³•ç¡®ä¿æ¯ä¸ªbatchéƒ½åŒ…å«æ­£ç¡®çš„language field

        Args:
            batch: è¾“å…¥batch
            language_instruction: ä»»åŠ¡çš„language instruction

        Returns:
            åŒ…å«languageå­—æ®µçš„batch
        """
        if 'task' not in batch:
            # ä¸ºbatchä¸­çš„æ¯ä¸ªæ ·æœ¬æ·»åŠ ç›¸åŒçš„language instruction
            batch_size = next(iter(batch.values())).shape[0]
            batch['task'] = [language_instruction] * batch_size

        return batch

    def forward(
        self,
        batch: Dict[str, torch.Tensor],
        noise: Optional[torch.Tensor] = None,
        time: Optional[torch.Tensor] = None
    ) -> tuple[torch.Tensor, Dict[str, Any]]:
        """
        è®­ç»ƒforward

        Args:
            batch: è¾“å…¥batchï¼Œå¿…é¡»åŒ…å«'task'å­—æ®µ
            noise: å¯é€‰çš„å™ªå£°ï¼ˆFlow Matchingä½¿ç”¨ï¼‰
            time: å¯é€‰çš„æ—¶é—´æ­¥ï¼ˆFlow Matchingä½¿ç”¨ï¼‰

        Returns:
            loss: æ ‡é‡tensor
            info: ä¿¡æ¯å­—å…¸
        """
        # ç¡®ä¿batchåŒ…å«taskå­—æ®µ
        if 'task' not in batch:
            raise ValueError(
                "Batch must contain 'task' field for SmolVLA. "
                "Use prepare_batch_with_language() to add language instruction."
            )

        # è°ƒç”¨çˆ¶ç±»forward
        return super().forward(batch, noise, time)

    def select_action(
        self,
        batch: Dict[str, torch.Tensor],
        noise: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        æ¨ç†forwardï¼šç”ŸæˆåŠ¨ä½œ

        Args:
            batch: è§‚æµ‹batchï¼Œå¿…é¡»åŒ…å«'task'å­—æ®µ
            noise: å¯é€‰çš„å™ªå£°ï¼ˆç”¨äºæµ‹è¯•ï¼‰

        Returns:
            action: [B, action_dim] å•æ­¥åŠ¨ä½œ
        """
        # ç¡®ä¿batchåŒ…å«taskå­—æ®µ
        if 'task' not in batch:
            raise ValueError(
                "Batch must contain 'task' field for SmolVLA inference. "
                "Provide language instruction to specify which task to execute."
            )

        # è°ƒç”¨çˆ¶ç±»select_action
        return super().select_action(batch, noise)

    @classmethod
    def from_pretrained(
        cls,
        pretrained_name_or_path: str,
        config: Optional[SmolVLAConfig] = None,
        dataset_stats: Optional[Dict[str, Dict[str, torch.Tensor]]] = None,
        **kwargs
    ):
        """
        ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½

        Args:
            pretrained_name_or_path:
                - HuggingFaceæ¨¡å‹IDï¼ˆå¦‚'lerobot/smolvla_base'ï¼‰
                - æœ¬åœ°è·¯å¾„ï¼ˆå¦‚'outputs/train/.../best'ï¼‰
            config: å¯é€‰çš„é…ç½®å¯¹è±¡ï¼ˆå¦‚æœæä¾›ï¼Œä¼šoverrideé¢„è®­ç»ƒé…ç½®ï¼‰
            dataset_stats: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŠ è½½çš„SmolVLAPolicyWrapperå®ä¾‹
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“‚ Loading SmolVLA from: {pretrained_name_or_path}")
        print(f"{'='*70}")

        # å¦‚æœæ²¡æœ‰æä¾›configï¼Œä»é¢„è®­ç»ƒè·¯å¾„åŠ è½½
        if config is None:
            from .SmolVLAConfigWrapper import SmolVLAConfigWrapper
            config = SmolVLAConfigWrapper.from_pretrained(pretrained_name_or_path)

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = cls(config, dataset_stats)

        # åŠ è½½æƒé‡
        pretrained_path = Path(pretrained_name_or_path)
        if pretrained_path.exists():
            # æœ¬åœ°checkpoint
            model_file = pretrained_path / "model.safetensors"
            if model_file.exists():
                from lerobot.policies.smolvla.modeling_smolvla import load_smolvla
                model = load_smolvla(
                    model,
                    str(model_file),
                    device='cpu',
                    checkpoint_keys_mapping="model._orig_mod.//model."
                )
                print(f"âœ… Loaded weights from local checkpoint")
            else:
                print(f"âš ï¸  Model file not found: {model_file}")
        else:
            # HuggingFaceæ¨¡å‹
            try:
                from huggingface_hub import hf_hub_download
                model_file = hf_hub_download(
                    repo_id=pretrained_name_or_path,
                    filename="model.safetensors"
                )
                from lerobot.policies.smolvla.modeling_smolvla import load_smolvla
                model = load_smolvla(
                    model,
                    model_file,
                    device='cpu',
                    checkpoint_keys_mapping="model._orig_mod.//model."
                )
                print(f"âœ… Loaded weights from HuggingFace: {pretrained_name_or_path}")
            except Exception as e:
                print(f"âš ï¸  Failed to load from HuggingFace: {e}")
                print(f"Using random initialization")

        print(f"{'='*70}\n")
        return model

    def save_pretrained(self, save_directory: Path) -> None:
        """
        ä¿å­˜æ¨¡å‹

        Args:
            save_directory: ä¿å­˜ç›®å½•è·¯å¾„
        """
        save_directory = Path(save_directory)
        save_directory.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ’¾ Saving SmolVLA model to {save_directory}")

        # ä¿å­˜é…ç½®
        self.config._save_pretrained(save_directory)

        # ä¿å­˜æ¨¡å‹æƒé‡
        from safetensors.torch import save_file
        model_file = save_directory / "model.safetensors"
        save_file(self.state_dict(), str(model_file))

        print(f"âœ… Model saved successfully")
        print(f"   Config: {save_directory / 'config.json'}")
        print(f"   Weights: {model_file}")
