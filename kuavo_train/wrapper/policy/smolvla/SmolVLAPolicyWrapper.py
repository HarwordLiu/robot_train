"""
SmolVLA Policy Wrapper for Kuavo Project

SmolVLAçš„Kuavoé¡¹ç›®åŒ…è£…å™¨ï¼Œç»§æ‰¿lerobotçš„SmolVLAPolicyï¼Œ
æ·»åŠ Kuavoç‰¹å®šçš„åŠŸèƒ½å’Œå…¼å®¹æ€§å¤„ç†ã€‚
"""

import torch
from typing import Dict, Any, Optional
from pathlib import Path

from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig


class SmolVLAPolicyWrapper(SmolVLAPolicy):
    """
    Kuavoé¡¹ç›®çš„SmolVLAç­–ç•¥åŒ…è£…å™¨

    ç›´æ¥ç»§æ‰¿lerobotçš„SmolVLAPolicyï¼Œæ·»åŠ ï¼š
    1. Kuavoé¡¹ç›®çš„åˆå§‹åŒ–æ—¥å¿—
    2. å…¼å®¹Kuavoæ•°æ®æ ¼å¼
    3. æ”¯æŒå¤šä»»åŠ¡é¡ºåºè®­ç»ƒ

    Usage:
        # è®­ç»ƒæ¨¡å¼
        policy = SmolVLAPolicyWrapper(config, dataset_stats)
        loss, info = policy.forward(batch)

        # æ¨ç†æ¨¡å¼
        action = policy.select_action(batch)
    """

    def __init__(
        self,
        config: SmolVLAConfig,
        dataset_stats: Optional[Dict[str, Dict[str, torch.Tensor]]] = None,
    ):
        """
        åˆå§‹åŒ–SmolVLAç­–ç•¥

        Args:
            config: SmolVLAConfigé…ç½®å¯¹è±¡
            dataset_stats: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
        """
        # è°ƒç”¨çˆ¶ç±»SmolVLAPolicyçš„åˆå§‹åŒ–
        super().__init__(config, dataset_stats)

        # Kuavoé¡¹ç›®ç‰¹å®šæ—¥å¿—
        print("\n" + "="*70)
        print("ğŸ¤– SmolVLA Policy Initialized for Kuavo Project")
        print("="*70)
        print(f"VLM Backbone: {config.vlm_model_name}")
        print(f"Action Dimension: {config.max_action_dim} (Kuavo Dual-Arm)")
        print(f"Chunk Size: {config.chunk_size}")
        print(f"Action Steps per Inference: {config.n_action_steps}")
        print(f"Freeze Vision Encoder: {config.freeze_vision_encoder}")
        print(f"Train Expert Only: {config.train_expert_only}")

        # æ‰“å°æ¨¡å‹å‚æ•°é‡
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel()
                               for p in self.parameters() if p.requires_grad)
        print(f"\nModel Parameters:")
        print(f"  Total: {total_params:,}")
        print(f"  Trainable: {trainable_params:,}")
        print(f"  Frozen: {total_params - trainable_params:,}")
        print("="*70 + "\n")

    def prepare_batch_with_language(
        self,
        batch: Dict[str, torch.Tensor],
        language_instruction: str
    ) -> Dict[str, torch.Tensor]:
        """
        ä¸ºbatchæ·»åŠ language instruction

        SmolVLAéœ€è¦language instructionä½œä¸ºä»»åŠ¡æ¡ä»¶ï¼Œ
        è¿™ä¸ªæ–¹æ³•ç¡®ä¿æ¯ä¸ªbatchéƒ½åŒ…å«æ­£ç¡®çš„language field

        Args:
            batch: è¾“å…¥batch
            language_instruction: ä»»åŠ¡çš„language instruction

        Returns:
            åŒ…å«languageå­—æ®µçš„batch
        """
        if 'task' not in batch:
            # ä¸ºbatchä¸­çš„æ¯ä¸ªæ ·æœ¬æ·»åŠ ç›¸åŒçš„language instruction
            batch_size = next(iter(batch.values())).shape[0]
            batch['task'] = [language_instruction] * batch_size

        return batch

    def forward(
        self,
        batch: Dict[str, torch.Tensor],
        noise: Optional[torch.Tensor] = None,
        time: Optional[torch.Tensor] = None
    ) -> tuple[torch.Tensor, Dict[str, Any]]:
        """
        è®­ç»ƒforward

        Args:
            batch: è¾“å…¥batchï¼Œå¿…é¡»åŒ…å«'task'å­—æ®µ
            noise: å¯é€‰çš„å™ªå£°ï¼ˆFlow Matchingä½¿ç”¨ï¼‰
            time: å¯é€‰çš„æ—¶é—´æ­¥ï¼ˆFlow Matchingä½¿ç”¨ï¼‰

        Returns:
            loss: æ ‡é‡tensor
            info: ä¿¡æ¯å­—å…¸
        """
        # ç¡®ä¿batchåŒ…å«taskå­—æ®µ
        if 'task' not in batch:
            raise ValueError(
                "Batch must contain 'task' field for SmolVLA. "
                "Use prepare_batch_with_language() to add language instruction."
            )

        # è°ƒç”¨çˆ¶ç±»forward
        return super().forward(batch, noise, time)

    def select_action(
        self,
        batch: Dict[str, torch.Tensor],
        noise: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        æ¨ç†forwardï¼šç”ŸæˆåŠ¨ä½œ

        Args:
            batch: è§‚æµ‹batchï¼Œå¿…é¡»åŒ…å«'task'å­—æ®µ
            noise: å¯é€‰çš„å™ªå£°ï¼ˆç”¨äºæµ‹è¯•ï¼‰

        Returns:
            action: [B, action_dim] å•æ­¥åŠ¨ä½œ
        """
        # ç¡®ä¿batchåŒ…å«taskå­—æ®µ
        if 'task' not in batch:
            raise ValueError(
                "Batch must contain 'task' field for SmolVLA inference. "
                "Provide language instruction to specify which task to execute."
            )

        # è°ƒç”¨çˆ¶ç±»select_action
        return super().select_action(batch, noise)

    @staticmethod
    def _create_identity_stats(config: SmolVLAConfig) -> Dict[str, Dict[str, torch.Tensor]]:
        """
        åˆ›å»º"ç©º"çš„dataset_statsï¼Œä½¿å½’ä¸€åŒ–æˆä¸ºæ’ç­‰å˜æ¢
        
        å¯¹äºæ¯ä¸ªfeatureï¼š
        - mean = 0ï¼ˆå‡å»0ä¸æ”¹å˜æ•°æ®ï¼‰
        - std = 1ï¼ˆé™¤ä»¥1ä¸æ”¹å˜æ•°æ®ï¼‰
        
        æ³¨æ„ï¼šå¯¹äº state å’Œ actionï¼Œä½¿ç”¨ max_state_dim å’Œ max_action_dimï¼ˆ32ç»´ï¼‰
        è€Œä¸æ˜¯å®é™…çš„ç»´åº¦ï¼ˆ16ç»´ï¼‰ï¼Œä»¥åŒ¹é…è®­ç»ƒæ—¶çš„å¡«å……ç»´åº¦ã€‚
        
        Args:
            config: SmolVLAé…ç½®å¯¹è±¡
            
        Returns:
            åŒ…å«æ‰€æœ‰featuresçš„identity statså­—å…¸
        """
        stats = {}
        
        # å¤„ç†input featuresï¼ˆobservationsï¼‰
        for key, feature in config.input_features.items():
            shape = feature.shape
            
            # å¯¹äºstateï¼Œä½¿ç”¨max_state_dimè€Œä¸æ˜¯å®é™…ç»´åº¦
            if 'state' in key.lower():
                shape = (config.max_state_dim,)
            
            stats[key] = {
                'mean': torch.zeros(shape, dtype=torch.float32),
                'std': torch.ones(shape, dtype=torch.float32),
                'min': torch.zeros(shape, dtype=torch.float32),
                'max': torch.ones(shape, dtype=torch.float32),
            }
        
        # å¤„ç†output featuresï¼ˆactionsï¼‰
        for key, feature in config.output_features.items():
            shape = feature.shape
            
            # å¯¹äºactionï¼Œä½¿ç”¨max_action_dimè€Œä¸æ˜¯å®é™…ç»´åº¦
            if 'action' in key.lower():
                shape = (config.max_action_dim,)
            
            stats[key] = {
                'mean': torch.zeros(shape, dtype=torch.float32),
                'std': torch.ones(shape, dtype=torch.float32),
                'min': torch.zeros(shape, dtype=torch.float32),
                'max': torch.ones(shape, dtype=torch.float32),
            }
        
        return stats

    @classmethod
    def from_pretrained(
        cls,
        pretrained_name_or_path: str,
        config: Optional[SmolVLAConfig] = None,
        dataset_stats: Optional[Dict[str, Dict[str, torch.Tensor]]] = None,
        **kwargs
    ):
        """
        ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½

        Args:
            pretrained_name_or_path:
                - HuggingFaceæ¨¡å‹IDï¼ˆå¦‚'lerobot/smolvla_base'ï¼‰
                - æœ¬åœ°è·¯å¾„ï¼ˆå¦‚'outputs/train/.../best'ï¼‰
            config: å¯é€‰çš„é…ç½®å¯¹è±¡ï¼ˆå¦‚æœæä¾›ï¼Œä¼šoverrideé¢„è®­ç»ƒé…ç½®ï¼‰
            dataset_stats: æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯

        Returns:
            åŠ è½½çš„SmolVLAPolicyWrapperå®ä¾‹
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“‚ Loading SmolVLA from: {pretrained_name_or_path}")
        print(f"{'='*70}")

        # å¦‚æœæ²¡æœ‰æä¾›configï¼Œä»é¢„è®­ç»ƒè·¯å¾„åŠ è½½
        if config is None:
            from .SmolVLAConfigWrapper import SmolVLAConfigWrapper
            config = SmolVLAConfigWrapper.from_pretrained(
                pretrained_name_or_path)

        # å¦‚æœæ²¡æœ‰æä¾›dataset_statsï¼Œåˆ›å»ºä¸´æ—¶çš„identity statsç”¨äºåˆå§‹åŒ–
        # çœŸå®çš„å½’ä¸€åŒ–å‚æ•°ä¼šä»checkpointä¸­åŠ è½½
        if dataset_stats is None:
            print("âš ï¸  No dataset_stats provided. Will load normalization params from checkpoint.")
            dataset_stats = cls._create_identity_stats(config)

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = cls(config, dataset_stats)

        # åŠ è½½æƒé‡
        pretrained_path = Path(pretrained_name_or_path)
        if pretrained_path.exists():
            # æœ¬åœ°checkpoint
            model_file = pretrained_path / "model.safetensors"
            if model_file.exists():
                # åŠ è½½å®Œæ•´çš„ state_dictï¼ˆåŒ…æ‹¬å½’ä¸€åŒ–å‚æ•°ï¼‰
                from safetensors.torch import load_file
                full_state_dict = load_file(str(model_file))
                
                # åˆ†ç¦»å½’ä¸€åŒ–å‚æ•°å’Œæ¨¡å‹å‚æ•°
                norm_keys = ("normalize_inputs", "normalize_targets", "unnormalize_outputs")
                norm_state_dict = {k: v for k, v in full_state_dict.items() if k.startswith(norm_keys)}
                model_state_dict = {k: v for k, v in full_state_dict.items() if not k.startswith(norm_keys)}
                
                # å…ˆåŠ è½½æ¨¡å‹å‚æ•°ï¼ˆä¸åŒ…æ‹¬å½’ä¸€åŒ–ï¼‰
                missing, unexpected = model.load_state_dict(model_state_dict, strict=False)
                print(f"âœ… Loaded model weights from local checkpoint")
                
                # å†åŠ è½½å½’ä¸€åŒ–å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if norm_state_dict:
                    model.load_state_dict(norm_state_dict, strict=False)
                    print(f"âœ… Loaded normalization parameters from checkpoint")
                    print(f"   - {len([k for k in norm_state_dict.keys() if 'normalize_inputs' in k])} input norm params")
                    print(f"   - {len([k for k in norm_state_dict.keys() if 'normalize_targets' in k])} target norm params")
                    print(f"   - {len([k for k in norm_state_dict.keys() if 'unnormalize_outputs' in k])} unnorm params")
                else:
                    print(f"âš ï¸  No normalization parameters found in checkpoint. Using identity normalization.")
            else:
                print(f"âš ï¸  Model file not found: {model_file}")
        else:
            # HuggingFaceæ¨¡å‹
            try:
                from huggingface_hub import hf_hub_download
                model_file = hf_hub_download(
                    repo_id=pretrained_name_or_path,
                    filename="model.safetensors"
                )
                from lerobot.policies.smolvla.modeling_smolvla import load_smolvla
                model = load_smolvla(
                    model,
                    model_file,
                    device='cpu',
                    checkpoint_keys_mapping="model._orig_mod.//model."
                )
                print(
                    f"âœ… Loaded weights from HuggingFace: {pretrained_name_or_path}")
            except Exception as e:
                print(f"âš ï¸  Failed to load from HuggingFace: {e}")
                print(f"Using random initialization")

        print(f"{'='*70}\n")
        return model

    def save_pretrained(self, save_directory: Path) -> None:
        """
        ä¿å­˜æ¨¡å‹

        Args:
            save_directory: ä¿å­˜ç›®å½•è·¯å¾„

        æ³¨æ„ï¼šä¾èµ– SmolVLAConfigWrapper å·²å°†æ‰€æœ‰ OmegaConf å¯¹è±¡è½¬æ¢ä¸ºåŸç”Ÿ Python å¯¹è±¡ï¼Œ
        å› æ­¤å¯ä»¥ç›´æ¥ä½¿ç”¨ lerobot çš„æ ‡å‡†ä¿å­˜æ–¹å¼ã€‚
        """
        save_directory = Path(save_directory)
        save_directory.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ’¾ Saving SmolVLA model to {save_directory}")

        # ä¿å­˜é…ç½®ï¼ˆä½¿ç”¨ lerobot æ ‡å‡†æ–¹å¼ï¼‰
        self.config._save_pretrained(save_directory)

        # ä¿å­˜æ¨¡å‹æƒé‡
        from safetensors.torch import save_file
        model_file = save_directory / "model.safetensors"
        save_file(self.state_dict(), str(model_file))

        print(f"âœ… Model saved successfully")
        print(f"   Config: {save_directory / 'config.json'}")
        print(f"   Weights: {model_file}")
