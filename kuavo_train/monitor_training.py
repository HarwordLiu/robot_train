#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒç›‘æ§è„šæœ¬ - å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œå…³é”®æŒ‡æ ‡

åŠŸèƒ½ï¼š
- å®æ—¶ç›‘æ§è®­ç»ƒæ—¥å¿—
- è§£æTensorBoardäº‹ä»¶æ–‡ä»¶
- æ˜¾ç¤ºå…³é”®æŒ‡æ ‡ï¼ˆlossã€lrã€epochè¿›åº¦ç­‰ï¼‰
- å¯è§†åŒ–è®­ç»ƒè¶‹åŠ¿
- è¯„ä¼°è®­ç»ƒçŠ¶æ€ï¼ˆæ­£å¸¸/è¿‡æ‹Ÿåˆ/å­¦ä¹ ç‡å¼‚å¸¸ç­‰ï¼‰
- æ”¯æŒå¤šç§è®­ç»ƒè„šæœ¬ï¼ˆSmolVLAã€Diffusionã€Hierarchicalç­‰ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # ç›‘æ§æœ€æ–°çš„è®­ç»ƒè¿è¡Œ
    python kuavo_train/monitor_training.py
    
    # ç›‘æ§æŒ‡å®šçš„è®­ç»ƒè¿è¡Œ
    python kuavo_train/monitor_training.py --run-dir outputs/train/task1_moving_grasp/smolvla_sequential/run_20251017_120000
    
    # æ˜¾ç¤ºå¯è§†åŒ–å›¾è¡¨
    python kuavo_train/monitor_training.py --plot
    
    # è‡ªåŠ¨åˆ·æ–°æ¨¡å¼ï¼ˆæ¯Nç§’åˆ·æ–°ä¸€æ¬¡ï¼‰
    python kuavo_train/monitor_training.py --refresh 5
"""

import argparse
import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
import re

try:
    from tensorboard.backend.event_processing.event_accumulator import EventAccumulator
    TENSORBOARD_AVAILABLE = True
except ImportError:
    TENSORBOARD_AVAILABLE = False
    print("âš ï¸  TensorBoardæœªå®‰è£…ï¼Œæ— æ³•è§£æäº‹ä»¶æ–‡ä»¶ã€‚è¯·è¿è¡Œ: pip install tensorboard")


class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self, run_dir: Path, enable_plot: bool = False):
        self.run_dir = Path(run_dir)
        self.enable_plot = enable_plot
        
        # æŸ¥æ‰¾TensorBoardæ—¥å¿—ç›®å½•
        self.tb_log_dir = self._find_tensorboard_dir()
        
        # åˆå§‹åŒ–äº‹ä»¶ç´¯åŠ å™¨
        self.event_acc = None
        if self.tb_log_dir and TENSORBOARD_AVAILABLE:
            self._init_event_accumulator()
        
        # ç”¨äºå­˜å‚¨è§£æçš„æ•°æ®
        self.metrics_history = {
            'train/loss': [],
            'train/lr': [],
            'train/epoch_duration_minutes': [],
        }
        
        self.last_update_time = None
        
    def _find_tensorboard_dir(self) -> Optional[Path]:
        """æŸ¥æ‰¾TensorBoardæ—¥å¿—ç›®å½•"""
        # TensorBoardæ—¥å¿—é»˜è®¤åœ¨run_diræœ¬èº«
        if (self.run_dir / 'events.out.tfevents').exists() or \
           any(f.name.startswith('events.out.tfevents') for f in self.run_dir.glob('events.out.tfevents.*')):
            return self.run_dir
        return None
    
    def _init_event_accumulator(self):
        """åˆå§‹åŒ–äº‹ä»¶ç´¯åŠ å™¨"""
        try:
            self.event_acc = EventAccumulator(str(self.tb_log_dir))
            self.event_acc.Reload()
        except Exception as e:
            print(f"âš ï¸  æ— æ³•åŠ è½½TensorBoardäº‹ä»¶: {e}")
            self.event_acc = None
    
    def reload_events(self):
        """é‡æ–°åŠ è½½äº‹ä»¶æ•°æ®"""
        if self.event_acc:
            try:
                self.event_acc.Reload()
            except Exception as e:
                print(f"âš ï¸  é‡æ–°åŠ è½½äº‹ä»¶å¤±è´¥: {e}")
    
    def get_scalar_data(self, tag: str) -> List[Tuple[float, float]]:
        """è·å–æ ‡é‡æ•°æ® (step, value)"""
        if not self.event_acc:
            return []
        
        try:
            events = self.event_acc.Scalars(tag)
            return [(e.step, e.value) for e in events]
        except KeyError:
            return []
    
    def get_latest_metrics(self) -> Dict:
        """è·å–æœ€æ–°çš„æŒ‡æ ‡"""
        self.reload_events()
        
        metrics = {}
        
        # è·å–è®­ç»ƒloss
        loss_data = self.get_scalar_data('train/loss')
        if loss_data:
            self.metrics_history['train/loss'] = loss_data
            metrics['loss'] = loss_data[-1][1]
            metrics['epoch'] = int(loss_data[-1][0])
        
        # è·å–å­¦ä¹ ç‡
        lr_data = self.get_scalar_data('train/lr')
        if lr_data:
            self.metrics_history['train/lr'] = lr_data
            metrics['lr'] = lr_data[-1][1]
        
        # è·å–epochè€—æ—¶
        duration_data = self.get_scalar_data('train/epoch_duration_minutes')
        if duration_data:
            self.metrics_history['train/epoch_duration_minutes'] = duration_data
            metrics['epoch_duration'] = duration_data[-1][1]
        
        # è·å–éªŒè¯æŒ‡æ ‡ï¼ˆå¯èƒ½æœ‰å¤šä¸ªä»»åŠ¡ï¼‰
        if self.event_acc:
            all_tags = self.event_acc.Tags().get('scalars', [])
            validation_tags = [tag for tag in all_tags if tag.startswith('validation/')]
            
            if validation_tags:
                metrics['validation'] = {}
                for tag in validation_tags:
                    val_data = self.get_scalar_data(tag)
                    if val_data:
                        task_name = tag.replace('validation/', '').replace('_loss', '')
                        metrics['validation'][task_name] = val_data[-1][1]
        
        self.last_update_time = datetime.now()
        return metrics
    
    def get_checkpoint_info(self) -> Dict:
        """è·å–checkpointä¿¡æ¯"""
        info = {
            'best_exists': (self.run_dir / 'best').exists(),
            'latest_epoch': None,
            'saved_epochs': []
        }
        
        # æŸ¥æ‰¾æ‰€æœ‰epoch checkpoints
        epoch_dirs = sorted(self.run_dir.glob('epoch*'))
        if epoch_dirs:
            info['saved_epochs'] = [int(d.name.replace('epoch', '')) for d in epoch_dirs]
            info['latest_epoch'] = max(info['saved_epochs'])
        
        return info
    
    def get_training_status(self, metrics: Dict) -> Dict:
        """è¯„ä¼°è®­ç»ƒçŠ¶æ€"""
        status = {
            'status': 'æœªçŸ¥',
            'warnings': [],
            'suggestions': []
        }
        
        # æ£€æŸ¥lossè¶‹åŠ¿
        loss_history = self.metrics_history.get('train/loss', [])
        if len(loss_history) >= 5:
            recent_losses = [v for s, v in loss_history[-5:]]
            
            # æ£€æŸ¥æ˜¯å¦æ”¶æ•›
            loss_std = sum((x - sum(recent_losses)/len(recent_losses))**2 for x in recent_losses) / len(recent_losses)
            loss_std = loss_std ** 0.5
            
            if loss_std < 0.01:
                status['status'] = 'å·²æ”¶æ•›'
            elif recent_losses[-1] < recent_losses[0]:
                status['status'] = 'æ­£å¸¸ä¸‹é™'
            elif recent_losses[-1] > recent_losses[0] * 1.5:
                status['status'] = 'å¼‚å¸¸ä¸Šå‡'
                status['warnings'].append('âš ï¸  Losså¼‚å¸¸ä¸Šå‡ï¼Œå¯èƒ½å­¦ä¹ ç‡è¿‡é«˜æˆ–æ•°æ®æœ‰é—®é¢˜')
            else:
                status['status'] = 'éœ‡è¡ä¸­'
        
        # æ£€æŸ¥å­¦ä¹ ç‡
        lr_history = self.metrics_history.get('train/lr', [])
        if lr_history:
            current_lr = lr_history[-1][1]
            if current_lr < 1e-7:
                status['warnings'].append('âš ï¸  å­¦ä¹ ç‡è¿‡å°ï¼Œè®­ç»ƒå¯èƒ½åœæ»')
            elif current_lr > 1e-2:
                status['warnings'].append('âš ï¸  å­¦ä¹ ç‡è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´ä¸ç¨³å®š')
        
        # æ£€æŸ¥è®­ç»ƒæ—¶é—´
        if len(loss_history) >= 2:
            total_epochs = len(loss_history)
            current_epoch = metrics.get('epoch', 0)
            
            if 'epoch_duration' in metrics:
                avg_duration = metrics['epoch_duration']
                estimated_total_time = avg_duration * total_epochs
                
                if estimated_total_time > 24 * 60:  # è¶…è¿‡24å°æ—¶
                    status['suggestions'].append(f'ğŸ’¡ é¢„è®¡æ€»è®­ç»ƒæ—¶é—´: {estimated_total_time/60:.1f}å°æ—¶ï¼Œå»ºè®®è°ƒæ•´batch sizeæˆ–å‡å°‘epoch')
        
        # æ£€æŸ¥è¿‡æ‹Ÿåˆ
        if 'validation' in metrics and loss_history:
            train_loss = metrics.get('loss')
            val_losses = list(metrics['validation'].values())
            if val_losses and train_loss:
                avg_val_loss = sum(val_losses) / len(val_losses)
                if avg_val_loss > train_loss * 1.5:
                    status['warnings'].append('âš ï¸  éªŒè¯lossæ˜æ˜¾é«˜äºè®­ç»ƒlossï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ')
                    status['suggestions'].append('ğŸ’¡ å»ºè®®: å¢åŠ æ•°æ®å¢å¼ºã€ä½¿ç”¨æ­£åˆ™åŒ–æˆ–å‡å°‘æ¨¡å‹å¤æ‚åº¦')
        
        return status
    
    def format_time_delta(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´å·®"""
        if seconds < 60:
            return f"{seconds:.0f}ç§’"
        elif seconds < 3600:
            return f"{seconds/60:.1f}åˆ†é’Ÿ"
        else:
            return f"{seconds/3600:.1f}å°æ—¶"
    
    def display_metrics(self, clear_screen: bool = True):
        """æ˜¾ç¤ºæŒ‡æ ‡"""
        if clear_screen:
            os.system('clear' if os.name != 'nt' else 'cls')
        
        print("=" * 80)
        print("ğŸ¤– è®­ç»ƒç›‘æ§å™¨")
        print("=" * 80)
        print(f"ğŸ“ è¿è¡Œç›®å½•: {self.run_dir}")
        print(f"ğŸ• æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        # è·å–æœ€æ–°æŒ‡æ ‡
        metrics = self.get_latest_metrics()
        
        if not metrics:
            print("\nâš ï¸  æš‚æ— è®­ç»ƒæ•°æ®ï¼Œç­‰å¾…è®­ç»ƒå¼€å§‹...")
            return
        
        # æ˜¾ç¤ºè®­ç»ƒè¿›åº¦
        print("\nğŸ“Š è®­ç»ƒè¿›åº¦:")
        print("-" * 80)
        
        if 'epoch' in metrics:
            print(f"å½“å‰Epoch: {metrics['epoch'] + 1}")
        
        if 'loss' in metrics:
            # è®¡ç®—losså˜åŒ–
            loss_history = self.metrics_history.get('train/loss', [])
            if len(loss_history) >= 2:
                prev_loss = loss_history[-2][1]
                curr_loss = metrics['loss']
                loss_change = curr_loss - prev_loss
                loss_change_pct = (loss_change / prev_loss) * 100 if prev_loss != 0 else 0
                
                change_symbol = "ğŸ“‰" if loss_change < 0 else "ğŸ“ˆ"
                print(f"è®­ç»ƒLoss: {metrics['loss']:.6f} {change_symbol} ({loss_change_pct:+.2f}%)")
            else:
                print(f"è®­ç»ƒLoss: {metrics['loss']:.6f}")
        
        if 'lr' in metrics:
            print(f"å­¦ä¹ ç‡: {metrics['lr']:.2e}")
        
        if 'epoch_duration' in metrics:
            print(f"Epochè€—æ—¶: {metrics['epoch_duration']:.2f}åˆ†é’Ÿ")
            
            # ä¼°ç®—å‰©ä½™æ—¶é—´ï¼ˆå‡è®¾æ€»å…±è¦è®­ç»ƒçš„epochæ•°ï¼‰
            loss_history = self.metrics_history.get('train/loss', [])
            if len(loss_history) >= 2:
                current_epoch = metrics['epoch']
                # å°è¯•ä»é…ç½®æ–‡ä»¶æ¨æ–­æ€»epochæ•°ï¼ˆç®€åŒ–å¤„ç†ï¼Œå¯ä»¥æ”¹è¿›ï¼‰
                # è¿™é‡Œå‡è®¾ä¸€ä¸ªé»˜è®¤å€¼
                total_epochs_estimate = max(50, current_epoch + 1)
                remaining_epochs = total_epochs_estimate - (current_epoch + 1)
                estimated_remaining_time = remaining_epochs * metrics['epoch_duration']
                
                if remaining_epochs > 0:
                    print(f"é¢„è®¡å‰©ä½™æ—¶é—´: {estimated_remaining_time:.1f}åˆ†é’Ÿ ({estimated_remaining_time/60:.1f}å°æ—¶)")
        
        # æ˜¾ç¤ºéªŒè¯æŒ‡æ ‡
        if 'validation' in metrics and metrics['validation']:
            print("\nğŸ“ˆ éªŒè¯æŒ‡æ ‡:")
            print("-" * 80)
            for task_name, val_loss in metrics['validation'].items():
                print(f"{task_name}: {val_loss:.6f}")
        
        # æ˜¾ç¤ºLossè¶‹åŠ¿
        loss_history = self.metrics_history.get('train/loss', [])
        if len(loss_history) >= 5:
            print("\nğŸ“‰ Lossè¶‹åŠ¿ (æœ€è¿‘10ä¸ªepoch):")
            print("-" * 80)
            recent_history = loss_history[-10:]
            
            # ç®€å•çš„ASCIIå›¾è¡¨
            min_loss = min(v for s, v in recent_history)
            max_loss = max(v for s, v in recent_history)
            loss_range = max_loss - min_loss if max_loss != min_loss else 1
            
            for step, loss in recent_history:
                bar_length = int(((loss - min_loss) / loss_range) * 40)
                bar = "â–ˆ" * bar_length
                print(f"Epoch {int(step)+1:3d}: {loss:.6f} {bar}")
        
        # æ˜¾ç¤ºcheckpointä¿¡æ¯
        checkpoint_info = self.get_checkpoint_info()
        print("\nğŸ’¾ CheckpointçŠ¶æ€:")
        print("-" * 80)
        print(f"æœ€ä½³æ¨¡å‹: {'âœ… å·²ä¿å­˜' if checkpoint_info['best_exists'] else 'âŒ æœªä¿å­˜'}")
        if checkpoint_info['saved_epochs']:
            print(f"å·²ä¿å­˜Epoch: {', '.join(map(str, checkpoint_info['saved_epochs']))}")
            print(f"æœ€æ–°Epoch: {checkpoint_info['latest_epoch']}")
        
        # æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€è¯„ä¼°
        status = self.get_training_status(metrics)
        print("\nğŸ” è®­ç»ƒçŠ¶æ€è¯„ä¼°:")
        print("-" * 80)
        print(f"çŠ¶æ€: {status['status']}")
        
        if status['warnings']:
            print("\nè­¦å‘Š:")
            for warning in status['warnings']:
                print(f"  {warning}")
        
        if status['suggestions']:
            print("\nå»ºè®®:")
            for suggestion in status['suggestions']:
                print(f"  {suggestion}")
        
        print("\n" + "=" * 80)
    
    def plot_metrics(self):
        """ç»˜åˆ¶æŒ‡æ ‡å›¾è¡¨"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('TkAgg')  # ä½¿ç”¨äº¤äº’å¼åç«¯
        except ImportError:
            print("âš ï¸  Matplotlibæœªå®‰è£…ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨ã€‚è¯·è¿è¡Œ: pip install matplotlib")
            return
        
        self.reload_events()
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        fig.suptitle(f'è®­ç»ƒç›‘æ§ - {self.run_dir.name}', fontsize=16)
        
        # 1. Lossæ›²çº¿
        loss_data = self.metrics_history.get('train/loss', [])
        if loss_data:
            steps, values = zip(*loss_data)
            axes[0, 0].plot(steps, values, 'b-', linewidth=2)
            axes[0, 0].set_xlabel('Epoch')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].set_title('è®­ç»ƒLoss')
            axes[0, 0].grid(True, alpha=0.3)
        
        # 2. å­¦ä¹ ç‡æ›²çº¿
        lr_data = self.metrics_history.get('train/lr', [])
        if lr_data:
            steps, values = zip(*lr_data)
            axes[0, 1].plot(steps, values, 'r-', linewidth=2)
            axes[0, 1].set_xlabel('Epoch')
            axes[0, 1].set_ylabel('Learning Rate')
            axes[0, 1].set_title('å­¦ä¹ ç‡å˜åŒ–')
            axes[0, 1].set_yscale('log')
            axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Epochè€—æ—¶
        duration_data = self.metrics_history.get('train/epoch_duration_minutes', [])
        if duration_data:
            steps, values = zip(*duration_data)
            axes[1, 0].plot(steps, values, 'g-', linewidth=2)
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Time (minutes)')
            axes[1, 0].set_title('æ¯Epochè®­ç»ƒæ—¶é—´')
            axes[1, 0].grid(True, alpha=0.3)
        
        # 4. éªŒè¯Lossï¼ˆå¦‚æœæœ‰ï¼‰
        if self.event_acc:
            all_tags = self.event_acc.Tags().get('scalars', [])
            validation_tags = [tag for tag in all_tags if tag.startswith('validation/')]
            
            if validation_tags:
                for tag in validation_tags:
                    val_data = self.get_scalar_data(tag)
                    if val_data:
                        steps, values = zip(*val_data)
                        task_name = tag.replace('validation/', '')
                        axes[1, 1].plot(steps, values, linewidth=2, label=task_name)
                
                axes[1, 1].set_xlabel('Epoch')
                axes[1, 1].set_ylabel('Validation Loss')
                axes[1, 1].set_title('éªŒè¯Loss')
                axes[1, 1].legend()
                axes[1, 1].grid(True, alpha=0.3)
            else:
                axes[1, 1].text(0.5, 0.5, 'æš‚æ— éªŒè¯æ•°æ®', 
                               ha='center', va='center', 
                               transform=axes[1, 1].transAxes)
                axes[1, 1].set_title('éªŒè¯Loss')
        
        plt.tight_layout()
        plt.show()
    
    def save_report(self, output_file: Optional[Path] = None):
        """ä¿å­˜è®­ç»ƒæŠ¥å‘Š"""
        if output_file is None:
            output_file = self.run_dir / f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        
        metrics = self.get_latest_metrics()
        checkpoint_info = self.get_checkpoint_info()
        status = self.get_training_status(metrics)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("è®­ç»ƒç›‘æ§æŠ¥å‘Š\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è¿è¡Œç›®å½•: {self.run_dir}\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("è®­ç»ƒæŒ‡æ ‡:\n")
            f.write("-" * 80 + "\n")
            for key, value in metrics.items():
                if key != 'validation':
                    f.write(f"{key}: {value}\n")
            
            if 'validation' in metrics:
                f.write("\néªŒè¯æŒ‡æ ‡:\n")
                f.write("-" * 80 + "\n")
                for task, loss in metrics['validation'].items():
                    f.write(f"{task}: {loss}\n")
            
            f.write("\nCheckpointçŠ¶æ€:\n")
            f.write("-" * 80 + "\n")
            f.write(f"æœ€ä½³æ¨¡å‹: {'å·²ä¿å­˜' if checkpoint_info['best_exists'] else 'æœªä¿å­˜'}\n")
            if checkpoint_info['saved_epochs']:
                f.write(f"å·²ä¿å­˜Epoch: {', '.join(map(str, checkpoint_info['saved_epochs']))}\n")
            
            f.write("\nè®­ç»ƒçŠ¶æ€è¯„ä¼°:\n")
            f.write("-" * 80 + "\n")
            f.write(f"çŠ¶æ€: {status['status']}\n")
            
            if status['warnings']:
                f.write("\nè­¦å‘Š:\n")
                for warning in status['warnings']:
                    f.write(f"  {warning}\n")
            
            if status['suggestions']:
                f.write("\nå»ºè®®:\n")
                for suggestion in status['suggestions']:
                    f.write(f"  {suggestion}\n")
        
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


def find_latest_run(base_dir: Path = None) -> Optional[Path]:
    """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¿è¡Œ"""
    if base_dir is None:
        base_dir = Path(__file__).parent.parent / "outputs" / "train"
    
    if not base_dir.exists():
        return None
    
    # æŸ¥æ‰¾æ‰€æœ‰run_*ç›®å½•
    run_dirs = []
    for task_dir in base_dir.iterdir():
        if task_dir.is_dir():
            for method_dir in task_dir.iterdir():
                if method_dir.is_dir():
                    for run_dir in method_dir.glob("run_*"):
                        if run_dir.is_dir():
                            run_dirs.append(run_dir)
    
    if not run_dirs:
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    run_dirs.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return run_dirs[0]


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒç›‘æ§å™¨")
    parser.add_argument("--run-dir", type=str, help="è®­ç»ƒè¿è¡Œç›®å½•")
    parser.add_argument("--plot", action="store_true", help="æ˜¾ç¤ºå¯è§†åŒ–å›¾è¡¨")
    parser.add_argument("--refresh", type=int, default=0, 
                       help="è‡ªåŠ¨åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºä¸åˆ·æ–°")
    parser.add_argument("--save-report", action="store_true", help="ä¿å­˜è®­ç»ƒæŠ¥å‘Š")
    
    args = parser.parse_args()
    
    # ç¡®å®šè¿è¡Œç›®å½•
    if args.run_dir:
        run_dir = Path(args.run_dir)
        if not run_dir.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {run_dir}")
            sys.exit(1)
    else:
        print("ğŸ” æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¿è¡Œ...")
        run_dir = find_latest_run()
        if run_dir is None:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒè¿è¡Œã€‚è¯·ä½¿ç”¨ --run-dir æŒ‡å®šç›®å½•ã€‚")
            sys.exit(1)
        print(f"âœ… æ‰¾åˆ°æœ€æ–°è¿è¡Œ: {run_dir}\n")
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = TrainingMonitor(run_dir, enable_plot=args.plot)
    
    # æ£€æŸ¥TensorBoardå¯ç”¨æ€§
    if not TENSORBOARD_AVAILABLE:
        print("âš ï¸  TensorBoardæœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨")
        print("   å®‰è£…å‘½ä»¤: pip install tensorboard\n")
    
    # æ˜¾ç¤ºæŒ‡æ ‡
    try:
        if args.refresh > 0:
            # è‡ªåŠ¨åˆ·æ–°æ¨¡å¼
            print(f"ğŸ”„ è‡ªåŠ¨åˆ·æ–°æ¨¡å¼ (æ¯{args.refresh}ç§’åˆ·æ–°ä¸€æ¬¡ï¼ŒæŒ‰Ctrl+Cé€€å‡º)\n")
            while True:
                monitor.display_metrics(clear_screen=True)
                time.sleep(args.refresh)
        else:
            # å•æ¬¡æ˜¾ç¤º
            monitor.display_metrics(clear_screen=False)
        
        # ä¿å­˜æŠ¥å‘Š
        if args.save_report:
            monitor.save_report()
        
        # æ˜¾ç¤ºå›¾è¡¨
        if args.plot:
            print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            monitor.plot_metrics()
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
        sys.exit(0)


if __name__ == "__main__":
    main()

