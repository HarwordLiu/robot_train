# -*- coding: utf-8 -*-
"""
æµ‹è¯•åˆ†å±‚æ¶æ„æ¡†æ¶çš„åŸºç¡€åŠŸèƒ½
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import torch
import time
from kuavo_train.wrapper.policy.humanoid.layers.SafetyReflexLayer import SafetyReflexLayer
from kuavo_train.wrapper.policy.humanoid.layers.GaitControlLayer import GaitControlLayer
from kuavo_train.wrapper.policy.humanoid.layers.ManipulationLayer import ManipulationLayer
from kuavo_train.wrapper.policy.humanoid.layers.GlobalPlanningLayer import GlobalPlanningLayer
from kuavo_train.wrapper.policy.humanoid.HierarchicalScheduler import HierarchicalScheduler


class MockConfig:
    """æ¨¡æ‹Ÿé…ç½®å¯¹è±¡ - åŒ¹é…å®é™…æœºå™¨äººé…ç½®"""
    def __init__(self):
        # é€‚é…only_arm=trueé…ç½®ï¼šåŒè‡‚14ç»´+æ‰‹çˆª2ç»´=16ç»´
        self.robot_state_feature = type('obj', (object,), {'shape': [16]})()
        self.use_hierarchical = True


def test_safety_layer():
    """æµ‹è¯•å®‰å…¨åå°„å±‚"""
    print("ğŸ§ª Testing SafetyReflexLayer...")

    config = {
        'input_dim': 16,  # é€‚é…å®é™…æœºå™¨äººé…ç½®
        'hidden_size': 64,
        'output_dim': 16,
        'emergency_threshold': 0.8,
        'tilt_threshold_degrees': 15.0,
        'enabled': True
    }

    base_config = MockConfig()
    layer = SafetyReflexLayer(config, base_config)

    # åˆ›å»ºæµ‹è¯•è¾“å…¥ - åŒ¹é…å®é™…æœºå™¨äººçŠ¶æ€ç»´åº¦
    batch_size = 4
    seq_len = 10
    inputs = {
        'observation.state': torch.randn(batch_size, seq_len, 16)  # åŒè‡‚+æ‰‹çˆªé…ç½®
    }

    # æµ‹è¯•å‰å‘ä¼ æ’­
    start_time = time.time()
    output = layer.forward_with_timing(inputs)
    execution_time = (time.time() - start_time) * 1000

    print("  âœ… Safety layer execution time: {:.2f}ms".format(execution_time))
    print("  âœ… Emergency status: {}".format(output['emergency']))
    print("  âœ… Output keys: {}".format(list(output.keys())))

    # éªŒè¯å»¶è¿Ÿè¦æ±‚
    assert execution_time < 20, "Safety layer too slow: {}ms".format(execution_time)
    assert 'emergency' in output
    assert 'balance_action' in output

    print("  âœ… SafetyReflexLayer test passed!")
    return True


def test_gait_layer():
    """æµ‹è¯•æ­¥æ€æ§åˆ¶å±‚"""
    print("ğŸ§ª Testing GaitControlLayer...")

    config = {
        'gru_hidden': 128,
        'gru_layers': 2,
        'tf_layers': 2,
        'tf_heads': 4,
        'tf_dim': 128,
        'enabled': True
    }

    base_config = MockConfig()
    layer = GaitControlLayer(config, base_config)

    # åˆ›å»ºæµ‹è¯•è¾“å…¥ - åŒ¹é…å®é™…æœºå™¨äººé…ç½®
    batch_size = 4
    seq_len = 15
    inputs = {
        'observation.state': torch.randn(batch_size, seq_len, 16)  # é€‚é…åŒè‡‚+æ‰‹çˆªé…ç½®
    }

    # æµ‹è¯•å‰å‘ä¼ æ’­
    start_time = time.time()
    output = layer.forward_with_timing(inputs)
    execution_time = (time.time() - start_time) * 1000

    print(f"  âœ… Gait layer execution time: {execution_time:.2f}ms")
    print(f"  âœ… Output keys: {list(output.keys())}")

    # éªŒè¯
    assert execution_time < 50, f"Gait layer too slow: {execution_time}ms"
    assert 'gait_features' in output
    assert 'action' in output

    print("  âœ… GaitControlLayer test passed!")
    return True


def test_manipulation_layer():
    """æµ‹è¯•æ“ä½œæ§åˆ¶å±‚"""
    print("ğŸ§ª Testing ManipulationLayer...")

    config = {
        'hidden_size': 512,
        'layers': 3,
        'heads': 8,
        'dim_feedforward': 2048,
        'enabled': True
    }

    base_config = MockConfig()
    layer = ManipulationLayer(config, base_config)

    # åˆ›å»ºæµ‹è¯•è¾“å…¥ - åŒ¹é…å®é™…æœºå™¨äººé…ç½®
    batch_size = 2
    seq_len = 8
    inputs = {
        'observation.state': torch.randn(batch_size, seq_len, 16),  # é€‚é…åŒè‡‚+æ‰‹çˆªé…ç½®
        'observation.images': torch.randn(batch_size, seq_len, 1280)  # æ¨¡æ‹Ÿè§†è§‰ç‰¹å¾
    }

    # æµ‹è¯•å‰å‘ä¼ æ’­
    start_time = time.time()
    output = layer.forward_with_timing(inputs)
    execution_time = (time.time() - start_time) * 1000

    print(f"  âœ… Manipulation layer execution time: {execution_time:.2f}ms")
    print(f"  âœ… Output keys: {list(output.keys())}")

    # éªŒè¯
    assert execution_time < 200, f"Manipulation layer too slow: {execution_time}ms"
    assert 'manipulation_features' in output
    assert 'action' in output

    print("  âœ… ManipulationLayer test passed!")
    return True


def test_planning_layer():
    """æµ‹è¯•å…¨å±€è§„åˆ’å±‚"""
    print("ğŸ§ª Testing GlobalPlanningLayer...")

    config = {
        'hidden_size': 1024,
        'layers': 4,
        'heads': 16,
        'dim_feedforward': 4096,
        'enabled': True
    }

    base_config = MockConfig()
    layer = GlobalPlanningLayer(config, base_config)

    # åˆ›å»ºæµ‹è¯•è¾“å…¥ - åŒ¹é…å®é™…æœºå™¨äººé…ç½®
    batch_size = 2
    seq_len = 5
    inputs = {
        'observation.state': torch.randn(batch_size, seq_len, 16),  # é€‚é…åŒè‡‚+æ‰‹çˆªé…ç½®
        'observation.images': torch.randn(batch_size, seq_len, 1280)
    }

    # æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆåªæœ‰é«˜å¤æ‚åº¦ä»»åŠ¡æ‰æ¿€æ´»ï¼‰
    context = {'task_complexity': 'high'}

    start_time = time.time()
    output = layer.forward_with_timing(inputs, context)
    execution_time = (time.time() - start_time) * 1000

    print(f"  âœ… Planning layer execution time: {execution_time:.2f}ms")
    print(f"  âœ… Output keys: {list(output.keys())}")

    # éªŒè¯
    assert execution_time < 1000, f"Planning layer too slow: {execution_time}ms"
    assert 'global_features' in output
    assert 'action' in output

    print("  âœ… GlobalPlanningLayer test passed!")
    return True


def test_hierarchical_scheduler():
    """æµ‹è¯•åˆ†å±‚è°ƒåº¦å™¨"""
    print("ğŸ§ª Testing HierarchicalScheduler...")

    # æ„å»ºé…ç½®
    hierarchical_config = {
        'layers': {
            'safety': {
                'type': 'GRU',
                'input_dim': 16,  # é€‚é…å®é™…æœºå™¨äººé…ç½®
                'hidden_size': 64,
                'output_dim': 16,
                'enabled': True
            },
            'gait': {
                'type': 'Hybrid',
                'gru_hidden': 128,
                'gru_layers': 2,
                'tf_layers': 2,
                'tf_heads': 4,
                'enabled': True
            },
            'manipulation': {
                'type': 'Transformer',
                'hidden_size': 512,
                'layers': 3,
                'heads': 8,
                'dim_feedforward': 2048,
                'enabled': True
            },
            'planning': {
                'type': 'Transformer',
                'hidden_size': 1024,
                'layers': 4,
                'heads': 16,
                'dim_feedforward': 4096,
                'enabled': False  # é»˜è®¤ç¦ç”¨æœ€å¤æ‚çš„å±‚
            }
        },
        'layer_weights': {
            'safety': 2.0,
            'gait': 1.5,
            'manipulation': 1.0,
            'planning': 0.8
        }
    }

    base_config = MockConfig()
    scheduler = HierarchicalScheduler(hierarchical_config, base_config)

    # åˆ›å»ºæµ‹è¯•è¾“å…¥ - åŒ¹é…å®é™…æœºå™¨äººé…ç½®
    batch_size = 2
    seq_len = 10
    batch = {
        'observation.state': torch.randn(batch_size, seq_len, 16)  # é€‚é…åŒè‡‚+æ‰‹çˆªé…ç½®
    }

    task_info = {
        'task_complexity': 'medium',
        'requires_locomotion': True,
        'requires_manipulation': True
    }

    # æµ‹è¯•åˆ†å±‚å‰å‘ä¼ æ’­
    start_time = time.time()
    outputs = scheduler(batch, task_info)
    execution_time = (time.time() - start_time) * 1000

    print(f"  âœ… Scheduler execution time: {execution_time:.2f}ms")
    print(f"  âœ… Active layers: {list(outputs.keys())}")

    # æµ‹è¯•æ¨ç†æ¨¡å¼
    start_time = time.time()
    inference_outputs = scheduler.inference_mode(batch, task_info, latency_budget_ms=50.0)
    inference_time = (time.time() - start_time) * 1000

    print(f"  âœ… Inference mode time: {inference_time:.2f}ms")
    print(f"  âœ… Within budget: {inference_outputs.get('_inference_stats', {}).get('within_budget', False)}")

    # è·å–æ€§èƒ½ç»Ÿè®¡
    stats = scheduler.get_performance_stats()
    print(f"  âœ… Performance stats: {stats}")

    print("  âœ… HierarchicalScheduler test passed!")
    return True


def test_integration():
    """é›†æˆæµ‹è¯•"""
    print("ğŸ§ª Running integration tests...")

    # è¿è¡Œæ‰€æœ‰å•ç‹¬çš„æµ‹è¯•
    tests = [
        test_safety_layer,
        test_gait_layer,
        test_manipulation_layer,
        test_planning_layer,
        test_hierarchical_scheduler
    ]

    passed = 0
    for test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"  âŒ {test_func.__name__} failed: {e}")

    print(f"\nğŸ“Š Test Results: {passed}/{len(tests)} tests passed")

    if passed == len(tests):
        print("ğŸ‰ All tests passed! Hierarchical framework is working correctly.")
        return True
    else:
        print("âŒ Some tests failed. Please check the implementation.")
        return False


if __name__ == "__main__":
    print("ğŸš€ Starting Hierarchical Framework Tests\n")

    try:
        success = test_integration()

        if success:
            print("\nâœ… Framework ready for training!")
            print("ğŸ“ Next steps:")
            print("   1. Train with: python kuavo_train/train_policy.py --config-name=humanoid_diffusion_config")
            print("   2. Monitor layer performance and adjust configurations")
            print("   3. Fine-tune layer weights and activation thresholds")
        else:
            print("\nâŒ Framework needs fixes before training")

    except Exception as e:
        print(f"\nğŸ’¥ Test framework error: {e}")
        import traceback
        traceback.print_exc()