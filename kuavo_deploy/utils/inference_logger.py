"""
æ¨ç†æ—¥å¿—è®°å½•å™¨
ç”¨äºè®°å½•æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
- æ¯æ­¥çš„æ¨ç†ç»“æœ
- å±‚æ¿€æ´»æƒ…å†µ
- æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
- ä»»åŠ¡ç›¸å…³ä¿¡æ¯
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
import numpy as np
import torch
from datetime import datetime


class InferenceLogger:
    """æ¨ç†æ—¥å¿—è®°å½•å™¨"""

    def __init__(self,
                 output_dir: Path,
                 episode_idx: int,
                 log_every_n_steps: int = 1,
                 save_detailed_layers: bool = True):
        """
        åˆå§‹åŒ–æ¨ç†æ—¥å¿—è®°å½•å™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            episode_idx: å½“å‰å›åˆç´¢å¼•
            log_every_n_steps: æ¯Næ­¥è®°å½•ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
            save_detailed_layers: æ˜¯å¦ä¿å­˜è¯¦ç»†çš„å±‚ä¿¡æ¯
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.episode_idx = episode_idx
        self.log_every_n_steps = log_every_n_steps
        self.save_detailed_layers = save_detailed_layers

        # åˆ›å»ºå›åˆç‰¹å®šçš„æ—¥å¿—æ–‡ä»¶
        self.log_file = self.output_dir / \
            f"inference_episode_{episode_idx}.jsonl"
        self.summary_file = self.output_dir / \
            f"inference_episode_{episode_idx}_summary.json"

        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.step_count = 0
        self.total_inference_time = 0.0
        self.layer_activation_counts = {}
        self.layer_execution_times = {}

        # ç¼“å­˜å½“å‰å›åˆçš„æ‰€æœ‰æ­¥éª¤è®°å½•
        self.step_records = []

        # è®°å½•å¼€å§‹æ—¶é—´
        self.episode_start_time = datetime.now()

    def log_step(self,
                 step: int,
                 action: np.ndarray,
                 observation_shapes: Dict[str, tuple],
                 layer_outputs: Optional[Dict[str, Any]] = None,
                 inference_time: float = 0.0,
                 additional_info: Optional[Dict[str, Any]] = None):
        """
        è®°å½•å•æ­¥æ¨ç†ä¿¡æ¯

        Args:
            step: å½“å‰æ­¥æ•°
            action: æ¨ç†å¾—åˆ°çš„åŠ¨ä½œ
            observation_shapes: è§‚æµ‹æ•°æ®çš„å½¢çŠ¶ä¿¡æ¯
            layer_outputs: å±‚è¾“å‡ºä¿¡æ¯ï¼ˆåˆ†å±‚æ¶æ„ï¼‰
            inference_time: æ¨ç†è€—æ—¶
            additional_info: é¢å¤–ä¿¡æ¯
        """
        self.step_count += 1
        self.total_inference_time += inference_time

        # æ„å»ºåŸºç¡€è®°å½•
        step_record = {
            "timestamp": datetime.now().isoformat(),
            "episode": self.episode_idx,
            "step": step,
            "inference_time_ms": inference_time * 1000,
            "observation_shapes": observation_shapes,
        }

        # è®°å½•åŠ¨ä½œä¿¡æ¯
        if isinstance(action, torch.Tensor):
            action = action.cpu().numpy()

        step_record["action"] = {
            "shape": action.shape,
            "mean": float(np.mean(action)),
            "std": float(np.std(action)),
            "min": float(np.min(action)),
            "max": float(np.max(action)),
        }

        # æ¯Næ­¥è®°å½•å®Œæ•´åŠ¨ä½œå€¼
        if step % self.log_every_n_steps == 0:
            step_record["action"]["values"] = action.tolist()

        # è®°å½•å±‚æ¿€æ´»ä¿¡æ¯ï¼ˆåˆ†å±‚æ¶æ„ï¼‰
        if layer_outputs is not None and self.save_detailed_layers:
            layer_info = self._process_layer_outputs(layer_outputs)
            step_record["hierarchical_layers"] = layer_info

        # æ·»åŠ é¢å¤–ä¿¡æ¯
        if additional_info:
            step_record["additional_info"] = additional_info

        # ä¿å­˜åˆ°ç¼“å­˜
        self.step_records.append(step_record)

        # å®æ—¶å†™å…¥JSONLæ–‡ä»¶ï¼ˆæ¯æ­¥è¿½åŠ ä¸€è¡Œï¼‰
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(step_record, ensure_ascii=False) + '\n')

    def _process_layer_outputs(self, layer_outputs: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å±‚è¾“å‡ºä¿¡æ¯ï¼Œæå–å…³é”®ç»Ÿè®¡æ•°æ®"""
        layer_info = {}

        for layer_name, layer_output in layer_outputs.items():
            # è·³è¿‡å†…éƒ¨ç»Ÿè®¡ä¿¡æ¯
            if layer_name.startswith('_'):
                continue

            # æ›´æ–°æ¿€æ´»è®¡æ•°
            if layer_name not in self.layer_activation_counts:
                self.layer_activation_counts[layer_name] = 0
            self.layer_activation_counts[layer_name] += 1

            layer_record = {
                "activated": True,
                "activation_count": self.layer_activation_counts[layer_name],
            }

            if isinstance(layer_output, dict):
                # è®°å½•æ‰§è¡Œæ—¶é—´
                if 'execution_time_ms' in layer_output:
                    exec_time = layer_output['execution_time_ms']
                    layer_record["execution_time_ms"] = exec_time

                    if layer_name not in self.layer_execution_times:
                        self.layer_execution_times[layer_name] = []
                    self.layer_execution_times[layer_name].append(exec_time)

                # è®°å½•æŸå¤±å€¼ï¼ˆè®­ç»ƒæ¨¡å¼ï¼‰
                if 'loss' in layer_output:
                    loss_value = layer_output['loss']
                    if torch.is_tensor(loss_value):
                        loss_value = loss_value.item()
                    layer_record["loss"] = loss_value

                # è®°å½•ç´§æ€¥çŠ¶æ€ï¼ˆå®‰å…¨å±‚ï¼‰
                if 'emergency' in layer_output:
                    layer_record["emergency"] = layer_output['emergency']

                # è®°å½•åŠ¨ä½œä¿¡æ¯
                if 'action' in layer_output:
                    action = layer_output['action']
                    if torch.is_tensor(action):
                        action = action.cpu().numpy()
                    layer_record["action_shape"] = action.shape
                    layer_record["action_norm"] = float(np.linalg.norm(action))

                # è®°å½•å…¶ä»–å¯åºåˆ—åŒ–çš„å­—æ®µ
                for key, value in layer_output.items():
                    if key not in ['action', 'loss', 'execution_time_ms', 'emergency']:
                        if isinstance(value, (int, float, str, bool)):
                            layer_record[key] = value
                        elif isinstance(value, (list, tuple)) and len(value) < 10:
                            layer_record[key] = value

            layer_info[layer_name] = layer_record

        return layer_info

    def save_episode_summary(self,
                             success: bool,
                             total_reward: float,
                             additional_stats: Optional[Dict[str, Any]] = None):
        """
        ä¿å­˜å›åˆæ€»ç»“ä¿¡æ¯

        Args:
            success: æ˜¯å¦æˆåŠŸ
            total_reward: æ€»å¥–åŠ±
            additional_stats: é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        """
        episode_end_time = datetime.now()
        episode_duration = (episode_end_time -
                            self.episode_start_time).total_seconds()

        summary = {
            "episode_index": self.episode_idx,
            "start_time": self.episode_start_time.isoformat(),
            "end_time": episode_end_time.isoformat(),
            "episode_duration_sec": episode_duration,
            "success": success,
            "total_reward": total_reward,
            "total_steps": self.step_count,
            "total_inference_time_sec": self.total_inference_time,
            "avg_inference_time_ms": (self.total_inference_time / self.step_count * 1000) if self.step_count > 0 else 0,
        }

        # åˆ†å±‚æ¶æ„ç»Ÿè®¡
        if self.layer_activation_counts:
            summary["hierarchical_stats"] = {
                "layer_activation_counts": self.layer_activation_counts,
                "layer_avg_execution_times_ms": {
                    layer: np.mean(times)
                    for layer, times in self.layer_execution_times.items()
                },
                "layer_total_execution_times_ms": {
                    layer: np.sum(times)
                    for layer, times in self.layer_execution_times.items()
                },
            }

        # æ·»åŠ é¢å¤–ç»Ÿè®¡ä¿¡æ¯
        if additional_stats:
            summary["additional_stats"] = additional_stats

        # ä¿å­˜æ€»ç»“
        with open(self.summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)

        print(f"âœ… æ¨ç†æ—¥å¿—å·²ä¿å­˜:")
        print(f"   è¯¦ç»†è®°å½•: {self.log_file}")
        print(f"   å›åˆæ€»ç»“: {self.summary_file}")
        print(f"   æ€»æ­¥æ•°: {self.step_count}, æˆåŠŸ: {success}")
        if self.layer_activation_counts:
            print(f"   å±‚æ¿€æ´»æ¬¡æ•°: {self.layer_activation_counts}")

    @staticmethod
    def create_aggregated_report(output_dir: Path, task_name: str = ""):
        """
        åˆ›å»ºèšåˆæŠ¥å‘Šï¼Œæ±‡æ€»æ‰€æœ‰å›åˆçš„ç»Ÿè®¡ä¿¡æ¯

        Args:
            output_dir: è¾“å‡ºç›®å½•
            task_name: ä»»åŠ¡åç§°
        """
        output_dir = Path(output_dir)
        summary_files = list(output_dir.glob(
            "inference_episode_*_summary.json"))

        if not summary_files:
            print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•å›åˆæ€»ç»“æ–‡ä»¶")
            return

        # è¯»å–æ‰€æœ‰æ€»ç»“æ–‡ä»¶
        all_summaries = []
        for summary_file in summary_files:
            with open(summary_file, 'r', encoding='utf-8') as f:
                all_summaries.append(json.load(f))

        # è®¡ç®—èšåˆç»Ÿè®¡
        total_episodes = len(all_summaries)
        success_count = sum(
            1 for s in all_summaries if s.get('success', False))
        success_rate = success_count / total_episodes if total_episodes > 0 else 0

        avg_steps = np.mean([s['total_steps'] for s in all_summaries])
        avg_inference_time = np.mean(
            [s['avg_inference_time_ms'] for s in all_summaries])

        aggregated_report = {
            "task_name": task_name,
            "generated_at": datetime.now().isoformat(),
            "total_episodes": total_episodes,
            "success_count": success_count,
            "success_rate": success_rate,
            "avg_steps_per_episode": avg_steps,
            "avg_inference_time_ms": avg_inference_time,
            "episodes": all_summaries,
        }

        # èšåˆåˆ†å±‚æ¶æ„ç»Ÿè®¡
        hierarchical_stats = {}
        for summary in all_summaries:
            if 'hierarchical_stats' in summary:
                h_stats = summary['hierarchical_stats']
                for layer, count in h_stats.get('layer_activation_counts', {}).items():
                    if layer not in hierarchical_stats:
                        hierarchical_stats[layer] = {
                            'total_activations': 0,
                            'avg_execution_times': []
                        }
                    hierarchical_stats[layer]['total_activations'] += count

                    layer_avg_time = h_stats.get(
                        'layer_avg_execution_times_ms', {}).get(layer)
                    if layer_avg_time is not None:
                        hierarchical_stats[layer]['avg_execution_times'].append(
                            layer_avg_time)

        # è®¡ç®—æ¯å±‚çš„å¹³å‡æ‰§è¡Œæ—¶é—´
        if hierarchical_stats:
            aggregated_report['hierarchical_aggregated_stats'] = {
                layer: {
                    'total_activations': stats['total_activations'],
                    'avg_execution_time_ms': np.mean(stats['avg_execution_times']) if stats['avg_execution_times'] else 0,
                }
                for layer, stats in hierarchical_stats.items()
            }

        # ä¿å­˜èšåˆæŠ¥å‘Š
        report_file = output_dir / "aggregated_inference_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(aggregated_report, f, indent=2, ensure_ascii=False)

        print(f"\n{'='*60}")
        print(f"ğŸ“Š èšåˆæ¨ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        print(f"{'='*60}")
        print(f"ä»»åŠ¡: {task_name}")
        print(f"æ€»å›åˆæ•°: {total_episodes}")
        print(f"æˆåŠŸç‡: {success_rate:.2%} ({success_count}/{total_episodes})")
        print(f"å¹³å‡æ­¥æ•°: {avg_steps:.1f}")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}ms")

        if 'hierarchical_aggregated_stats' in aggregated_report:
            print(f"\nåˆ†å±‚æ¶æ„ç»Ÿè®¡:")
            for layer, stats in aggregated_report['hierarchical_aggregated_stats'].items():
                print(f"  {layer}:")
                print(f"    æ€»æ¿€æ´»æ¬¡æ•°: {stats['total_activations']}")
                print(f"    å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_execution_time_ms']:.2f}ms")

        print(f"{'='*60}\n")

        return aggregated_report


class InferenceLoggerContext:
    """æ¨ç†æ—¥å¿—è®°å½•å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, logger: InferenceLogger, step: int):
        self.logger = logger
        self.step = step
        self.start_time = None
        self.observation_shapes = {}
        self.layer_outputs = None
        self.action = None
        self.additional_info = {}

    def __enter__(self):
        self.start_time = time.time()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None and self.action is not None:
            inference_time = time.time() - self.start_time
            self.logger.log_step(
                step=self.step,
                action=self.action,
                observation_shapes=self.observation_shapes,
                layer_outputs=self.layer_outputs,
                inference_time=inference_time,
                additional_info=self.additional_info
            )
