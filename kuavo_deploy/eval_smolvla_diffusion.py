"""
SmolVLA Diffusion éƒ¨ç½²è¯„ä¼°è„šæœ¬

åœ¨ä»¿çœŸç¯å¢ƒä¸­è¯„ä¼° SmolVLA Diffusion æ¨¡å‹çš„æ€§èƒ½
"""

import os
import sys
import time
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional
import hydra
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from kuavo_train.wrapper.policy.smolvla import SmolVLADiffusionPolicyWrapper
from kuavo_sim_env.envs.kuavo_sim_env import KuavoSimEnv


class SmolVLADiffusionEvaluator:
    """
    SmolVLA Diffusion è¯„ä¼°å™¨
    """

    def __init__(self, cfg):
        self.cfg = cfg
        self.device = torch.device(cfg.policy.device if torch.cuda.is_available() else 'cpu')

        # åˆå§‹åŒ–ç¯å¢ƒ
        self.env = KuavoSimEnv(
            host=cfg.env.host,
            port=cfg.env.port
        )

        # åˆå§‹åŒ–ç­–ç•¥
        self.policy = self._load_policy()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'episodes': [],
            'success_rate': 0.0,
            'avg_inference_time': 0.0,
            'placement_accuracy': 0.0,
        }

        print(f"\nğŸš€ SmolVLA Diffusion è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - æ¨ç†æ­¥æ•°: {cfg.policy.inference.num_inference_steps}")
        print(f"   - ä½¿ç”¨ DDIM: {cfg.policy.inference.use_ddim_sampling}")

    def _load_policy(self) -> SmolVLADiffusionPolicyWrapper:
        """
        åŠ è½½ SmolVLA Diffusion æ¨¡å‹
        """
        print("\nğŸ“¦ åŠ è½½ SmolVLA Diffusion æ¨¡å‹...")

        policy = SmolVLADiffusionPolicyWrapper.from_pretrained(
            pretrained_name_or_path=self.cfg.policy.pretrained_name_or_path,
            apply_freezing=False  # æ¨ç†æ¨¡å¼ä¸éœ€è¦å†»ç»“
        )

        policy.to(self.device)
        policy.eval()

        # ä¼˜åŒ–æ¨ç†
        if self.cfg.optimization.use_amp:
            policy = policy.half()  # ä½¿ç”¨åŠç²¾åº¦

        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")

        return policy

    def prepare_observation(self, obs: Dict[str, Any]) -> Dict[str, torch.Tensor]:
        """
        å‡†å¤‡è§‚æµ‹æ•°æ®
        """
        batch = {}

        # å¤„ç†å›¾åƒ
        for key in self.cfg.observation.images:
            if key in obs:
                img = obs[key]
                if isinstance(img, np.ndarray):
                    img = torch.from_numpy(img).float()
                    img = img.permute(2, 0, 1)  # HWC -> CHW
                    img = img / 255.0  # å½’ä¸€åŒ–åˆ° [0, 1]
                batch[key] = img.unsqueeze(0).to(self.device)  # æ·»åŠ  batch ç»´

        # å¤„ç†æ·±åº¦
        for key in self.cfg.observation.depth:
            if key in obs:
                depth = obs[key]
                if isinstance(depth, np.ndarray):
                    depth = torch.from_numpy(depth).float()
                    depth = depth.unsqueeze(0)  # æ·»åŠ é€šé“ç»´
                batch[key] = depth.unsqueeze(0).to(self.device)

        # å¤„ç†çŠ¶æ€
        if 'observation.state' in obs:
            state = obs['observation.state']
            if isinstance(state, np.ndarray):
                state = torch.from_numpy(state).float()

            # å¡«å……åˆ°32ç»´
            if self.cfg.preprocessing.state.padding and state.shape[-1] < 32:
                padding = torch.zeros(32 - state.shape[-1])
                state = torch.cat([state, padding], dim=-1)

            batch['observation.state'] = state.unsqueeze(0).to(self.device)

        # æ·»åŠ è¯­è¨€æŒ‡ä»¤
        batch['task'] = [self.cfg.task.language_instruction]

        return batch

    def select_action(self, obs: Dict[str, Any]) -> np.ndarray:
        """
        é€‰æ‹©åŠ¨ä½œ
        """
        # å‡†å¤‡è§‚æµ‹
        batch = self.prepare_observation(obs)

        # æ¨ç†
        with torch.no_grad():
            start_time = time.time()

            # ä½¿ç”¨ Diffusion é‡‡æ ·
            if self.cfg.optimization.use_amp:
                with torch.autocast(device_type='cuda', dtype=torch.float16):
                    actions = self.policy.select_action(
                        batch,
                        num_inference_steps=self.cfg.policy.inference.num_inference_steps
                    )
            else:
                actions = self.policy.select_action(
                    batch,
                    num_inference_steps=self.cfg.policy.inference.num_inference_steps
                )

            inference_time = time.time() - start_time

        # æå–ç¬¬ä¸€ä¸ªåŠ¨ä½œ
        action = actions[0, 0].cpu().numpy()

        # è£å‰ªåˆ°16ç»´ï¼ˆKuavo å®é™…ç»´åº¦ï¼‰
        action = action[:16]

        return action, inference_time

    def evaluate_episode(self, episode_idx: int) -> Dict[str, Any]:
        """
        è¯„ä¼°å•ä¸ªå›åˆ
        """
        print(f"\nğŸ“Š è¯„ä¼°å›åˆ {episode_idx + 1}/{self.cfg.evaluation.num_episodes}")

        # é‡ç½®ç¯å¢ƒ
        obs = self.env.reset()
        done = False
        steps = 0
        inference_times = []
        placements = []

        while not done and steps < self.cfg.task.action.chunk_size:
            # é€‰æ‹©åŠ¨ä½œ
            action, inference_time = self.select_action(obs)
            inference_times.append(inference_time)

            # æ‰§è¡ŒåŠ¨ä½œ
            obs, reward, done, info = self.env.step(action)

            # è®°å½•æ”¾ç½®ä½ç½®
            if 'placement_position' in info:
                placements.append(info['placement_position'])

            steps += 1

            # æ£€æŸ¥è¶…æ—¶
            if steps * self.cfg.task.action.control_frequency > self.cfg.evaluation.timeout.per_episode:
                print(f"   âš ï¸ å›åˆè¶…æ—¶")
                break

        # è®¡ç®—æˆåŠŸç‡
        success = done and info.get('is_success', False)

        # è®¡ç®—æ”¾ç½®ç²¾åº¦
        placement_accuracy = 0.0
        if placements:
            target_positions = info.get('target_positions', [])
            if target_positions:
                errors = [np.linalg.norm(p - t) for p, t in zip(placements, target_positions)]
                placement_accuracy = np.mean(errors)

        # è®¡ç®—å¹³å‡æ¨ç†æ—¶é—´
        avg_inference_time = np.mean(inference_times) if inference_times else 0.0

        episode_stats = {
            'success': success,
            'steps': steps,
            'inference_times': inference_times,
            'avg_inference_time': avg_inference_time,
            'placement_accuracy': placement_accuracy,
            'total_reward': info.get('total_reward', 0.0),
        }

        print(f"   - æˆåŠŸ: {'âœ…' if success else 'âŒ'}")
        print(f"   - æ­¥æ•°: {steps}")
        print(f"   - å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f} ms")
        if placement_accuracy > 0:
            print(f"   - æ”¾ç½®ç²¾åº¦: {placement_accuracy*100:.2f} cm")

        return episode_stats

    def evaluate(self):
        """
        æ‰§è¡Œå®Œæ•´è¯„ä¼°
        """
        print(f"\n{'='*70}")
        print("ğŸ¯ å¼€å§‹ SmolVLA Diffusion è¯„ä¼°")
        print(f"{'='*70}")
        print(f"ğŸ“‹ è¯„ä¼°é…ç½®:")
        print(f"   - å›åˆæ•°: {self.cfg.evaluation.num_episodes}")
        print(f"   - æ¨¡å‹è·¯å¾„: {self.cfg.policy.pretrained_name_or_path}")
        print(f"   - æ¨ç†æ­¥æ•°: {self.cfg.policy.inference.num_inference_steps}")
        print(f"{'='*70}\n")

        # è¯„ä¼°æ‰€æœ‰å›åˆ
        all_episodes = []
        for i in range(self.cfg.evaluation.num_episodes):
            episode_stats = self.evaluate_episode(i)
            all_episodes.append(episode_stats)
            self.stats['episodes'].append(episode_stats)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        successes = sum(e['success'] for e in all_episodes)
        self.stats['success_rate'] = successes / len(all_episodes)

        avg_inference_times = [e['avg_inference_time'] for e in all_episodes]
        self.stats['avg_inference_time'] = np.mean(avg_inference_times)

        placement_accuracies = [e['placement_accuracy'] for e in all_episodes if e['placement_accuracy'] > 0]
        if placement_accuracies:
            self.stats['placement_accuracy'] = np.mean(placement_accuracies)

        # æ‰“å°ç»“æœ
        self.print_results()

        # ä¿å­˜ç»“æœ
        self.save_results()

        return self.stats

    def print_results(self):
        """
        æ‰“å°è¯„ä¼°ç»“æœ
        """
        print(f"\n{'='*70}")
        print("ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€»")
        print(f"{'='*70}")
        print(f"âœ… æˆåŠŸç‡: {self.stats['success_rate']*100:.1f}%")
        print(f"âš¡ å¹³å‡æ¨ç†æ—¶é—´: {self.stats['avg_inference_time']*1000:.2f} ms")
        if self.stats['placement_accuracy'] > 0:
            print(f"ğŸ¯ å¹³å‡æ”¾ç½®ç²¾åº¦: {self.stats['placement_accuracy']*100:.2f} cm")

        # è¯¦ç»†ç»Ÿè®¡
        print(f"\nğŸ“ˆ è¯¦ç»†ç»Ÿè®¡:")
        episodes = self.stats['episodes']
        print(f"   - æˆåŠŸå›åˆ: {sum(e['success'] for e in episodes)}/{len(episodes)}")
        print(f"   - å¹³å‡æ­¥æ•°: {np.mean([e['steps'] for e in episodes]):.1f}")
        print(f"   - æœ€å¿«æ¨ç†: {min([e['avg_inference_time'] for e in episodes])*1000:.2f} ms")
        print(f"   - æœ€æ…¢æ¨ç†: {max([e['avg_inference_time'] for e in episodes])*1000:.2f} ms")

    def save_results(self):
        """
        ä¿å­˜è¯„ä¼°ç»“æœ
        """
        import json
        from datetime import datetime

        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(self.cfg.logging.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        result_file = output_dir / f"eval_results_{timestamp}.json"

        # å‡†å¤‡ä¿å­˜æ•°æ®
        save_data = {
            'config': OmegaConf.to_container(self.cfg, resolve=True),
            'stats': {
                'success_rate': float(self.stats['success_rate']),
                'avg_inference_time': float(self.stats['avg_inference_time']),
                'placement_accuracy': float(self.stats['placement_accuracy']),
            },
            'episodes': self.stats['episodes'],
            'timestamp': timestamp,
        }

        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(result_file, 'w') as f:
            json.dump(save_data, f, indent=2, default=str)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")


@hydra.main(
    version_base=None,
    config_path="../configs/deploy",
    config_name="kuavo_smolvla_diffusion_sim_env"
)
def main(cfg):
    """
    ä¸»è¯„ä¼°å‡½æ•°
    """
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = SmolVLADiffusionEvaluator(cfg)

    # æ‰§è¡Œè¯„ä¼°
    stats = evaluator.evaluate()

    print(f"\nğŸ‰ è¯„ä¼°å®Œæˆ!")

    return stats


if __name__ == "__main__":
    main()